{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hardi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:12: SyntaxWarning: invalid escape sequence '\\g'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\g'\n",
      "C:\\Users\\hardi\\AppData\\Local\\Temp\\ipykernel_37668\\1994683909.py:12: SyntaxWarning: invalid escape sequence '\\g'\n",
      "  glove_file = 'goolove\\glove.6B.300d.txt'\n"
     ]
    }
   ],
   "source": [
    "def load_glove_embeddings(glove_file):\n",
    "    embeddings_index = {}\n",
    "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    return embeddings_index\n",
    "\n",
    "# Load GloVe embeddings\n",
    "glove_file = 'goolove\\glove.6B.300d.txt'\n",
    "glove_model = load_glove_embeddings(glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackGANDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, img_size=(64, 64), glove_model=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        self.img_size = img_size\n",
    "        self.glove_model = glove_model\n",
    "\n",
    "        for subdir in os.listdir(root_dir):\n",
    "            subdir_path = os.path.join(root_dir, subdir)\n",
    "            if os.path.isdir(subdir_path):\n",
    "                try:\n",
    "                    img_file = [f for f in os.listdir(subdir_path) if f.endswith('.jpg')][0]\n",
    "                    txt_file = [f for f in os.listdir(subdir_path) if f.endswith('.txt')][0]\n",
    "                    self.data.append((os.path.join(subdir_path, img_file), os.path.join(subdir_path, txt_file)))\n",
    "                except IndexError as e:\n",
    "                    print(f\"Error: {e}, in directory {subdir_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Unexpected error: {e}, in directory {subdir_path}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_path, txt_path = self.data[idx]\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "            image = image.resize(self.img_size)  # Resize the image\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "            with open(txt_path, 'r') as f:\n",
    "                text = f.read().strip()\n",
    "\n",
    "            text_embedding = self.text_to_embedding(text)\n",
    "            return image, text_embedding\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading item at index {idx}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def text_to_embedding(self, text):\n",
    "        words = word_tokenize(text.lower())\n",
    "        embeddings = [self.glove_model[word] for word in words if word in self.glove_model]\n",
    "        if embeddings:\n",
    "            text_embedding = np.mean(embeddings, axis=0)\n",
    "        else:\n",
    "            text_embedding = np.zeros(len(next(iter(self.glove_model.values()))))\n",
    "        return text_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # for Stage-I\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = StackGANDataset('stackgan_input', transform=transform, img_size=(128, 128), glove_model=glove_model)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=0)  # Changed num_workers to 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConditionalAugmentation(nn.Module):\n",
    "    def __init__(self, text_dim, projected_dim):\n",
    "        super(ConditionalAugmentation, self).__init__()\n",
    "        self.proj = nn.Linear(text_dim, projected_dim * 2)\n",
    "\n",
    "    def forward(self, text_embedding):\n",
    "        mu_logvar = self.proj(text_embedding)\n",
    "        mu, logvar = mu_logvar.chunk(2, dim=1)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "class Generator_Stage1(nn.Module):\n",
    "    def __init__(self, noise_dim, text_dim, projected_dim):\n",
    "        super(Generator_Stage1, self).__init__()\n",
    "        self.ca = ConditionalAugmentation(text_dim, projected_dim)\n",
    "        self.fc = nn.Linear(noise_dim + projected_dim, 256 * 4 * 4)\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1), # output: 8x8\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1), # output: 16x16\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1), # output: 32x32\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 3, 4, 2, 1), # output: 64x64\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, text_embedding):\n",
    "        cond_code = self.ca(text_embedding)\n",
    "        z = torch.cat([noise, cond_code], dim=1)\n",
    "        out = self.fc(z)\n",
    "        out = out.view(-1, 256, 4, 4)\n",
    "        out = self.main(out)\n",
    "        return out\n",
    "\n",
    "class Discriminator_Stage1(nn.Module):\n",
    "    def __init__(self, text_dim):\n",
    "        super(Discriminator_Stage1, self).__init__()\n",
    "        self.img_encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        self.text_proj = nn.Linear(text_dim, 256)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),  # Changed kernel size to 3\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, 4, 1, 0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img, text_embedding):\n",
    "        noise = torch.randn_like(img) * 0.1  # Add small noise to images\n",
    "        img_features = self.img_encoder(img + noise)\n",
    "        # img_features = self.img_encoder(img)\n",
    "        text_features = self.text_proj(text_embedding)\n",
    "\n",
    "        text_features = text_features.view(-1, 256, 1, 1)\n",
    "        text_features = text_features.repeat(1, 1, img_features.size(2), img_features.size(3))\n",
    "\n",
    "        features = torch.cat([img_features, text_features], dim=1)\n",
    "        out = self.classifier(features)\n",
    "        \n",
    "        # Average over the spatial dimensions\n",
    "        out = out.view(out.size(0), -1).mean(dim=1, keepdim=True)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model initialization\n",
    "noise_dim = 100\n",
    "projected_dim = 128\n",
    "text_dim = 300\n",
    "\n",
    "netG1 = Generator_Stage1(noise_dim, text_dim, projected_dim)\n",
    "netD1 = Discriminator_Stage1(text_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator_Stage1(\n",
       "  (img_encoder): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (text_proj): Linear(in_features=300, out_features=256, bias=True)\n",
       "  (classifier): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (3): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (4): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimizers\n",
    "optimizerD1 = optim.Adam(netD1.parameters(), lr=0.00004, betas=(0.5, 0.999))\n",
    "optimizerG1 = optim.Adam(netG1.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "# Loss function\n",
    "# criterion = nn.BCELoss()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "netG1.to(device)\n",
    "netD1.to(device)\n",
    "# criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hardi\\AppData\\Local\\Temp\\ipykernel_37668\\3363272463.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  text_embeddings = torch.tensor(text_embeddings, dtype=torch.float32).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Batch [1/469] Loss D: -0.40161705017089844, loss G: -0.24863529205322266\n",
      "Epoch [1/10] Batch [2/469] Loss D: -0.37660855054855347, loss G: -0.11486691981554031\n",
      "Epoch [1/10] Batch [3/469] Loss D: -0.38887912034988403, loss G: -0.187670037150383\n",
      "Epoch [1/10] Batch [4/469] Loss D: -0.35497623682022095, loss G: -0.25086838006973267\n",
      "Epoch [1/10] Batch [5/469] Loss D: -0.29792386293411255, loss G: -0.13597102463245392\n",
      "Epoch [1/10] Batch [6/469] Loss D: -0.2904597520828247, loss G: -0.22203028202056885\n",
      "Epoch [1/10] Batch [7/469] Loss D: -0.36134710907936096, loss G: -0.1591770350933075\n",
      "Epoch [1/10] Batch [8/469] Loss D: -0.34976255893707275, loss G: -0.10442692041397095\n",
      "Epoch [1/10] Batch [9/469] Loss D: -0.4185994863510132, loss G: -0.22135594487190247\n",
      "Epoch [1/10] Batch [10/469] Loss D: -0.4643121361732483, loss G: -0.12373197078704834\n",
      "Epoch [1/10] Batch [11/469] Loss D: -0.4379749596118927, loss G: -0.2481486201286316\n",
      "Epoch [1/10] Batch [12/469] Loss D: -0.430651992559433, loss G: -0.06117648258805275\n",
      "Epoch [1/10] Batch [13/469] Loss D: -0.45564335584640503, loss G: -0.3583104610443115\n",
      "Epoch [1/10] Batch [14/469] Loss D: -0.328274667263031, loss G: -0.14749804139137268\n",
      "Epoch [1/10] Batch [15/469] Loss D: -0.30227774381637573, loss G: -0.12466011941432953\n",
      "Epoch [1/10] Batch [16/469] Loss D: -0.24217131733894348, loss G: -0.29991212487220764\n",
      "Epoch [1/10] Batch [17/469] Loss D: -0.1528293490409851, loss G: -0.30652230978012085\n",
      "Epoch [1/10] Batch [18/469] Loss D: -0.21038281917572021, loss G: -0.11672694236040115\n",
      "Epoch [1/10] Batch [19/469] Loss D: -0.1924055516719818, loss G: -0.2554280161857605\n",
      "Epoch [1/10] Batch [20/469] Loss D: -0.13751643896102905, loss G: -0.23546648025512695\n",
      "Epoch [1/10] Batch [21/469] Loss D: -0.2097700834274292, loss G: -0.25110647082328796\n",
      "Epoch [1/10] Batch [22/469] Loss D: -0.2679426670074463, loss G: -0.24202772974967957\n",
      "Epoch [1/10] Batch [23/469] Loss D: -0.26783692836761475, loss G: -0.3012905418872833\n",
      "Epoch [1/10] Batch [24/469] Loss D: -0.27987727522850037, loss G: -0.16396194696426392\n",
      "Epoch [1/10] Batch [25/469] Loss D: -0.32014358043670654, loss G: -0.2148447334766388\n",
      "Epoch [1/10] Batch [26/469] Loss D: -0.2672334909439087, loss G: -0.3762529194355011\n",
      "Epoch [1/10] Batch [27/469] Loss D: -0.287539541721344, loss G: -0.15083515644073486\n",
      "Epoch [1/10] Batch [28/469] Loss D: -0.19179433584213257, loss G: -0.2656013071537018\n",
      "Epoch [1/10] Batch [29/469] Loss D: -0.1977219581604004, loss G: -0.38111424446105957\n",
      "Epoch [1/10] Batch [30/469] Loss D: -0.26627641916275024, loss G: -0.29152482748031616\n",
      "Epoch [1/10] Batch [31/469] Loss D: -0.3056623041629791, loss G: -0.11426975578069687\n",
      "Epoch [1/10] Batch [32/469] Loss D: -0.2658521831035614, loss G: -0.26355668902397156\n",
      "Epoch [1/10] Batch [33/469] Loss D: -0.33075371384620667, loss G: -0.22243860363960266\n",
      "Epoch [1/10] Batch [34/469] Loss D: -0.3906097412109375, loss G: -0.1995307207107544\n",
      "Epoch [1/10] Batch [35/469] Loss D: -0.4235648810863495, loss G: -0.18467363715171814\n",
      "Epoch [1/10] Batch [36/469] Loss D: -0.3039695918560028, loss G: -0.1833265721797943\n",
      "Epoch [1/10] Batch [37/469] Loss D: -0.41265618801116943, loss G: -0.386651873588562\n",
      "Epoch [1/10] Batch [38/469] Loss D: -0.22611218690872192, loss G: -0.19680361449718475\n",
      "Epoch [1/10] Batch [39/469] Loss D: -0.2981353998184204, loss G: -0.1400204300880432\n",
      "Epoch [1/10] Batch [40/469] Loss D: -0.3349473476409912, loss G: -0.40589284896850586\n",
      "Epoch [1/10] Batch [41/469] Loss D: -0.232918381690979, loss G: -0.17044883966445923\n",
      "Epoch [1/10] Batch [42/469] Loss D: -0.2615804076194763, loss G: -0.15860234200954437\n",
      "Epoch [1/10] Batch [43/469] Loss D: -0.35435545444488525, loss G: -0.36517107486724854\n",
      "Epoch [1/10] Batch [44/469] Loss D: -0.2600066661834717, loss G: -0.12882238626480103\n",
      "Epoch [1/10] Batch [45/469] Loss D: -0.3131847679615021, loss G: -0.2527981698513031\n",
      "Epoch [1/10] Batch [46/469] Loss D: -0.342329740524292, loss G: -0.28029727935791016\n",
      "Epoch [1/10] Batch [47/469] Loss D: -0.3359142243862152, loss G: -0.1755332052707672\n",
      "Epoch [1/10] Batch [48/469] Loss D: -0.3681192994117737, loss G: -0.299458384513855\n",
      "Epoch [1/10] Batch [49/469] Loss D: -0.2897704839706421, loss G: -0.19865339994430542\n",
      "Epoch [1/10] Batch [50/469] Loss D: -0.3097257614135742, loss G: -0.19463813304901123\n",
      "Epoch [1/10] Batch [51/469] Loss D: -0.4211828112602234, loss G: -0.2716364562511444\n",
      "Epoch [1/10] Batch [52/469] Loss D: -0.37088173627853394, loss G: -0.18190842866897583\n",
      "Epoch [1/10] Batch [53/469] Loss D: -0.47373172640800476, loss G: -0.16688168048858643\n",
      "Epoch [1/10] Batch [54/469] Loss D: -0.49073126912117004, loss G: -0.17397654056549072\n",
      "Epoch [1/10] Batch [55/469] Loss D: -0.45265862345695496, loss G: -0.1926897019147873\n",
      "Epoch [1/10] Batch [56/469] Loss D: -0.4169079065322876, loss G: -0.1406310498714447\n",
      "Epoch [1/10] Batch [57/469] Loss D: -0.3674898147583008, loss G: -0.5013993382453918\n",
      "Epoch [1/10] Batch [58/469] Loss D: -0.2017453908920288, loss G: -0.23685206472873688\n",
      "Epoch [1/10] Batch [59/469] Loss D: -0.3179796636104584, loss G: -0.09442976117134094\n",
      "Epoch [1/10] Batch [60/469] Loss D: -0.2899787425994873, loss G: -0.3779938519001007\n",
      "Epoch [1/10] Batch [61/469] Loss D: -0.24238502979278564, loss G: -0.22673343122005463\n",
      "Epoch [1/10] Batch [62/469] Loss D: -0.2717030644416809, loss G: -0.1617823839187622\n",
      "Epoch [1/10] Batch [63/469] Loss D: -0.36781126260757446, loss G: -0.32815396785736084\n",
      "Epoch [1/10] Batch [64/469] Loss D: -0.3102511167526245, loss G: -0.06891442835330963\n",
      "Epoch [1/10] Batch [65/469] Loss D: -0.30672183632850647, loss G: -0.3662377595901489\n",
      "Epoch [1/10] Batch [66/469] Loss D: -0.2687019109725952, loss G: -0.23291856050491333\n",
      "Epoch [1/10] Batch [67/469] Loss D: -0.21342885494232178, loss G: -0.24614760279655457\n",
      "Epoch [1/10] Batch [68/469] Loss D: -0.25960439443588257, loss G: -0.2756316661834717\n",
      "Epoch [1/10] Batch [69/469] Loss D: -0.2309594452381134, loss G: -0.33342796564102173\n",
      "Epoch [1/10] Batch [70/469] Loss D: -0.13296347856521606, loss G: -0.3560110628604889\n",
      "Epoch [1/10] Batch [71/469] Loss D: -0.14965331554412842, loss G: -0.2644769549369812\n",
      "Epoch [1/10] Batch [72/469] Loss D: -0.19570252299308777, loss G: -0.27651557326316833\n",
      "Epoch [1/10] Batch [73/469] Loss D: -0.23686429858207703, loss G: -0.264191597700119\n",
      "Epoch [1/10] Batch [74/469] Loss D: -0.3009675443172455, loss G: -0.29655808210372925\n",
      "Epoch [1/10] Batch [75/469] Loss D: -0.2640044391155243, loss G: -0.22930270433425903\n",
      "Epoch [1/10] Batch [76/469] Loss D: -0.324226051568985, loss G: -0.22511357069015503\n",
      "Epoch [1/10] Batch [77/469] Loss D: -0.3241736888885498, loss G: -0.2148580551147461\n",
      "Epoch [1/10] Batch [78/469] Loss D: -0.2898640036582947, loss G: -0.2274026721715927\n",
      "Epoch [1/10] Batch [79/469] Loss D: -0.2593228816986084, loss G: -0.31338804960250854\n",
      "Epoch [1/10] Batch [80/469] Loss D: -0.30044686794281006, loss G: -0.11634647846221924\n",
      "Epoch [1/10] Batch [81/469] Loss D: -0.3498837351799011, loss G: -0.285011887550354\n",
      "Epoch [1/10] Batch [82/469] Loss D: -0.24214136600494385, loss G: -0.2132633477449417\n",
      "Epoch [1/10] Batch [83/469] Loss D: -0.2501511871814728, loss G: -0.15170973539352417\n",
      "Epoch [1/10] Batch [84/469] Loss D: -0.25615373253822327, loss G: -0.282804399728775\n",
      "Epoch [1/10] Batch [85/469] Loss D: -0.26445138454437256, loss G: -0.23726093769073486\n",
      "Epoch [1/10] Batch [86/469] Loss D: -0.20437860488891602, loss G: -0.2047039270401001\n",
      "Epoch [1/10] Batch [87/469] Loss D: -0.2289997935295105, loss G: -0.24415375292301178\n",
      "Epoch [1/10] Batch [88/469] Loss D: -0.28836894035339355, loss G: -0.25970879197120667\n",
      "Epoch [1/10] Batch [89/469] Loss D: -0.3037031888961792, loss G: -0.10128243267536163\n",
      "Epoch [1/10] Batch [90/469] Loss D: -0.3074818253517151, loss G: -0.28911885619163513\n",
      "Epoch [1/10] Batch [91/469] Loss D: -0.31769850850105286, loss G: -0.10650937259197235\n",
      "Epoch [1/10] Batch [92/469] Loss D: -0.3545052707195282, loss G: -0.38605690002441406\n",
      "Epoch [1/10] Batch [93/469] Loss D: -0.2883899211883545, loss G: -0.1576431691646576\n",
      "Epoch [1/10] Batch [94/469] Loss D: -0.2611995041370392, loss G: -0.15129724144935608\n",
      "Epoch [1/10] Batch [95/469] Loss D: -0.35173332691192627, loss G: -0.3366174101829529\n",
      "Epoch [1/10] Batch [96/469] Loss D: -0.26841819286346436, loss G: -0.2182566225528717\n",
      "Epoch [1/10] Batch [97/469] Loss D: -0.3323085904121399, loss G: -0.18039794266223907\n",
      "Epoch [1/10] Batch [98/469] Loss D: -0.35294973850250244, loss G: -0.28604188561439514\n",
      "Epoch [1/10] Batch [99/469] Loss D: -0.22770875692367554, loss G: -0.19359594583511353\n",
      "Epoch [1/10] Batch [100/469] Loss D: -0.2793624997138977, loss G: -0.2782772183418274\n",
      "Epoch [1/10] Batch [101/469] Loss D: -0.19732004404067993, loss G: -0.24566209316253662\n",
      "Epoch [1/10] Batch [102/469] Loss D: -0.1513332724571228, loss G: -0.23038621246814728\n",
      "Epoch [1/10] Batch [103/469] Loss D: -0.21037328243255615, loss G: -0.24908535182476044\n",
      "Epoch [1/10] Batch [104/469] Loss D: -0.279235303401947, loss G: -0.20109054446220398\n",
      "Epoch [1/10] Batch [105/469] Loss D: -0.29885298013687134, loss G: -0.26245665550231934\n",
      "Epoch [1/10] Batch [106/469] Loss D: -0.30087369680404663, loss G: -0.12456704676151276\n",
      "Epoch [1/10] Batch [107/469] Loss D: -0.3457263708114624, loss G: -0.21368519961833954\n",
      "Epoch [1/10] Batch [108/469] Loss D: -0.37709125876426697, loss G: -0.25478044152259827\n",
      "Epoch [1/10] Batch [109/469] Loss D: -0.27693647146224976, loss G: -0.16662994027137756\n",
      "Epoch [1/10] Batch [110/469] Loss D: -0.28390827775001526, loss G: -0.20128698647022247\n",
      "Epoch [1/10] Batch [111/469] Loss D: -0.19572877883911133, loss G: -0.41782346367836\n",
      "Epoch [1/10] Batch [112/469] Loss D: -0.16940277814865112, loss G: -0.3270721733570099\n",
      "Epoch [1/10] Batch [113/469] Loss D: -0.20164746046066284, loss G: -0.20748986303806305\n",
      "Epoch [1/10] Batch [114/469] Loss D: -0.26541006565093994, loss G: -0.26401007175445557\n",
      "Epoch [1/10] Batch [115/469] Loss D: -0.21377018094062805, loss G: -0.3489258289337158\n",
      "Epoch [1/10] Batch [116/469] Loss D: -0.19626063108444214, loss G: -0.3838077187538147\n",
      "Epoch [1/10] Batch [117/469] Loss D: -0.11355417966842651, loss G: -0.4061344861984253\n",
      "Epoch [1/10] Batch [118/469] Loss D: -0.12565875053405762, loss G: -0.46573737263679504\n",
      "Epoch [1/10] Batch [119/469] Loss D: -0.13759994506835938, loss G: -0.4156458377838135\n",
      "Epoch [1/10] Batch [120/469] Loss D: -0.12805557250976562, loss G: -0.43953996896743774\n",
      "Epoch [1/10] Batch [121/469] Loss D: -0.10634583234786987, loss G: -0.5021452307701111\n",
      "Epoch [1/10] Batch [122/469] Loss D: -0.13943010568618774, loss G: -0.4741092324256897\n",
      "Epoch [1/10] Batch [123/469] Loss D: -0.09610134363174438, loss G: -0.5135097503662109\n",
      "Epoch [1/10] Batch [124/469] Loss D: -0.15417742729187012, loss G: -0.5286732912063599\n",
      "Epoch [1/10] Batch [125/469] Loss D: -0.08746236562728882, loss G: -0.5513523817062378\n",
      "Epoch [1/10] Batch [126/469] Loss D: -0.1678304672241211, loss G: -0.3927130103111267\n",
      "Epoch [1/10] Batch [127/469] Loss D: -0.17504379153251648, loss G: -0.27125489711761475\n",
      "Epoch [1/10] Batch [128/469] Loss D: -0.189378023147583, loss G: -0.26684531569480896\n",
      "Epoch [1/10] Batch [129/469] Loss D: -0.2879716455936432, loss G: -0.271837055683136\n",
      "Epoch [1/10] Batch [130/469] Loss D: -0.24239128828048706, loss G: -0.2967106103897095\n",
      "Epoch [1/10] Batch [131/469] Loss D: -0.23577937483787537, loss G: -0.29252099990844727\n",
      "Epoch [1/10] Batch [132/469] Loss D: -0.22361615300178528, loss G: -0.39528265595436096\n",
      "Epoch [1/10] Batch [133/469] Loss D: -0.18548047542572021, loss G: -0.4553755223751068\n",
      "Epoch [1/10] Batch [134/469] Loss D: -0.16593921184539795, loss G: -0.3535669445991516\n",
      "Epoch [1/10] Batch [135/469] Loss D: -0.12761181592941284, loss G: -0.301445335149765\n",
      "Epoch [1/10] Batch [136/469] Loss D: -0.21239376068115234, loss G: -0.28020626306533813\n",
      "Epoch [1/10] Batch [137/469] Loss D: -0.28194767236709595, loss G: -0.2168571650981903\n",
      "Epoch [1/10] Batch [138/469] Loss D: -0.24400806427001953, loss G: -0.18044567108154297\n",
      "Epoch [1/10] Batch [139/469] Loss D: -0.25994688272476196, loss G: -0.22149799764156342\n",
      "Epoch [1/10] Batch [140/469] Loss D: -0.3880729079246521, loss G: -0.23024623095989227\n",
      "Epoch [1/10] Batch [141/469] Loss D: -0.42160966992378235, loss G: -0.1097426638007164\n",
      "Epoch [1/10] Batch [142/469] Loss D: -0.3051789104938507, loss G: -0.2844754457473755\n",
      "Epoch [1/10] Batch [143/469] Loss D: -0.3908064365386963, loss G: -0.1479082703590393\n",
      "Epoch [1/10] Batch [144/469] Loss D: -0.4003662168979645, loss G: -0.197560653090477\n",
      "Epoch [1/10] Batch [145/469] Loss D: -0.33045271039009094, loss G: -0.177928164601326\n",
      "Epoch [1/10] Batch [146/469] Loss D: -0.35863015055656433, loss G: -0.23427912592887878\n",
      "Epoch [1/10] Batch [147/469] Loss D: -0.26728159189224243, loss G: -0.1422019898891449\n",
      "Epoch [1/10] Batch [148/469] Loss D: -0.26717424392700195, loss G: -0.22904250025749207\n",
      "Epoch [1/10] Batch [149/469] Loss D: -0.366389662027359, loss G: -0.27908065915107727\n",
      "Epoch [1/10] Batch [150/469] Loss D: -0.22630977630615234, loss G: -0.19000953435897827\n",
      "Epoch [1/10] Batch [151/469] Loss D: -0.31455197930336, loss G: -0.23817932605743408\n",
      "Epoch [1/10] Batch [152/469] Loss D: -0.22090601921081543, loss G: -0.1552337408065796\n",
      "Epoch [1/10] Batch [153/469] Loss D: -0.24864032864570618, loss G: -0.20061221718788147\n",
      "Epoch [1/10] Batch [154/469] Loss D: -0.2742915153503418, loss G: -0.35198119282722473\n",
      "Epoch [1/10] Batch [155/469] Loss D: -0.23465001583099365, loss G: -0.20528997480869293\n",
      "Epoch [1/10] Batch [156/469] Loss D: -0.3234528601169586, loss G: -0.1600630283355713\n",
      "Epoch [1/10] Batch [157/469] Loss D: -0.2963583171367645, loss G: -0.39527779817581177\n",
      "Epoch [1/10] Batch [158/469] Loss D: -0.31788498163223267, loss G: -0.18661904335021973\n",
      "Epoch [1/10] Batch [159/469] Loss D: -0.36217600107192993, loss G: -0.162657231092453\n",
      "Epoch [1/10] Batch [160/469] Loss D: -0.29926055669784546, loss G: -0.3160841166973114\n",
      "Epoch [1/10] Batch [161/469] Loss D: -0.28864023089408875, loss G: -0.1457856297492981\n",
      "Epoch [1/10] Batch [162/469] Loss D: -0.2900254428386688, loss G: -0.19894766807556152\n",
      "Epoch [1/10] Batch [163/469] Loss D: -0.2778719663619995, loss G: -0.31918907165527344\n",
      "Epoch [1/10] Batch [164/469] Loss D: -0.2790554165840149, loss G: -0.1993173211812973\n",
      "Epoch [1/10] Batch [165/469] Loss D: -0.12742900848388672, loss G: -0.31774652004241943\n",
      "Epoch [1/10] Batch [166/469] Loss D: -0.06441089510917664, loss G: -0.37777456641197205\n",
      "Epoch [1/10] Batch [167/469] Loss D: -0.12258517742156982, loss G: -0.35294851660728455\n",
      "Epoch [1/10] Batch [168/469] Loss D: -0.09987092018127441, loss G: -0.38424718379974365\n",
      "Epoch [1/10] Batch [169/469] Loss D: -0.16025975346565247, loss G: -0.30174070596694946\n",
      "Epoch [1/10] Batch [170/469] Loss D: -0.19881942868232727, loss G: -0.2650686502456665\n",
      "Epoch [1/10] Batch [171/469] Loss D: -0.21255001425743103, loss G: -0.3622317910194397\n",
      "Epoch [1/10] Batch [172/469] Loss D: -0.24551540613174438, loss G: -0.29582202434539795\n",
      "Epoch [1/10] Batch [173/469] Loss D: -0.28343716263771057, loss G: -0.2032078504562378\n",
      "Epoch [1/10] Batch [174/469] Loss D: -0.2811965346336365, loss G: -0.21563883125782013\n",
      "Epoch [1/10] Batch [175/469] Loss D: -0.28346550464630127, loss G: -0.337467223405838\n",
      "Epoch [1/10] Batch [176/469] Loss D: -0.26835155487060547, loss G: -0.21173331141471863\n",
      "Epoch [1/10] Batch [177/469] Loss D: -0.2547904849052429, loss G: -0.17746524512767792\n",
      "Epoch [1/10] Batch [178/469] Loss D: -0.10656160116195679, loss G: -0.25513625144958496\n",
      "Epoch [1/10] Batch [179/469] Loss D: -0.16364431381225586, loss G: -0.29391199350357056\n",
      "Epoch [1/10] Batch [180/469] Loss D: -0.22035625576972961, loss G: -0.3931276798248291\n",
      "Epoch [1/10] Batch [181/469] Loss D: -0.18423670530319214, loss G: -0.37816983461380005\n",
      "Epoch [1/10] Batch [182/469] Loss D: -0.1471540927886963, loss G: -0.2947164475917816\n",
      "Epoch [1/10] Batch [183/469] Loss D: -0.09949234127998352, loss G: -0.29191485047340393\n",
      "Epoch [1/10] Batch [184/469] Loss D: -0.11896771192550659, loss G: -0.2715896964073181\n",
      "Epoch [1/10] Batch [185/469] Loss D: -0.1670011579990387, loss G: -0.33623969554901123\n",
      "Epoch [1/10] Batch [186/469] Loss D: -0.17470204830169678, loss G: -0.32353997230529785\n",
      "Epoch [1/10] Batch [187/469] Loss D: -0.126428484916687, loss G: -0.3435311019420624\n",
      "Epoch [1/10] Batch [188/469] Loss D: -0.22973281145095825, loss G: -0.21972855925559998\n",
      "Epoch [1/10] Batch [189/469] Loss D: -0.24245822429656982, loss G: -0.21671000123023987\n",
      "Epoch [1/10] Batch [190/469] Loss D: -0.3218660354614258, loss G: -0.30296629667282104\n",
      "Epoch [1/10] Batch [191/469] Loss D: -0.21468576788902283, loss G: -0.2935514450073242\n",
      "Epoch [1/10] Batch [192/469] Loss D: -0.30137136578559875, loss G: -0.23625721037387848\n",
      "Epoch [1/10] Batch [193/469] Loss D: -0.3063901364803314, loss G: -0.2036615014076233\n",
      "Epoch [1/10] Batch [194/469] Loss D: -0.2828814387321472, loss G: -0.36254239082336426\n",
      "Epoch [1/10] Batch [195/469] Loss D: -0.19915801286697388, loss G: -0.3109844923019409\n",
      "Epoch [1/10] Batch [196/469] Loss D: -0.19607064127922058, loss G: -0.2019934356212616\n",
      "Epoch [1/10] Batch [197/469] Loss D: -0.2638278007507324, loss G: -0.2122284173965454\n",
      "Epoch [1/10] Batch [198/469] Loss D: -0.33208656311035156, loss G: -0.30690762400627136\n",
      "Epoch [1/10] Batch [199/469] Loss D: -0.2745724320411682, loss G: -0.23326963186264038\n",
      "Epoch [1/10] Batch [200/469] Loss D: -0.2075052261352539, loss G: -0.24443238973617554\n",
      "Epoch [1/10] Batch [201/469] Loss D: -0.20364123582839966, loss G: -0.2507215738296509\n",
      "Epoch [1/10] Batch [202/469] Loss D: -0.19027113914489746, loss G: -0.319365918636322\n",
      "Epoch [1/10] Batch [203/469] Loss D: -0.1818508505821228, loss G: -0.4072825312614441\n",
      "Epoch [1/10] Batch [204/469] Loss D: -0.07239389419555664, loss G: -0.3886614143848419\n",
      "Epoch [1/10] Batch [205/469] Loss D: -0.16975590586662292, loss G: -0.3074802756309509\n",
      "Epoch [1/10] Batch [206/469] Loss D: -0.19515612721443176, loss G: -0.32005518674850464\n",
      "Epoch [1/10] Batch [207/469] Loss D: -0.1646289825439453, loss G: -0.3622676134109497\n",
      "Epoch [1/10] Batch [208/469] Loss D: -0.1361464262008667, loss G: -0.39830338954925537\n",
      "Epoch [1/10] Batch [209/469] Loss D: -0.16337084770202637, loss G: -0.43478089570999146\n",
      "Epoch [1/10] Batch [210/469] Loss D: -0.17568141222000122, loss G: -0.33303147554397583\n",
      "Epoch [1/10] Batch [211/469] Loss D: -0.21960791945457458, loss G: -0.30828776955604553\n",
      "Epoch [1/10] Batch [212/469] Loss D: -0.22670477628707886, loss G: -0.31250113248825073\n",
      "Epoch [1/10] Batch [213/469] Loss D: -0.3027491569519043, loss G: -0.20765464007854462\n",
      "Epoch [1/10] Batch [214/469] Loss D: -0.3027106523513794, loss G: -0.2382756620645523\n",
      "Epoch [1/10] Batch [215/469] Loss D: -0.2967309057712555, loss G: -0.21231864392757416\n",
      "Epoch [1/10] Batch [216/469] Loss D: -0.2505834102630615, loss G: -0.2777125835418701\n",
      "Epoch [1/10] Batch [217/469] Loss D: -0.23755398392677307, loss G: -0.2498052567243576\n",
      "Epoch [1/10] Batch [218/469] Loss D: -0.19982314109802246, loss G: -0.26323747634887695\n",
      "Epoch [1/10] Batch [219/469] Loss D: -0.24833202362060547, loss G: -0.23246003687381744\n",
      "Epoch [1/10] Batch [220/469] Loss D: -0.2153778374195099, loss G: -0.2857735753059387\n",
      "Epoch [1/10] Batch [221/469] Loss D: -0.16882407665252686, loss G: -0.35527503490448\n",
      "Epoch [1/10] Batch [222/469] Loss D: -0.11097568273544312, loss G: -0.3127084970474243\n",
      "Epoch [1/10] Batch [223/469] Loss D: -0.20344418287277222, loss G: -0.19565273821353912\n",
      "Epoch [1/10] Batch [224/469] Loss D: -0.18291893601417542, loss G: -0.26607513427734375\n",
      "Epoch [1/10] Batch [225/469] Loss D: -0.23027551174163818, loss G: -0.3088996410369873\n",
      "Epoch [1/10] Batch [226/469] Loss D: -0.1784420609474182, loss G: -0.38149386644363403\n",
      "Epoch [1/10] Batch [227/469] Loss D: -0.2539481520652771, loss G: -0.26240092515945435\n",
      "Epoch [1/10] Batch [228/469] Loss D: -0.26580914855003357, loss G: -0.29972267150878906\n",
      "Epoch [1/10] Batch [229/469] Loss D: -0.18468785285949707, loss G: -0.2751550078392029\n",
      "Epoch [1/10] Batch [230/469] Loss D: -0.2351483404636383, loss G: -0.17143937945365906\n",
      "Epoch [1/10] Batch [231/469] Loss D: -0.16119778156280518, loss G: -0.24693332612514496\n",
      "Epoch [1/10] Batch [232/469] Loss D: -0.286617636680603, loss G: -0.24445731937885284\n",
      "Epoch [1/10] Batch [233/469] Loss D: -0.21979868412017822, loss G: -0.42634767293930054\n",
      "Epoch [1/10] Batch [234/469] Loss D: -0.26396456360816956, loss G: -0.287447988986969\n",
      "Epoch [1/10] Batch [235/469] Loss D: -0.2475055754184723, loss G: -0.2351921796798706\n",
      "Epoch [1/10] Batch [236/469] Loss D: -0.2518364191055298, loss G: -0.21542701125144958\n",
      "Epoch [1/10] Batch [237/469] Loss D: -0.2398471236228943, loss G: -0.3005433976650238\n",
      "Epoch [1/10] Batch [238/469] Loss D: -0.2554677724838257, loss G: -0.19623678922653198\n",
      "Epoch [1/10] Batch [239/469] Loss D: -0.30917489528656006, loss G: -0.2822112441062927\n",
      "Epoch [1/10] Batch [240/469] Loss D: -0.2133028507232666, loss G: -0.23955067992210388\n",
      "Epoch [1/10] Batch [241/469] Loss D: -0.22973531484603882, loss G: -0.2887823283672333\n",
      "Epoch [1/10] Batch [242/469] Loss D: -0.20288169384002686, loss G: -0.26435112953186035\n",
      "Epoch [1/10] Batch [243/469] Loss D: -0.1266493797302246, loss G: -0.2763783037662506\n",
      "Epoch [1/10] Batch [244/469] Loss D: -0.20521098375320435, loss G: -0.2659527659416199\n",
      "Epoch [1/10] Batch [245/469] Loss D: -0.29453933238983154, loss G: -0.20637297630310059\n",
      "Epoch [1/10] Batch [246/469] Loss D: -0.36658668518066406, loss G: -0.2040078341960907\n",
      "Epoch [1/10] Batch [247/469] Loss D: -0.2726674973964691, loss G: -0.3037925064563751\n",
      "Epoch [1/10] Batch [248/469] Loss D: -0.3250778913497925, loss G: -0.2348027229309082\n",
      "Epoch [1/10] Batch [249/469] Loss D: -0.3551708161830902, loss G: -0.15419863164424896\n",
      "Epoch [1/10] Batch [250/469] Loss D: -0.29941946268081665, loss G: -0.3127557039260864\n",
      "Epoch [1/10] Batch [251/469] Loss D: -0.26570451259613037, loss G: -0.207760289311409\n",
      "Epoch [1/10] Batch [252/469] Loss D: -0.1724921464920044, loss G: -0.2605345845222473\n",
      "Epoch [1/10] Batch [253/469] Loss D: -0.1848609745502472, loss G: -0.318324476480484\n",
      "Epoch [1/10] Batch [254/469] Loss D: -0.21809428930282593, loss G: -0.2818524241447449\n",
      "Epoch [1/10] Batch [255/469] Loss D: -0.18019241094589233, loss G: -0.3648858070373535\n",
      "Epoch [1/10] Batch [256/469] Loss D: -0.1969040036201477, loss G: -0.37744104862213135\n",
      "Epoch [1/10] Batch [257/469] Loss D: -0.15325689315795898, loss G: -0.32571521401405334\n",
      "Epoch [1/10] Batch [258/469] Loss D: -0.1632806956768036, loss G: -0.34993958473205566\n",
      "Epoch [1/10] Batch [259/469] Loss D: -0.17164397239685059, loss G: -0.34819698333740234\n",
      "Epoch [1/10] Batch [260/469] Loss D: -0.10705238580703735, loss G: -0.25138190388679504\n",
      "Epoch [1/10] Batch [261/469] Loss D: -0.2110787034034729, loss G: -0.2602470815181732\n",
      "Epoch [1/10] Batch [262/469] Loss D: -0.1988322138786316, loss G: -0.3358737826347351\n",
      "Epoch [1/10] Batch [263/469] Loss D: -0.1950426697731018, loss G: -0.41917768120765686\n",
      "Epoch [1/10] Batch [264/469] Loss D: -0.21849822998046875, loss G: -0.3184391260147095\n",
      "Epoch [1/10] Batch [265/469] Loss D: -0.32028335332870483, loss G: -0.17993566393852234\n",
      "Epoch [1/10] Batch [266/469] Loss D: -0.24408572912216187, loss G: -0.270661324262619\n",
      "Epoch [1/10] Batch [267/469] Loss D: -0.23242217302322388, loss G: -0.32046061754226685\n",
      "Epoch [1/10] Batch [268/469] Loss D: -0.2661818265914917, loss G: -0.2796303629875183\n",
      "Epoch [1/10] Batch [269/469] Loss D: -0.2871260941028595, loss G: -0.21103408932685852\n",
      "Epoch [1/10] Batch [270/469] Loss D: -0.3690744638442993, loss G: -0.21195238828659058\n",
      "Epoch [1/10] Batch [271/469] Loss D: -0.29969775676727295, loss G: -0.2569725215435028\n",
      "Epoch [1/10] Batch [272/469] Loss D: -0.2774570882320404, loss G: -0.27735209465026855\n",
      "Epoch [1/10] Batch [273/469] Loss D: -0.3306925892829895, loss G: -0.14664575457572937\n",
      "Epoch [1/10] Batch [274/469] Loss D: -0.2553774416446686, loss G: -0.32130002975463867\n",
      "Epoch [1/10] Batch [275/469] Loss D: -0.2668738067150116, loss G: -0.2481880486011505\n",
      "Epoch [1/10] Batch [276/469] Loss D: -0.23690378665924072, loss G: -0.2726535201072693\n",
      "Epoch [1/10] Batch [277/469] Loss D: -0.15851935744285583, loss G: -0.32956168055534363\n",
      "Epoch [1/10] Batch [278/469] Loss D: -0.19370725750923157, loss G: -0.3879435360431671\n",
      "Epoch [1/10] Batch [279/469] Loss D: -0.16908422112464905, loss G: -0.3004574179649353\n",
      "Epoch [1/10] Batch [280/469] Loss D: -0.11378729343414307, loss G: -0.3462011516094208\n",
      "Epoch [1/10] Batch [281/469] Loss D: -0.13049045205116272, loss G: -0.3063150644302368\n",
      "Epoch [1/10] Batch [282/469] Loss D: -0.15063583850860596, loss G: -0.3456133306026459\n",
      "Epoch [1/10] Batch [283/469] Loss D: -0.17764869332313538, loss G: -0.31736084818840027\n",
      "Epoch [1/10] Batch [284/469] Loss D: -0.14319247007369995, loss G: -0.3618469536304474\n",
      "Epoch [1/10] Batch [285/469] Loss D: -0.2612757682800293, loss G: -0.2576245069503784\n",
      "Epoch [1/10] Batch [286/469] Loss D: -0.256382554769516, loss G: -0.2714391350746155\n",
      "Epoch [1/10] Batch [287/469] Loss D: -0.3029593825340271, loss G: -0.32971733808517456\n",
      "Epoch [1/10] Batch [288/469] Loss D: -0.2582482695579529, loss G: -0.2572326362133026\n",
      "Epoch [1/10] Batch [289/469] Loss D: -0.2329716682434082, loss G: -0.3154361844062805\n",
      "Epoch [1/10] Batch [290/469] Loss D: -0.2567159831523895, loss G: -0.3077511191368103\n",
      "Epoch [1/10] Batch [291/469] Loss D: -0.23637288808822632, loss G: -0.1767941564321518\n",
      "Epoch [1/10] Batch [292/469] Loss D: -0.23347355425357819, loss G: -0.24936476349830627\n",
      "Epoch [1/10] Batch [293/469] Loss D: -0.20984378457069397, loss G: -0.43464237451553345\n",
      "Epoch [1/10] Batch [294/469] Loss D: -0.2047552466392517, loss G: -0.34113067388534546\n",
      "Epoch [1/10] Batch [295/469] Loss D: -0.1245763897895813, loss G: -0.37441015243530273\n",
      "Epoch [1/10] Batch [296/469] Loss D: -0.17544448375701904, loss G: -0.30621498823165894\n",
      "Epoch [1/10] Batch [297/469] Loss D: -0.22184184193611145, loss G: -0.3485584855079651\n",
      "Epoch [1/10] Batch [298/469] Loss D: -0.1717197299003601, loss G: -0.36286789178848267\n",
      "Epoch [1/10] Batch [299/469] Loss D: -0.21619892120361328, loss G: -0.3380125164985657\n",
      "Epoch [1/10] Batch [300/469] Loss D: -0.1278529167175293, loss G: -0.31564152240753174\n",
      "Epoch [1/10] Batch [301/469] Loss D: -0.14403501152992249, loss G: -0.26749804615974426\n",
      "Epoch [1/10] Batch [302/469] Loss D: -0.2225322723388672, loss G: -0.3154357075691223\n",
      "Epoch [1/10] Batch [303/469] Loss D: -0.2600417733192444, loss G: -0.2791869640350342\n",
      "Epoch [1/10] Batch [304/469] Loss D: -0.2797955870628357, loss G: -0.24553556740283966\n",
      "Epoch [1/10] Batch [305/469] Loss D: -0.24817752838134766, loss G: -0.31026691198349\n",
      "Epoch [1/10] Batch [306/469] Loss D: -0.3203318119049072, loss G: -0.18795453011989594\n",
      "Epoch [1/10] Batch [307/469] Loss D: -0.3201955556869507, loss G: -0.22597739100456238\n",
      "Epoch [1/10] Batch [308/469] Loss D: -0.3041154444217682, loss G: -0.21927541494369507\n",
      "Epoch [1/10] Batch [309/469] Loss D: -0.35754531621932983, loss G: -0.14983931183815002\n",
      "Epoch [1/10] Batch [310/469] Loss D: -0.3171549439430237, loss G: -0.26897281408309937\n",
      "Epoch [1/10] Batch [311/469] Loss D: -0.29852095246315, loss G: -0.18590795993804932\n",
      "Epoch [1/10] Batch [312/469] Loss D: -0.2607722282409668, loss G: -0.25708746910095215\n",
      "Epoch [1/10] Batch [313/469] Loss D: -0.29516667127609253, loss G: -0.33773666620254517\n",
      "Epoch [1/10] Batch [314/469] Loss D: -0.19963040947914124, loss G: -0.23971714079380035\n",
      "Epoch [1/10] Batch [315/469] Loss D: -0.1268797516822815, loss G: -0.3178488612174988\n",
      "Epoch [1/10] Batch [316/469] Loss D: -0.16097423434257507, loss G: -0.3556317985057831\n",
      "Epoch [1/10] Batch [317/469] Loss D: -0.11822527647018433, loss G: -0.3714156448841095\n",
      "Epoch [1/10] Batch [318/469] Loss D: -0.18806123733520508, loss G: -0.3486296534538269\n",
      "Epoch [1/10] Batch [319/469] Loss D: -0.11988189816474915, loss G: -0.4134691059589386\n",
      "Epoch [1/10] Batch [320/469] Loss D: -0.1889784336090088, loss G: -0.2508646249771118\n",
      "Epoch [1/10] Batch [321/469] Loss D: -0.15698575973510742, loss G: -0.20600274205207825\n",
      "Epoch [1/10] Batch [322/469] Loss D: -0.15787184238433838, loss G: -0.27638548612594604\n",
      "Epoch [1/10] Batch [323/469] Loss D: -0.23686093091964722, loss G: -0.3373836278915405\n",
      "Epoch [1/10] Batch [324/469] Loss D: -0.13980752229690552, loss G: -0.4029529094696045\n",
      "Epoch [1/10] Batch [325/469] Loss D: -0.20948690176010132, loss G: -0.2762468457221985\n",
      "Epoch [1/10] Batch [326/469] Loss D: -0.1994737982749939, loss G: -0.33597230911254883\n",
      "Epoch [1/10] Batch [327/469] Loss D: -0.2959977388381958, loss G: -0.27082115411758423\n",
      "Epoch [1/10] Batch [328/469] Loss D: -0.2713015079498291, loss G: -0.2539701461791992\n",
      "Epoch [1/10] Batch [329/469] Loss D: -0.28851228952407837, loss G: -0.2897825241088867\n",
      "Epoch [1/10] Batch [330/469] Loss D: -0.2833811640739441, loss G: -0.2874787747859955\n",
      "Epoch [1/10] Batch [331/469] Loss D: -0.31527674198150635, loss G: -0.15706384181976318\n",
      "Epoch [1/10] Batch [332/469] Loss D: -0.3618033826351166, loss G: -0.2439865618944168\n",
      "Epoch [1/10] Batch [333/469] Loss D: -0.3218439519405365, loss G: -0.2707384526729584\n",
      "Epoch [1/10] Batch [334/469] Loss D: -0.31229257583618164, loss G: -0.22116538882255554\n",
      "Epoch [1/10] Batch [335/469] Loss D: -0.27578699588775635, loss G: -0.28232431411743164\n",
      "Epoch [1/10] Batch [336/469] Loss D: -0.2635691165924072, loss G: -0.24165524542331696\n",
      "Epoch [1/10] Batch [337/469] Loss D: -0.22137504816055298, loss G: -0.21484535932540894\n",
      "Epoch [1/10] Batch [338/469] Loss D: -0.1702863872051239, loss G: -0.2343921661376953\n",
      "Epoch [1/10] Batch [339/469] Loss D: -0.26059794425964355, loss G: -0.32413890957832336\n",
      "Epoch [1/10] Batch [340/469] Loss D: -0.21217525005340576, loss G: -0.25016915798187256\n",
      "Epoch [1/10] Batch [341/469] Loss D: -0.22948795557022095, loss G: -0.17245478928089142\n",
      "Epoch [1/10] Batch [342/469] Loss D: -0.17538389563560486, loss G: -0.3048498332500458\n",
      "Epoch [1/10] Batch [343/469] Loss D: -0.09570237994194031, loss G: -0.4305175244808197\n",
      "Epoch [1/10] Batch [344/469] Loss D: -0.11343729496002197, loss G: -0.3792034387588501\n",
      "Epoch [1/10] Batch [345/469] Loss D: -0.13918182253837585, loss G: -0.3021772801876068\n",
      "Epoch [1/10] Batch [346/469] Loss D: -0.18627864122390747, loss G: -0.258483350276947\n",
      "Epoch [1/10] Batch [347/469] Loss D: -0.24881184101104736, loss G: -0.21848338842391968\n",
      "Epoch [1/10] Batch [348/469] Loss D: -0.2484409511089325, loss G: -0.2512989044189453\n",
      "Epoch [1/10] Batch [349/469] Loss D: -0.25043579936027527, loss G: -0.19126659631729126\n",
      "Epoch [1/10] Batch [350/469] Loss D: -0.33210161328315735, loss G: -0.2551273703575134\n",
      "Epoch [1/10] Batch [351/469] Loss D: -0.39213839173316956, loss G: -0.0958251953125\n",
      "Epoch [1/10] Batch [352/469] Loss D: -0.20664037764072418, loss G: -0.24917103350162506\n",
      "Epoch [1/10] Batch [353/469] Loss D: -0.27439042925834656, loss G: -0.2806512713432312\n",
      "Epoch [1/10] Batch [354/469] Loss D: -0.2670042812824249, loss G: -0.2015032172203064\n",
      "Epoch [1/10] Batch [355/469] Loss D: -0.1341124176979065, loss G: -0.2641550302505493\n",
      "Epoch [1/10] Batch [356/469] Loss D: -0.20433157682418823, loss G: -0.2977166175842285\n",
      "Epoch [1/10] Batch [357/469] Loss D: -0.0900840163230896, loss G: -0.36819127202033997\n",
      "Epoch [1/10] Batch [358/469] Loss D: -0.2745717763900757, loss G: -0.17060375213623047\n",
      "Epoch [1/10] Batch [359/469] Loss D: -0.2057802677154541, loss G: -0.30467158555984497\n",
      "Epoch [1/10] Batch [360/469] Loss D: -0.24297654628753662, loss G: -0.3463405966758728\n",
      "Epoch [1/10] Batch [361/469] Loss D: -0.30222180485725403, loss G: -0.17508834600448608\n",
      "Epoch [1/10] Batch [362/469] Loss D: -0.32523009181022644, loss G: -0.2478402554988861\n",
      "Epoch [1/10] Batch [363/469] Loss D: -0.3019179105758667, loss G: -0.264376163482666\n",
      "Epoch [1/10] Batch [364/469] Loss D: -0.3572927713394165, loss G: -0.20719656348228455\n",
      "Epoch [1/10] Batch [365/469] Loss D: -0.3406922221183777, loss G: -0.21423593163490295\n",
      "Epoch [1/10] Batch [366/469] Loss D: -0.20349711179733276, loss G: -0.31383103132247925\n",
      "Epoch [1/10] Batch [367/469] Loss D: -0.306155800819397, loss G: -0.17237208783626556\n",
      "Epoch [1/10] Batch [368/469] Loss D: -0.29158347845077515, loss G: -0.2322920858860016\n",
      "Epoch [1/10] Batch [369/469] Loss D: -0.2683357000350952, loss G: -0.3026793599128723\n",
      "Epoch [1/10] Batch [370/469] Loss D: -0.2004294991493225, loss G: -0.31560155749320984\n",
      "Epoch [1/10] Batch [371/469] Loss D: -0.15287157893180847, loss G: -0.3369622230529785\n",
      "Epoch [1/10] Batch [372/469] Loss D: -0.09084439277648926, loss G: -0.3214282989501953\n",
      "Epoch [1/10] Batch [373/469] Loss D: -0.18306705355644226, loss G: -0.19882601499557495\n",
      "Epoch [1/10] Batch [374/469] Loss D: -0.18515744805335999, loss G: -0.36067068576812744\n",
      "Epoch [1/10] Batch [375/469] Loss D: -0.12000393867492676, loss G: -0.4667988419532776\n",
      "Epoch [1/10] Batch [376/469] Loss D: -0.17998474836349487, loss G: -0.23993098735809326\n",
      "Epoch [1/10] Batch [377/469] Loss D: -0.13412132859230042, loss G: -0.25890594720840454\n",
      "Epoch [1/10] Batch [378/469] Loss D: -0.15262877941131592, loss G: -0.3385539650917053\n",
      "Epoch [1/10] Batch [379/469] Loss D: -0.2991311848163605, loss G: -0.2585805356502533\n",
      "Epoch [1/10] Batch [380/469] Loss D: -0.21667402982711792, loss G: -0.3223339915275574\n",
      "Epoch [1/10] Batch [381/469] Loss D: -0.20837286114692688, loss G: -0.1884450912475586\n",
      "Epoch [1/10] Batch [382/469] Loss D: -0.2390241026878357, loss G: -0.23192456364631653\n",
      "Epoch [1/10] Batch [383/469] Loss D: -0.2932615578174591, loss G: -0.3035265803337097\n",
      "Epoch [1/10] Batch [384/469] Loss D: -0.2708643674850464, loss G: -0.3189017176628113\n",
      "Epoch [1/10] Batch [385/469] Loss D: -0.25228452682495117, loss G: -0.2758740782737732\n",
      "Epoch [1/10] Batch [386/469] Loss D: -0.2333822250366211, loss G: -0.3019517660140991\n",
      "Epoch [1/10] Batch [387/469] Loss D: -0.10324066877365112, loss G: -0.38754093647003174\n",
      "Epoch [1/10] Batch [388/469] Loss D: -0.12514728307724, loss G: -0.4245688021183014\n",
      "Epoch [1/10] Batch [389/469] Loss D: -0.11661851406097412, loss G: -0.41877472400665283\n",
      "Epoch [1/10] Batch [390/469] Loss D: -0.16440588235855103, loss G: -0.3727492094039917\n",
      "Epoch [1/10] Batch [391/469] Loss D: -0.09125387668609619, loss G: -0.3152649998664856\n",
      "Epoch [1/10] Batch [392/469] Loss D: -0.09001287817955017, loss G: -0.34792906045913696\n",
      "Epoch [1/10] Batch [393/469] Loss D: -0.18409615755081177, loss G: -0.3650396168231964\n",
      "Epoch [1/10] Batch [394/469] Loss D: -0.22277432680130005, loss G: -0.333160400390625\n",
      "Epoch [1/10] Batch [395/469] Loss D: -0.2634009122848511, loss G: -0.3796297311782837\n",
      "Epoch [1/10] Batch [396/469] Loss D: -0.21684947609901428, loss G: -0.33984375\n",
      "Epoch [1/10] Batch [397/469] Loss D: -0.14480924606323242, loss G: -0.32601287961006165\n",
      "Epoch [1/10] Batch [398/469] Loss D: -0.08952760696411133, loss G: -0.3865036964416504\n",
      "Epoch [1/10] Batch [399/469] Loss D: -0.08465251326560974, loss G: -0.3897215723991394\n",
      "Epoch [1/10] Batch [400/469] Loss D: -0.10365039110183716, loss G: -0.34713345766067505\n",
      "Epoch [1/10] Batch [401/469] Loss D: -0.155037522315979, loss G: -0.22627203166484833\n",
      "Epoch [1/10] Batch [402/469] Loss D: -0.125875324010849, loss G: -0.22512492537498474\n",
      "Epoch [1/10] Batch [403/469] Loss D: -0.15516561269760132, loss G: -0.2987241744995117\n",
      "Epoch [1/10] Batch [404/469] Loss D: -0.1689852476119995, loss G: -0.31686872243881226\n",
      "Epoch [1/10] Batch [405/469] Loss D: -0.25721538066864014, loss G: -0.17933939397335052\n",
      "Epoch [1/10] Batch [406/469] Loss D: -0.22173672914505005, loss G: -0.1813395470380783\n",
      "Epoch [1/10] Batch [407/469] Loss D: -0.2597438097000122, loss G: -0.2939950227737427\n",
      "Epoch [1/10] Batch [408/469] Loss D: -0.3062443733215332, loss G: -0.21053637564182281\n",
      "Epoch [1/10] Batch [409/469] Loss D: -0.2665386497974396, loss G: -0.1621623933315277\n",
      "Epoch [1/10] Batch [410/469] Loss D: -0.283345103263855, loss G: -0.26330357789993286\n",
      "Epoch [1/10] Batch [411/469] Loss D: -0.1722046434879303, loss G: -0.44103530049324036\n",
      "Epoch [1/10] Batch [412/469] Loss D: -0.18296629190444946, loss G: -0.3633670210838318\n",
      "Epoch [1/10] Batch [413/469] Loss D: -0.19228261709213257, loss G: -0.2710583209991455\n",
      "Epoch [1/10] Batch [414/469] Loss D: -0.2191956639289856, loss G: -0.36212480068206787\n",
      "Epoch [1/10] Batch [415/469] Loss D: -0.19804298877716064, loss G: -0.34997546672821045\n",
      "Epoch [1/10] Batch [416/469] Loss D: -0.1445235013961792, loss G: -0.34430646896362305\n",
      "Epoch [1/10] Batch [417/469] Loss D: -0.12368392944335938, loss G: -0.35431769490242004\n",
      "Epoch [1/10] Batch [418/469] Loss D: -0.2070985734462738, loss G: -0.30268585681915283\n",
      "Epoch [1/10] Batch [419/469] Loss D: -0.18292662501335144, loss G: -0.3015109896659851\n",
      "Epoch [1/10] Batch [420/469] Loss D: -0.3200051188468933, loss G: -0.18534962832927704\n",
      "Epoch [1/10] Batch [421/469] Loss D: -0.22762849926948547, loss G: -0.3025851845741272\n",
      "Epoch [1/10] Batch [422/469] Loss D: -0.26306217908859253, loss G: -0.3463367223739624\n",
      "Epoch [1/10] Batch [423/469] Loss D: -0.21239811182022095, loss G: -0.36766135692596436\n",
      "Epoch [1/10] Batch [424/469] Loss D: -0.23181310296058655, loss G: -0.2968071699142456\n",
      "Epoch [1/10] Batch [425/469] Loss D: -0.22562235593795776, loss G: -0.25748854875564575\n",
      "Epoch [1/10] Batch [426/469] Loss D: -0.3083227276802063, loss G: -0.2591978907585144\n",
      "Epoch [1/10] Batch [427/469] Loss D: -0.21706229448318481, loss G: -0.29180991649627686\n",
      "Epoch [1/10] Batch [428/469] Loss D: -0.18581804633140564, loss G: -0.37536749243736267\n",
      "Epoch [1/10] Batch [429/469] Loss D: -0.22654962539672852, loss G: -0.24200144410133362\n",
      "Epoch [1/10] Batch [430/469] Loss D: -0.26472464203834534, loss G: -0.27614501118659973\n",
      "Epoch [1/10] Batch [431/469] Loss D: -0.23461610078811646, loss G: -0.31088733673095703\n",
      "Epoch [1/10] Batch [432/469] Loss D: -0.3435264229774475, loss G: -0.19248488545417786\n",
      "Epoch [1/10] Batch [433/469] Loss D: -0.276946097612381, loss G: -0.36401379108428955\n",
      "Epoch [1/10] Batch [434/469] Loss D: -0.22498518228530884, loss G: -0.4187158942222595\n",
      "Epoch [1/10] Batch [435/469] Loss D: -0.2067737877368927, loss G: -0.29352760314941406\n",
      "Epoch [1/10] Batch [436/469] Loss D: -0.20889922976493835, loss G: -0.2779391407966614\n",
      "Epoch [1/10] Batch [437/469] Loss D: -0.18413779139518738, loss G: -0.27540433406829834\n",
      "Epoch [1/10] Batch [438/469] Loss D: -0.22824352979660034, loss G: -0.36551985144615173\n",
      "Epoch [1/10] Batch [439/469] Loss D: -0.2110568881034851, loss G: -0.33952271938323975\n",
      "Epoch [1/10] Batch [440/469] Loss D: -0.15242460370063782, loss G: -0.3655434548854828\n",
      "Epoch [1/10] Batch [441/469] Loss D: -0.1805758774280548, loss G: -0.31545716524124146\n",
      "Epoch [1/10] Batch [442/469] Loss D: -0.21644923090934753, loss G: -0.3222288489341736\n",
      "Epoch [1/10] Batch [443/469] Loss D: -0.21236002445220947, loss G: -0.3184441328048706\n",
      "Epoch [1/10] Batch [444/469] Loss D: -0.16231438517570496, loss G: -0.34496840834617615\n",
      "Epoch [1/10] Batch [445/469] Loss D: -0.15838932991027832, loss G: -0.2788183093070984\n",
      "Epoch [1/10] Batch [446/469] Loss D: -0.17754873633384705, loss G: -0.32540056109428406\n",
      "Epoch [1/10] Batch [447/469] Loss D: -0.1610393524169922, loss G: -0.3151584267616272\n",
      "Epoch [1/10] Batch [448/469] Loss D: -0.17376413941383362, loss G: -0.3573351502418518\n",
      "Epoch [1/10] Batch [449/469] Loss D: -0.18514207005500793, loss G: -0.2879824638366699\n",
      "Epoch [1/10] Batch [450/469] Loss D: -0.18140354752540588, loss G: -0.30557486414909363\n",
      "Epoch [1/10] Batch [451/469] Loss D: -0.16871756315231323, loss G: -0.33637735247612\n",
      "Epoch [1/10] Batch [452/469] Loss D: -0.22219982743263245, loss G: -0.30170679092407227\n",
      "Epoch [1/10] Batch [453/469] Loss D: -0.23423165082931519, loss G: -0.26075395941734314\n",
      "Epoch [1/10] Batch [454/469] Loss D: -0.20064914226531982, loss G: -0.35397085547447205\n",
      "Epoch [1/10] Batch [455/469] Loss D: -0.25247377157211304, loss G: -0.31503015756607056\n",
      "Epoch [1/10] Batch [456/469] Loss D: -0.2943081557750702, loss G: -0.30625981092453003\n",
      "Epoch [1/10] Batch [457/469] Loss D: -0.25488537549972534, loss G: -0.24875609576702118\n",
      "Epoch [1/10] Batch [458/469] Loss D: -0.20308879017829895, loss G: -0.2872568666934967\n",
      "Epoch [1/10] Batch [459/469] Loss D: -0.15130901336669922, loss G: -0.3897901177406311\n",
      "Epoch [1/10] Batch [460/469] Loss D: -0.2430936098098755, loss G: -0.3106171488761902\n",
      "Epoch [1/10] Batch [461/469] Loss D: -0.2832472622394562, loss G: -0.282061368227005\n",
      "Epoch [1/10] Batch [462/469] Loss D: -0.20973721146583557, loss G: -0.32910484075546265\n",
      "Epoch [1/10] Batch [463/469] Loss D: -0.18797749280929565, loss G: -0.42142125964164734\n",
      "Epoch [1/10] Batch [464/469] Loss D: -0.20078080892562866, loss G: -0.29450416564941406\n",
      "Epoch [1/10] Batch [465/469] Loss D: -0.22643879055976868, loss G: -0.36372455954551697\n",
      "Epoch [1/10] Batch [466/469] Loss D: -0.1861046552658081, loss G: -0.3315228223800659\n",
      "Epoch [1/10] Batch [467/469] Loss D: -0.1498669981956482, loss G: -0.4181809425354004\n",
      "Epoch [1/10] Batch [468/469] Loss D: -0.18096572160720825, loss G: -0.32832273840904236\n",
      "Epoch [1/10] Batch [469/469] Loss D: -0.0387343168258667, loss G: -0.37269338965415955\n",
      "Epoch [2/10] Batch [1/469] Loss D: -0.18495142459869385, loss G: -0.2842402458190918\n",
      "Epoch [2/10] Batch [2/469] Loss D: -0.2264585793018341, loss G: -0.3546530604362488\n",
      "Epoch [2/10] Batch [3/469] Loss D: -0.3313977122306824, loss G: -0.2576783299446106\n",
      "Epoch [2/10] Batch [4/469] Loss D: -0.27584385871887207, loss G: -0.2503601908683777\n",
      "Epoch [2/10] Batch [5/469] Loss D: -0.29216617345809937, loss G: -0.21409092843532562\n",
      "Epoch [2/10] Batch [6/469] Loss D: -0.2702426612377167, loss G: -0.35977476835250854\n",
      "Epoch [2/10] Batch [7/469] Loss D: -0.307620108127594, loss G: -0.3115740418434143\n",
      "Epoch [2/10] Batch [8/469] Loss D: -0.24929746985435486, loss G: -0.262992262840271\n",
      "Epoch [2/10] Batch [9/469] Loss D: -0.24914494156837463, loss G: -0.28236186504364014\n",
      "Epoch [2/10] Batch [10/469] Loss D: -0.3171287178993225, loss G: -0.3729705214500427\n",
      "Epoch [2/10] Batch [11/469] Loss D: -0.2842433750629425, loss G: -0.26336824893951416\n",
      "Epoch [2/10] Batch [12/469] Loss D: -0.23704108595848083, loss G: -0.2258504331111908\n",
      "Epoch [2/10] Batch [13/469] Loss D: -0.20262321829795837, loss G: -0.3291012644767761\n",
      "Epoch [2/10] Batch [14/469] Loss D: -0.24775177240371704, loss G: -0.3427635729312897\n",
      "Epoch [2/10] Batch [15/469] Loss D: -0.23694640398025513, loss G: -0.24238792061805725\n",
      "Epoch [2/10] Batch [16/469] Loss D: -0.2862354516983032, loss G: -0.32639825344085693\n",
      "Epoch [2/10] Batch [17/469] Loss D: -0.26941215991973877, loss G: -0.27820906043052673\n",
      "Epoch [2/10] Batch [18/469] Loss D: -0.24402016401290894, loss G: -0.2779872417449951\n",
      "Epoch [2/10] Batch [19/469] Loss D: -0.2636312246322632, loss G: -0.31372711062431335\n",
      "Epoch [2/10] Batch [20/469] Loss D: -0.2678966522216797, loss G: -0.22786302864551544\n",
      "Epoch [2/10] Batch [21/469] Loss D: -0.31872379779815674, loss G: -0.2530226409435272\n",
      "Epoch [2/10] Batch [22/469] Loss D: -0.22646808624267578, loss G: -0.3245335817337036\n",
      "Epoch [2/10] Batch [23/469] Loss D: -0.2558388411998749, loss G: -0.1802968978881836\n",
      "Epoch [2/10] Batch [24/469] Loss D: -0.3079646825790405, loss G: -0.34852665662765503\n",
      "Epoch [2/10] Batch [25/469] Loss D: -0.2899782061576843, loss G: -0.24241213500499725\n",
      "Epoch [2/10] Batch [26/469] Loss D: -0.32881805300712585, loss G: -0.27532729506492615\n",
      "Epoch [2/10] Batch [27/469] Loss D: -0.22333335876464844, loss G: -0.33499228954315186\n",
      "Epoch [2/10] Batch [28/469] Loss D: -0.21126291155815125, loss G: -0.25795984268188477\n",
      "Epoch [2/10] Batch [29/469] Loss D: -0.26206958293914795, loss G: -0.2475147396326065\n",
      "Epoch [2/10] Batch [30/469] Loss D: -0.18243077397346497, loss G: -0.30856263637542725\n",
      "Epoch [2/10] Batch [31/469] Loss D: -0.23112890124320984, loss G: -0.30196744203567505\n",
      "Epoch [2/10] Batch [32/469] Loss D: -0.1646241545677185, loss G: -0.4114478528499603\n",
      "Epoch [2/10] Batch [33/469] Loss D: -0.17721888422966003, loss G: -0.3252077102661133\n",
      "Epoch [2/10] Batch [34/469] Loss D: -0.1902252435684204, loss G: -0.3495078682899475\n",
      "Epoch [2/10] Batch [35/469] Loss D: -0.20550820231437683, loss G: -0.3886120915412903\n",
      "Epoch [2/10] Batch [36/469] Loss D: -0.2149176001548767, loss G: -0.27515268325805664\n",
      "Epoch [2/10] Batch [37/469] Loss D: -0.2238616645336151, loss G: -0.3431044816970825\n",
      "Epoch [2/10] Batch [38/469] Loss D: -0.17905044555664062, loss G: -0.330790638923645\n",
      "Epoch [2/10] Batch [39/469] Loss D: -0.11641377210617065, loss G: -0.36370718479156494\n",
      "Epoch [2/10] Batch [40/469] Loss D: -0.1790289282798767, loss G: -0.37988144159317017\n",
      "Epoch [2/10] Batch [41/469] Loss D: -0.24594157934188843, loss G: -0.25093114376068115\n",
      "Epoch [2/10] Batch [42/469] Loss D: -0.22537434101104736, loss G: -0.2909795045852661\n",
      "Epoch [2/10] Batch [43/469] Loss D: -0.2871754765510559, loss G: -0.187742680311203\n",
      "Epoch [2/10] Batch [44/469] Loss D: -0.22608423233032227, loss G: -0.3856368064880371\n",
      "Epoch [2/10] Batch [45/469] Loss D: -0.27962997555732727, loss G: -0.27639007568359375\n",
      "Epoch [2/10] Batch [46/469] Loss D: -0.2604154646396637, loss G: -0.16855508089065552\n",
      "Epoch [2/10] Batch [47/469] Loss D: -0.2493179440498352, loss G: -0.25496941804885864\n",
      "Epoch [2/10] Batch [48/469] Loss D: -0.07336002588272095, loss G: -0.3229101300239563\n",
      "Epoch [2/10] Batch [49/469] Loss D: -0.03828775882720947, loss G: -0.2860542833805084\n",
      "Epoch [2/10] Batch [50/469] Loss D: -0.10535204410552979, loss G: -0.3202894926071167\n",
      "Epoch [2/10] Batch [51/469] Loss D: -0.14825087785720825, loss G: -0.42072299122810364\n",
      "Epoch [2/10] Batch [52/469] Loss D: -0.18815010786056519, loss G: -0.43699532747268677\n",
      "Epoch [2/10] Batch [53/469] Loss D: -0.1363428831100464, loss G: -0.28227734565734863\n",
      "Epoch [2/10] Batch [54/469] Loss D: -0.22290825843811035, loss G: -0.2031821310520172\n",
      "Epoch [2/10] Batch [55/469] Loss D: -0.16794848442077637, loss G: -0.3194296360015869\n",
      "Epoch [2/10] Batch [56/469] Loss D: -0.2092808187007904, loss G: -0.41584840416908264\n",
      "Epoch [2/10] Batch [57/469] Loss D: -0.2088838815689087, loss G: -0.29771000146865845\n",
      "Epoch [2/10] Batch [58/469] Loss D: -0.20345130562782288, loss G: -0.1770710051059723\n",
      "Epoch [2/10] Batch [59/469] Loss D: -0.19459207355976105, loss G: -0.3334729075431824\n",
      "Epoch [2/10] Batch [60/469] Loss D: -0.2489740252494812, loss G: -0.2863454520702362\n",
      "Epoch [2/10] Batch [61/469] Loss D: -0.2668061852455139, loss G: -0.2440876066684723\n",
      "Epoch [2/10] Batch [62/469] Loss D: -0.25531983375549316, loss G: -0.2202865183353424\n",
      "Epoch [2/10] Batch [63/469] Loss D: -0.1905943751335144, loss G: -0.40920916199684143\n",
      "Epoch [2/10] Batch [64/469] Loss D: -0.2513209581375122, loss G: -0.25265949964523315\n",
      "Epoch [2/10] Batch [65/469] Loss D: -0.23223692178726196, loss G: -0.24874772131443024\n",
      "Epoch [2/10] Batch [66/469] Loss D: -0.3813974857330322, loss G: -0.25710660219192505\n",
      "Epoch [2/10] Batch [67/469] Loss D: -0.18740147352218628, loss G: -0.3073609471321106\n",
      "Epoch [2/10] Batch [68/469] Loss D: -0.17075657844543457, loss G: -0.3308718502521515\n",
      "Epoch [2/10] Batch [69/469] Loss D: -0.2704325318336487, loss G: -0.2691578269004822\n",
      "Epoch [2/10] Batch [70/469] Loss D: -0.19912803173065186, loss G: -0.2431935966014862\n",
      "Epoch [2/10] Batch [71/469] Loss D: -0.20981085300445557, loss G: -0.2755362391471863\n",
      "Epoch [2/10] Batch [72/469] Loss D: -0.27557626366615295, loss G: -0.2638568580150604\n",
      "Epoch [2/10] Batch [73/469] Loss D: -0.20686879754066467, loss G: -0.4278990626335144\n",
      "Epoch [2/10] Batch [74/469] Loss D: -0.2403934895992279, loss G: -0.3492925763130188\n",
      "Epoch [2/10] Batch [75/469] Loss D: -0.2638060748577118, loss G: -0.2506631016731262\n",
      "Epoch [2/10] Batch [76/469] Loss D: -0.2673250436782837, loss G: -0.2807901203632355\n",
      "Epoch [2/10] Batch [77/469] Loss D: -0.22167715430259705, loss G: -0.3212166428565979\n",
      "Epoch [2/10] Batch [78/469] Loss D: -0.16801121830940247, loss G: -0.3667362332344055\n",
      "Epoch [2/10] Batch [79/469] Loss D: -0.161410391330719, loss G: -0.33245131373405457\n",
      "Epoch [2/10] Batch [80/469] Loss D: -0.2484586238861084, loss G: -0.24141936004161835\n",
      "Epoch [2/10] Batch [81/469] Loss D: -0.17118161916732788, loss G: -0.37277674674987793\n",
      "Epoch [2/10] Batch [82/469] Loss D: -0.19814088940620422, loss G: -0.31086790561676025\n",
      "Epoch [2/10] Batch [83/469] Loss D: -0.15252286195755005, loss G: -0.28785720467567444\n",
      "Epoch [2/10] Batch [84/469] Loss D: -0.22830429673194885, loss G: -0.28448686003685\n",
      "Epoch [2/10] Batch [85/469] Loss D: -0.2242666482925415, loss G: -0.39492711424827576\n",
      "Epoch [2/10] Batch [86/469] Loss D: -0.3158285617828369, loss G: -0.2642993927001953\n",
      "Epoch [2/10] Batch [87/469] Loss D: -0.35902392864227295, loss G: -0.23887886106967926\n",
      "Epoch [2/10] Batch [88/469] Loss D: -0.298703670501709, loss G: -0.23602572083473206\n",
      "Epoch [2/10] Batch [89/469] Loss D: -0.36530065536499023, loss G: -0.23320512473583221\n",
      "Epoch [2/10] Batch [90/469] Loss D: -0.3502938151359558, loss G: -0.2747565805912018\n",
      "Epoch [2/10] Batch [91/469] Loss D: -0.31348246335983276, loss G: -0.23966391384601593\n",
      "Epoch [2/10] Batch [92/469] Loss D: -0.3334897458553314, loss G: -0.2063319832086563\n",
      "Epoch [2/10] Batch [93/469] Loss D: -0.28266894817352295, loss G: -0.3247692883014679\n",
      "Epoch [2/10] Batch [94/469] Loss D: -0.31403791904449463, loss G: -0.34166085720062256\n",
      "Epoch [2/10] Batch [95/469] Loss D: -0.26060086488723755, loss G: -0.2348102331161499\n",
      "Epoch [2/10] Batch [96/469] Loss D: -0.19924527406692505, loss G: -0.31728625297546387\n",
      "Epoch [2/10] Batch [97/469] Loss D: -0.16199856996536255, loss G: -0.3457830846309662\n",
      "Epoch [2/10] Batch [98/469] Loss D: -0.16898345947265625, loss G: -0.3149045407772064\n",
      "Epoch [2/10] Batch [99/469] Loss D: -0.18277490139007568, loss G: -0.29461348056793213\n",
      "Epoch [2/10] Batch [100/469] Loss D: -0.19702577590942383, loss G: -0.24118085205554962\n",
      "Epoch [2/10] Batch [101/469] Loss D: -0.16955995559692383, loss G: -0.3460293412208557\n",
      "Epoch [2/10] Batch [102/469] Loss D: -0.20852643251419067, loss G: -0.4158821702003479\n",
      "Epoch [2/10] Batch [103/469] Loss D: -0.18228697776794434, loss G: -0.2556917667388916\n",
      "Epoch [2/10] Batch [104/469] Loss D: -0.16118213534355164, loss G: -0.33689048886299133\n",
      "Epoch [2/10] Batch [105/469] Loss D: -0.1861160397529602, loss G: -0.3680388331413269\n",
      "Epoch [2/10] Batch [106/469] Loss D: -0.18414488434791565, loss G: -0.32906806468963623\n",
      "Epoch [2/10] Batch [107/469] Loss D: -0.16464966535568237, loss G: -0.38126498460769653\n",
      "Epoch [2/10] Batch [108/469] Loss D: -0.07434412837028503, loss G: -0.4252459704875946\n",
      "Epoch [2/10] Batch [109/469] Loss D: -0.11127078533172607, loss G: -0.4090152084827423\n",
      "Epoch [2/10] Batch [110/469] Loss D: -0.15448370575904846, loss G: -0.32101282477378845\n",
      "Epoch [2/10] Batch [111/469] Loss D: -0.20551228523254395, loss G: -0.26611220836639404\n",
      "Epoch [2/10] Batch [112/469] Loss D: -0.17974853515625, loss G: -0.3617105484008789\n",
      "Epoch [2/10] Batch [113/469] Loss D: -0.19832611083984375, loss G: -0.3430739641189575\n",
      "Epoch [2/10] Batch [114/469] Loss D: -0.26997822523117065, loss G: -0.21682116389274597\n",
      "Epoch [2/10] Batch [115/469] Loss D: -0.19470614194869995, loss G: -0.32310575246810913\n",
      "Epoch [2/10] Batch [116/469] Loss D: -0.25775429606437683, loss G: -0.36106061935424805\n",
      "Epoch [2/10] Batch [117/469] Loss D: -0.2775213122367859, loss G: -0.26189345121383667\n",
      "Epoch [2/10] Batch [118/469] Loss D: -0.2661353349685669, loss G: -0.26317691802978516\n",
      "Epoch [2/10] Batch [119/469] Loss D: -0.17979055643081665, loss G: -0.28325796127319336\n",
      "Epoch [2/10] Batch [120/469] Loss D: -0.2523610591888428, loss G: -0.2516542673110962\n",
      "Epoch [2/10] Batch [121/469] Loss D: -0.25777870416641235, loss G: -0.2658170461654663\n",
      "Epoch [2/10] Batch [122/469] Loss D: -0.23011648654937744, loss G: -0.37564462423324585\n",
      "Epoch [2/10] Batch [123/469] Loss D: -0.20087295770645142, loss G: -0.36967772245407104\n",
      "Epoch [2/10] Batch [124/469] Loss D: -0.214401513338089, loss G: -0.24169862270355225\n",
      "Epoch [2/10] Batch [125/469] Loss D: -0.22679629921913147, loss G: -0.2785188555717468\n",
      "Epoch [2/10] Batch [126/469] Loss D: -0.2679485082626343, loss G: -0.3999609351158142\n",
      "Epoch [2/10] Batch [127/469] Loss D: -0.1714751124382019, loss G: -0.40981757640838623\n",
      "Epoch [2/10] Batch [128/469] Loss D: -0.2589457929134369, loss G: -0.19853204488754272\n",
      "Epoch [2/10] Batch [129/469] Loss D: -0.34642356634140015, loss G: -0.28325021266937256\n",
      "Epoch [2/10] Batch [130/469] Loss D: -0.3834072947502136, loss G: -0.33146992325782776\n",
      "Epoch [2/10] Batch [131/469] Loss D: -0.3122715353965759, loss G: -0.2895596921443939\n",
      "Epoch [2/10] Batch [132/469] Loss D: -0.3309653401374817, loss G: -0.19491778314113617\n",
      "Epoch [2/10] Batch [133/469] Loss D: -0.2955767512321472, loss G: -0.3063494563102722\n",
      "Epoch [2/10] Batch [134/469] Loss D: -0.279002845287323, loss G: -0.4191729426383972\n",
      "Epoch [2/10] Batch [135/469] Loss D: -0.2240689992904663, loss G: -0.21846944093704224\n",
      "Epoch [2/10] Batch [136/469] Loss D: -0.25621235370635986, loss G: -0.27019596099853516\n",
      "Epoch [2/10] Batch [137/469] Loss D: -0.22202065587043762, loss G: -0.3687475621700287\n",
      "Epoch [2/10] Batch [138/469] Loss D: -0.26136523485183716, loss G: -0.3889578580856323\n",
      "Epoch [2/10] Batch [139/469] Loss D: -0.22541701793670654, loss G: -0.2581446170806885\n",
      "Epoch [2/10] Batch [140/469] Loss D: -0.27276891469955444, loss G: -0.27022647857666016\n",
      "Epoch [2/10] Batch [141/469] Loss D: -0.2982667088508606, loss G: -0.2783728837966919\n",
      "Epoch [2/10] Batch [142/469] Loss D: -0.2900635600090027, loss G: -0.2605350911617279\n",
      "Epoch [2/10] Batch [143/469] Loss D: -0.26748043298721313, loss G: -0.3165343999862671\n",
      "Epoch [2/10] Batch [144/469] Loss D: -0.29472577571868896, loss G: -0.298526406288147\n",
      "Epoch [2/10] Batch [145/469] Loss D: -0.24630621075630188, loss G: -0.2806386351585388\n",
      "Epoch [2/10] Batch [146/469] Loss D: -0.18922153115272522, loss G: -0.3021058440208435\n",
      "Epoch [2/10] Batch [147/469] Loss D: -0.1941366195678711, loss G: -0.34779587388038635\n",
      "Epoch [2/10] Batch [148/469] Loss D: -0.23206964135169983, loss G: -0.2100670039653778\n",
      "Epoch [2/10] Batch [149/469] Loss D: -0.19496285915374756, loss G: -0.23472443222999573\n",
      "Epoch [2/10] Batch [150/469] Loss D: -0.2727883458137512, loss G: -0.3218640685081482\n",
      "Epoch [2/10] Batch [151/469] Loss D: -0.21059107780456543, loss G: -0.3429938852787018\n",
      "Epoch [2/10] Batch [152/469] Loss D: -0.27740663290023804, loss G: -0.14916718006134033\n",
      "Epoch [2/10] Batch [153/469] Loss D: -0.21045775711536407, loss G: -0.2859988510608673\n",
      "Epoch [2/10] Batch [154/469] Loss D: -0.20033270120620728, loss G: -0.41077402234077454\n",
      "Epoch [2/10] Batch [155/469] Loss D: -0.26771092414855957, loss G: -0.18766507506370544\n",
      "Epoch [2/10] Batch [156/469] Loss D: -0.16637110710144043, loss G: -0.295601487159729\n",
      "Epoch [2/10] Batch [157/469] Loss D: -0.17786544561386108, loss G: -0.4305870831012726\n",
      "Epoch [2/10] Batch [158/469] Loss D: -0.14919990301132202, loss G: -0.4678008258342743\n",
      "Epoch [2/10] Batch [159/469] Loss D: -0.2229994535446167, loss G: -0.3151012063026428\n",
      "Epoch [2/10] Batch [160/469] Loss D: -0.17331963777542114, loss G: -0.3700156807899475\n",
      "Epoch [2/10] Batch [161/469] Loss D: -0.18202602863311768, loss G: -0.3806857168674469\n",
      "Epoch [2/10] Batch [162/469] Loss D: -0.2883046865463257, loss G: -0.2512756586074829\n",
      "Epoch [2/10] Batch [163/469] Loss D: -0.23417195677757263, loss G: -0.3289269804954529\n",
      "Epoch [2/10] Batch [164/469] Loss D: -0.28057947754859924, loss G: -0.34383803606033325\n",
      "Epoch [2/10] Batch [165/469] Loss D: -0.2982414960861206, loss G: -0.24254505336284637\n",
      "Epoch [2/10] Batch [166/469] Loss D: -0.3213041424751282, loss G: -0.2641948461532593\n",
      "Epoch [2/10] Batch [167/469] Loss D: -0.2891117036342621, loss G: -0.2381455898284912\n",
      "Epoch [2/10] Batch [168/469] Loss D: -0.2245699167251587, loss G: -0.36923331022262573\n",
      "Epoch [2/10] Batch [169/469] Loss D: -0.18198639154434204, loss G: -0.39213013648986816\n",
      "Epoch [2/10] Batch [170/469] Loss D: -0.17462584376335144, loss G: -0.23860979080200195\n",
      "Epoch [2/10] Batch [171/469] Loss D: -0.08978286385536194, loss G: -0.303183376789093\n",
      "Epoch [2/10] Batch [172/469] Loss D: -0.10771739482879639, loss G: -0.2959206700325012\n",
      "Epoch [2/10] Batch [173/469] Loss D: -0.05401921272277832, loss G: -0.2871742248535156\n",
      "Epoch [2/10] Batch [174/469] Loss D: -0.139378160238266, loss G: -0.1800917685031891\n",
      "Epoch [2/10] Batch [175/469] Loss D: -0.22510331869125366, loss G: -0.20821058750152588\n",
      "Epoch [2/10] Batch [176/469] Loss D: -0.26913222670555115, loss G: -0.22501716017723083\n",
      "Epoch [2/10] Batch [177/469] Loss D: -0.28846311569213867, loss G: -0.23147574067115784\n",
      "Epoch [2/10] Batch [178/469] Loss D: -0.3093230128288269, loss G: -0.2598573565483093\n",
      "Epoch [2/10] Batch [179/469] Loss D: -0.34994834661483765, loss G: -0.25958606600761414\n",
      "Epoch [2/10] Batch [180/469] Loss D: -0.3937373459339142, loss G: -0.11877471208572388\n",
      "Epoch [2/10] Batch [181/469] Loss D: -0.36935076117515564, loss G: -0.2289924919605255\n",
      "Epoch [2/10] Batch [182/469] Loss D: -0.27680662274360657, loss G: -0.36356422305107117\n",
      "Epoch [2/10] Batch [183/469] Loss D: -0.17287564277648926, loss G: -0.36227864027023315\n",
      "Epoch [2/10] Batch [184/469] Loss D: -0.2647464871406555, loss G: -0.16595709323883057\n",
      "Epoch [2/10] Batch [185/469] Loss D: -0.16937196254730225, loss G: -0.33847254514694214\n",
      "Epoch [2/10] Batch [186/469] Loss D: -0.1297992765903473, loss G: -0.547328531742096\n",
      "Epoch [2/10] Batch [187/469] Loss D: -0.2029171586036682, loss G: -0.373269259929657\n",
      "Epoch [2/10] Batch [188/469] Loss D: -0.22618359327316284, loss G: -0.2110920250415802\n",
      "Epoch [2/10] Batch [189/469] Loss D: -0.14577865600585938, loss G: -0.2764453887939453\n",
      "Epoch [2/10] Batch [190/469] Loss D: -0.18381580710411072, loss G: -0.38987642526626587\n",
      "Epoch [2/10] Batch [191/469] Loss D: -0.24178102612495422, loss G: -0.365384042263031\n",
      "Epoch [2/10] Batch [192/469] Loss D: -0.1675153374671936, loss G: -0.25762829184532166\n",
      "Epoch [2/10] Batch [193/469] Loss D: -0.2562149167060852, loss G: -0.25477486848831177\n",
      "Epoch [2/10] Batch [194/469] Loss D: -0.2611134946346283, loss G: -0.28072744607925415\n",
      "Epoch [2/10] Batch [195/469] Loss D: -0.25024664402008057, loss G: -0.2538532316684723\n",
      "Epoch [2/10] Batch [196/469] Loss D: -0.21122127771377563, loss G: -0.26231980323791504\n",
      "Epoch [2/10] Batch [197/469] Loss D: -0.26007410883903503, loss G: -0.30421990156173706\n",
      "Epoch [2/10] Batch [198/469] Loss D: -0.2517327070236206, loss G: -0.29214048385620117\n",
      "Epoch [2/10] Batch [199/469] Loss D: -0.253414511680603, loss G: -0.23894116282463074\n",
      "Epoch [2/10] Batch [200/469] Loss D: -0.18680506944656372, loss G: -0.2577657997608185\n",
      "Epoch [2/10] Batch [201/469] Loss D: -0.24579685926437378, loss G: -0.3337506651878357\n",
      "Epoch [2/10] Batch [202/469] Loss D: -0.15403640270233154, loss G: -0.4224429428577423\n",
      "Epoch [2/10] Batch [203/469] Loss D: -0.13754692673683167, loss G: -0.34685009717941284\n",
      "Epoch [2/10] Batch [204/469] Loss D: -0.18007314205169678, loss G: -0.3526776432991028\n",
      "Epoch [2/10] Batch [205/469] Loss D: -0.29569846391677856, loss G: -0.26680105924606323\n",
      "Epoch [2/10] Batch [206/469] Loss D: -0.25018346309661865, loss G: -0.28649187088012695\n",
      "Epoch [2/10] Batch [207/469] Loss D: -0.2944750189781189, loss G: -0.28029394149780273\n",
      "Epoch [2/10] Batch [208/469] Loss D: -0.3465522527694702, loss G: -0.22723370790481567\n",
      "Epoch [2/10] Batch [209/469] Loss D: -0.4002201557159424, loss G: -0.1825524866580963\n",
      "Epoch [2/10] Batch [210/469] Loss D: -0.28484052419662476, loss G: -0.2155991792678833\n",
      "Epoch [2/10] Batch [211/469] Loss D: -0.3156173825263977, loss G: -0.270510733127594\n",
      "Epoch [2/10] Batch [212/469] Loss D: -0.3531627357006073, loss G: -0.244086354970932\n",
      "Epoch [2/10] Batch [213/469] Loss D: -0.2356327772140503, loss G: -0.2742181420326233\n",
      "Epoch [2/10] Batch [214/469] Loss D: -0.2129553258419037, loss G: -0.3758230209350586\n",
      "Epoch [2/10] Batch [215/469] Loss D: -0.10946857929229736, loss G: -0.4363606572151184\n",
      "Epoch [2/10] Batch [216/469] Loss D: -0.19530022144317627, loss G: -0.269271582365036\n",
      "Epoch [2/10] Batch [217/469] Loss D: -0.10832276940345764, loss G: -0.2928072512149811\n",
      "Epoch [2/10] Batch [218/469] Loss D: -0.1633574664592743, loss G: -0.42292875051498413\n",
      "Epoch [2/10] Batch [219/469] Loss D: -0.1996132731437683, loss G: -0.3452402353286743\n",
      "Epoch [2/10] Batch [220/469] Loss D: -0.26010236144065857, loss G: -0.2651125490665436\n",
      "Epoch [2/10] Batch [221/469] Loss D: -0.2604601979255676, loss G: -0.27746036648750305\n",
      "Epoch [2/10] Batch [222/469] Loss D: -0.1905248761177063, loss G: -0.30186188220977783\n",
      "Epoch [2/10] Batch [223/469] Loss D: -0.28213271498680115, loss G: -0.25222039222717285\n",
      "Epoch [2/10] Batch [224/469] Loss D: -0.2814188003540039, loss G: -0.2189536690711975\n",
      "Epoch [2/10] Batch [225/469] Loss D: -0.25798162817955017, loss G: -0.33293554186820984\n",
      "Epoch [2/10] Batch [226/469] Loss D: -0.2060520052909851, loss G: -0.40330976247787476\n",
      "Epoch [2/10] Batch [227/469] Loss D: -0.15643033385276794, loss G: -0.38028502464294434\n",
      "Epoch [2/10] Batch [228/469] Loss D: -0.2686656713485718, loss G: -0.26747143268585205\n",
      "Epoch [2/10] Batch [229/469] Loss D: -0.2941795885562897, loss G: -0.2806382179260254\n",
      "Epoch [2/10] Batch [230/469] Loss D: -0.21082726120948792, loss G: -0.36411377787590027\n",
      "Epoch [2/10] Batch [231/469] Loss D: -0.28687000274658203, loss G: -0.27012088894844055\n",
      "Epoch [2/10] Batch [232/469] Loss D: -0.27804428339004517, loss G: -0.3059805631637573\n",
      "Epoch [2/10] Batch [233/469] Loss D: -0.21725940704345703, loss G: -0.33377498388290405\n",
      "Epoch [2/10] Batch [234/469] Loss D: -0.2010226547718048, loss G: -0.36201179027557373\n",
      "Epoch [2/10] Batch [235/469] Loss D: -0.201555073261261, loss G: -0.3227675259113312\n",
      "Epoch [2/10] Batch [236/469] Loss D: -0.20008432865142822, loss G: -0.25670456886291504\n",
      "Epoch [2/10] Batch [237/469] Loss D: -0.22409921884536743, loss G: -0.37671828269958496\n",
      "Epoch [2/10] Batch [238/469] Loss D: -0.1960028111934662, loss G: -0.3577575981616974\n",
      "Epoch [2/10] Batch [239/469] Loss D: -0.2014331817626953, loss G: -0.3172323703765869\n",
      "Epoch [2/10] Batch [240/469] Loss D: -0.20626980066299438, loss G: -0.30607521533966064\n",
      "Epoch [2/10] Batch [241/469] Loss D: -0.15727221965789795, loss G: -0.2599731385707855\n",
      "Epoch [2/10] Batch [242/469] Loss D: -0.23857298493385315, loss G: -0.30392366647720337\n",
      "Epoch [2/10] Batch [243/469] Loss D: -0.1591830551624298, loss G: -0.3432406187057495\n",
      "Epoch [2/10] Batch [244/469] Loss D: -0.27678346633911133, loss G: -0.3572133183479309\n",
      "Epoch [2/10] Batch [245/469] Loss D: -0.31024473905563354, loss G: -0.22425836324691772\n",
      "Epoch [2/10] Batch [246/469] Loss D: -0.22418701648712158, loss G: -0.3427252471446991\n",
      "Epoch [2/10] Batch [247/469] Loss D: -0.24701547622680664, loss G: -0.41732093691825867\n",
      "Epoch [2/10] Batch [248/469] Loss D: -0.28051143884658813, loss G: -0.2994999289512634\n",
      "Epoch [2/10] Batch [249/469] Loss D: -0.2917601466178894, loss G: -0.2971842885017395\n",
      "Epoch [2/10] Batch [250/469] Loss D: -0.2742924690246582, loss G: -0.18912248313426971\n",
      "Epoch [2/10] Batch [251/469] Loss D: -0.21639198064804077, loss G: -0.2526872158050537\n",
      "Epoch [2/10] Batch [252/469] Loss D: -0.25531142950057983, loss G: -0.40412694215774536\n",
      "Epoch [2/10] Batch [253/469] Loss D: -0.19707131385803223, loss G: -0.4700542688369751\n",
      "Epoch [2/10] Batch [254/469] Loss D: -0.15290945768356323, loss G: -0.3249724209308624\n",
      "Epoch [2/10] Batch [255/469] Loss D: -0.20012223720550537, loss G: -0.2406458556652069\n",
      "Epoch [2/10] Batch [256/469] Loss D: -0.2620852589607239, loss G: -0.2675046920776367\n",
      "Epoch [2/10] Batch [257/469] Loss D: -0.13213080167770386, loss G: -0.3903481364250183\n",
      "Epoch [2/10] Batch [258/469] Loss D: -0.15023425221443176, loss G: -0.3471284806728363\n",
      "Epoch [2/10] Batch [259/469] Loss D: -0.1509484052658081, loss G: -0.38064146041870117\n",
      "Epoch [2/10] Batch [260/469] Loss D: -0.19029390811920166, loss G: -0.3755283057689667\n",
      "Epoch [2/10] Batch [261/469] Loss D: -0.26787427067756653, loss G: -0.2735842764377594\n",
      "Epoch [2/10] Batch [262/469] Loss D: -0.23097646236419678, loss G: -0.3687163293361664\n",
      "Epoch [2/10] Batch [263/469] Loss D: -0.3170020282268524, loss G: -0.2854243516921997\n",
      "Epoch [2/10] Batch [264/469] Loss D: -0.3172464966773987, loss G: -0.268884539604187\n",
      "Epoch [2/10] Batch [265/469] Loss D: -0.277082622051239, loss G: -0.33558645844459534\n",
      "Epoch [2/10] Batch [266/469] Loss D: -0.2954379916191101, loss G: -0.25364840030670166\n",
      "Epoch [2/10] Batch [267/469] Loss D: -0.3017355799674988, loss G: -0.28300365805625916\n",
      "Epoch [2/10] Batch [268/469] Loss D: -0.24113184213638306, loss G: -0.3761129379272461\n",
      "Epoch [2/10] Batch [269/469] Loss D: -0.22936779260635376, loss G: -0.3762671649456024\n",
      "Epoch [2/10] Batch [270/469] Loss D: -0.21247494220733643, loss G: -0.3021513521671295\n",
      "Epoch [2/10] Batch [271/469] Loss D: -0.17251121997833252, loss G: -0.3072117567062378\n",
      "Epoch [2/10] Batch [272/469] Loss D: -0.2880905270576477, loss G: -0.2802574336528778\n",
      "Epoch [2/10] Batch [273/469] Loss D: -0.18614822626113892, loss G: -0.4666973948478699\n",
      "Epoch [2/10] Batch [274/469] Loss D: -0.16333365440368652, loss G: -0.43235868215560913\n",
      "Epoch [2/10] Batch [275/469] Loss D: -0.22550880908966064, loss G: -0.3142772912979126\n",
      "Epoch [2/10] Batch [276/469] Loss D: -0.23278498649597168, loss G: -0.3593056797981262\n",
      "Epoch [2/10] Batch [277/469] Loss D: -0.25686895847320557, loss G: -0.33073657751083374\n",
      "Epoch [2/10] Batch [278/469] Loss D: -0.19974690675735474, loss G: -0.32721203565597534\n",
      "Epoch [2/10] Batch [279/469] Loss D: -0.26770010590553284, loss G: -0.28369274735450745\n",
      "Epoch [2/10] Batch [280/469] Loss D: -0.23051708936691284, loss G: -0.36930376291275024\n",
      "Epoch [2/10] Batch [281/469] Loss D: -0.2525169253349304, loss G: -0.27765268087387085\n",
      "Epoch [2/10] Batch [282/469] Loss D: -0.32032716274261475, loss G: -0.24798065423965454\n",
      "Epoch [2/10] Batch [283/469] Loss D: -0.23306488990783691, loss G: -0.3424454629421234\n",
      "Epoch [2/10] Batch [284/469] Loss D: -0.24068903923034668, loss G: -0.4741808772087097\n",
      "Epoch [2/10] Batch [285/469] Loss D: -0.25846385955810547, loss G: -0.2862904965877533\n",
      "Epoch [2/10] Batch [286/469] Loss D: -0.3092914819717407, loss G: -0.2491646707057953\n",
      "Epoch [2/10] Batch [287/469] Loss D: -0.27616018056869507, loss G: -0.37451648712158203\n",
      "Epoch [2/10] Batch [288/469] Loss D: -0.1592484712600708, loss G: -0.4632847309112549\n",
      "Epoch [2/10] Batch [289/469] Loss D: -0.21937289834022522, loss G: -0.34469014406204224\n",
      "Epoch [2/10] Batch [290/469] Loss D: -0.2370138168334961, loss G: -0.35238319635391235\n",
      "Epoch [2/10] Batch [291/469] Loss D: -0.23763298988342285, loss G: -0.30839526653289795\n",
      "Epoch [2/10] Batch [292/469] Loss D: -0.26213139295578003, loss G: -0.2995057702064514\n",
      "Epoch [2/10] Batch [293/469] Loss D: -0.22538185119628906, loss G: -0.40721213817596436\n",
      "Epoch [2/10] Batch [294/469] Loss D: -0.20838835835456848, loss G: -0.3511804938316345\n",
      "Epoch [2/10] Batch [295/469] Loss D: -0.21252679824829102, loss G: -0.28367123007774353\n",
      "Epoch [2/10] Batch [296/469] Loss D: -0.10994032025337219, loss G: -0.2394188940525055\n",
      "Epoch [2/10] Batch [297/469] Loss D: -0.1907106339931488, loss G: -0.27549368143081665\n",
      "Epoch [2/10] Batch [298/469] Loss D: -0.2300364375114441, loss G: -0.3834713101387024\n",
      "Epoch [2/10] Batch [299/469] Loss D: -0.25529295206069946, loss G: -0.34103474020957947\n",
      "Epoch [2/10] Batch [300/469] Loss D: -0.24257993698120117, loss G: -0.3031134605407715\n",
      "Epoch [2/10] Batch [301/469] Loss D: -0.14232024550437927, loss G: -0.419111430644989\n",
      "Epoch [2/10] Batch [302/469] Loss D: -0.2615876793861389, loss G: -0.3464278280735016\n",
      "Epoch [2/10] Batch [303/469] Loss D: -0.31112945079803467, loss G: -0.28133323788642883\n",
      "Epoch [2/10] Batch [304/469] Loss D: -0.13447177410125732, loss G: -0.42379507422447205\n",
      "Epoch [2/10] Batch [305/469] Loss D: -0.2591525912284851, loss G: -0.3362448215484619\n",
      "Epoch [2/10] Batch [306/469] Loss D: -0.20241791009902954, loss G: -0.2907631993293762\n",
      "Epoch [2/10] Batch [307/469] Loss D: -0.23929181694984436, loss G: -0.38798287510871887\n",
      "Epoch [2/10] Batch [308/469] Loss D: -0.1688280701637268, loss G: -0.404997318983078\n",
      "Epoch [2/10] Batch [309/469] Loss D: -0.1989128589630127, loss G: -0.33877164125442505\n",
      "Epoch [2/10] Batch [310/469] Loss D: -0.2916850447654724, loss G: -0.2890607714653015\n",
      "Epoch [2/10] Batch [311/469] Loss D: -0.25446149706840515, loss G: -0.3428502082824707\n",
      "Epoch [2/10] Batch [312/469] Loss D: -0.19614821672439575, loss G: -0.35944944620132446\n",
      "Epoch [2/10] Batch [313/469] Loss D: -0.25407883524894714, loss G: -0.3901597559452057\n",
      "Epoch [2/10] Batch [314/469] Loss D: -0.3155656158924103, loss G: -0.1983531415462494\n",
      "Epoch [2/10] Batch [315/469] Loss D: -0.24089962244033813, loss G: -0.27141278982162476\n",
      "Epoch [2/10] Batch [316/469] Loss D: -0.2738701403141022, loss G: -0.3185774087905884\n",
      "Epoch [2/10] Batch [317/469] Loss D: -0.271848201751709, loss G: -0.30097696185112\n",
      "Epoch [2/10] Batch [318/469] Loss D: -0.2590399384498596, loss G: -0.28865933418273926\n",
      "Epoch [2/10] Batch [319/469] Loss D: -0.2400003969669342, loss G: -0.3112714886665344\n",
      "Epoch [2/10] Batch [320/469] Loss D: -0.2714165449142456, loss G: -0.30238139629364014\n",
      "Epoch [2/10] Batch [321/469] Loss D: -0.2754387855529785, loss G: -0.2526717782020569\n",
      "Epoch [2/10] Batch [322/469] Loss D: -0.23970255255699158, loss G: -0.35639554262161255\n",
      "Epoch [2/10] Batch [323/469] Loss D: -0.14968931674957275, loss G: -0.3393540382385254\n",
      "Epoch [2/10] Batch [324/469] Loss D: -0.17949897050857544, loss G: -0.298123300075531\n",
      "Epoch [2/10] Batch [325/469] Loss D: -0.15645182132720947, loss G: -0.30458471179008484\n",
      "Epoch [2/10] Batch [326/469] Loss D: -0.2198464274406433, loss G: -0.41205304861068726\n",
      "Epoch [2/10] Batch [327/469] Loss D: -0.255916029214859, loss G: -0.3064529597759247\n",
      "Epoch [2/10] Batch [328/469] Loss D: -0.18502354621887207, loss G: -0.23339258134365082\n",
      "Epoch [2/10] Batch [329/469] Loss D: -0.20827245712280273, loss G: -0.35970771312713623\n",
      "Epoch [2/10] Batch [330/469] Loss D: -0.2119395136833191, loss G: -0.4266658425331116\n",
      "Epoch [2/10] Batch [331/469] Loss D: -0.24085283279418945, loss G: -0.3085457384586334\n",
      "Epoch [2/10] Batch [332/469] Loss D: -0.2707242965698242, loss G: -0.29624783992767334\n",
      "Epoch [2/10] Batch [333/469] Loss D: -0.11756467819213867, loss G: -0.41737860441207886\n",
      "Epoch [2/10] Batch [334/469] Loss D: -0.2527013123035431, loss G: -0.2805885076522827\n",
      "Epoch [2/10] Batch [335/469] Loss D: -0.20794227719306946, loss G: -0.3468257784843445\n",
      "Epoch [2/10] Batch [336/469] Loss D: -0.21996229887008667, loss G: -0.3510899543762207\n",
      "Epoch [2/10] Batch [337/469] Loss D: -0.2735845744609833, loss G: -0.24321648478507996\n",
      "Epoch [2/10] Batch [338/469] Loss D: -0.21503591537475586, loss G: -0.35047125816345215\n",
      "Epoch [2/10] Batch [339/469] Loss D: -0.2861349582672119, loss G: -0.2945028841495514\n",
      "Epoch [2/10] Batch [340/469] Loss D: -0.16213375329971313, loss G: -0.38837748765945435\n",
      "Epoch [2/10] Batch [341/469] Loss D: -0.26546311378479004, loss G: -0.22432570159435272\n",
      "Epoch [2/10] Batch [342/469] Loss D: -0.250202476978302, loss G: -0.2963230013847351\n",
      "Epoch [2/10] Batch [343/469] Loss D: -0.23950982093811035, loss G: -0.33856040239334106\n",
      "Epoch [2/10] Batch [344/469] Loss D: -0.17020708322525024, loss G: -0.3147795498371124\n",
      "Epoch [2/10] Batch [345/469] Loss D: -0.10907918214797974, loss G: -0.2560877501964569\n",
      "Epoch [2/10] Batch [346/469] Loss D: -0.20588845014572144, loss G: -0.33768749237060547\n",
      "Epoch [2/10] Batch [347/469] Loss D: -0.24496084451675415, loss G: -0.24034839868545532\n",
      "Epoch [2/10] Batch [348/469] Loss D: -0.2470097541809082, loss G: -0.3206014335155487\n",
      "Epoch [2/10] Batch [349/469] Loss D: -0.2248694896697998, loss G: -0.33641517162323\n",
      "Epoch [2/10] Batch [350/469] Loss D: -0.27480292320251465, loss G: -0.26121634244918823\n",
      "Epoch [2/10] Batch [351/469] Loss D: -0.2890201807022095, loss G: -0.31687426567077637\n",
      "Epoch [2/10] Batch [352/469] Loss D: -0.16843444108963013, loss G: -0.4283069968223572\n",
      "Epoch [2/10] Batch [353/469] Loss D: -0.2384495735168457, loss G: -0.34029415249824524\n",
      "Epoch [2/10] Batch [354/469] Loss D: -0.2233397364616394, loss G: -0.24582967162132263\n",
      "Epoch [2/10] Batch [355/469] Loss D: -0.31877365708351135, loss G: -0.3035208284854889\n",
      "Epoch [2/10] Batch [356/469] Loss D: -0.22663941979408264, loss G: -0.3319084644317627\n",
      "Epoch [2/10] Batch [357/469] Loss D: -0.22543802857398987, loss G: -0.28442758321762085\n",
      "Epoch [2/10] Batch [358/469] Loss D: -0.15628308057785034, loss G: -0.3344922363758087\n",
      "Epoch [2/10] Batch [359/469] Loss D: -0.2883698344230652, loss G: -0.24661388993263245\n",
      "Epoch [2/10] Batch [360/469] Loss D: -0.2568091154098511, loss G: -0.30602070689201355\n",
      "Epoch [2/10] Batch [361/469] Loss D: -0.252220094203949, loss G: -0.35578545928001404\n",
      "Epoch [2/10] Batch [362/469] Loss D: -0.22040623426437378, loss G: -0.33765992522239685\n",
      "Epoch [2/10] Batch [363/469] Loss D: -0.24881654977798462, loss G: -0.2999197244644165\n",
      "Epoch [2/10] Batch [364/469] Loss D: -0.244770348072052, loss G: -0.2608037292957306\n",
      "Epoch [2/10] Batch [365/469] Loss D: -0.28222501277923584, loss G: -0.3153856694698334\n",
      "Epoch [2/10] Batch [366/469] Loss D: -0.23208898305892944, loss G: -0.31215333938598633\n",
      "Epoch [2/10] Batch [367/469] Loss D: -0.2597752809524536, loss G: -0.2940264940261841\n",
      "Epoch [2/10] Batch [368/469] Loss D: -0.255165159702301, loss G: -0.29967546463012695\n",
      "Epoch [2/10] Batch [369/469] Loss D: -0.243333637714386, loss G: -0.3143334984779358\n",
      "Epoch [2/10] Batch [370/469] Loss D: -0.2405858039855957, loss G: -0.3441411852836609\n",
      "Epoch [2/10] Batch [371/469] Loss D: -0.22730910778045654, loss G: -0.40739959478378296\n",
      "Epoch [2/10] Batch [372/469] Loss D: -0.14974772930145264, loss G: -0.47088056802749634\n",
      "Epoch [2/10] Batch [373/469] Loss D: -0.19779473543167114, loss G: -0.3471508324146271\n",
      "Epoch [2/10] Batch [374/469] Loss D: -0.186794251203537, loss G: -0.3255801200866699\n",
      "Epoch [2/10] Batch [375/469] Loss D: -0.2020474672317505, loss G: -0.3531126379966736\n",
      "Epoch [2/10] Batch [376/469] Loss D: -0.1601088047027588, loss G: -0.3902750611305237\n",
      "Epoch [2/10] Batch [377/469] Loss D: -0.1881347894668579, loss G: -0.33431804180145264\n",
      "Epoch [2/10] Batch [378/469] Loss D: -0.22508060932159424, loss G: -0.28993475437164307\n",
      "Epoch [2/10] Batch [379/469] Loss D: -0.2553636133670807, loss G: -0.2908945083618164\n",
      "Epoch [2/10] Batch [380/469] Loss D: -0.19015294313430786, loss G: -0.3156154751777649\n",
      "Epoch [2/10] Batch [381/469] Loss D: -0.25742268562316895, loss G: -0.28003671765327454\n",
      "Epoch [2/10] Batch [382/469] Loss D: -0.2753375470638275, loss G: -0.2314462661743164\n",
      "Epoch [2/10] Batch [383/469] Loss D: -0.3046879172325134, loss G: -0.336683452129364\n",
      "Epoch [2/10] Batch [384/469] Loss D: -0.23513507843017578, loss G: -0.32313597202301025\n",
      "Epoch [2/10] Batch [385/469] Loss D: -0.26859697699546814, loss G: -0.27034062147140503\n",
      "Epoch [2/10] Batch [386/469] Loss D: -0.292263925075531, loss G: -0.2634626626968384\n",
      "Epoch [2/10] Batch [387/469] Loss D: -0.30501365661621094, loss G: -0.3792659640312195\n",
      "Epoch [2/10] Batch [388/469] Loss D: -0.2497323751449585, loss G: -0.30175450444221497\n",
      "Epoch [2/10] Batch [389/469] Loss D: -0.22291842103004456, loss G: -0.3265891671180725\n",
      "Epoch [2/10] Batch [390/469] Loss D: -0.22688663005828857, loss G: -0.2809895873069763\n",
      "Epoch [2/10] Batch [391/469] Loss D: -0.21307379007339478, loss G: -0.3773244023323059\n",
      "Epoch [2/10] Batch [392/469] Loss D: -0.24337360262870789, loss G: -0.2763661742210388\n",
      "Epoch [2/10] Batch [393/469] Loss D: -0.21154087781906128, loss G: -0.2996332347393036\n",
      "Epoch [2/10] Batch [394/469] Loss D: -0.25387829542160034, loss G: -0.4084310531616211\n",
      "Epoch [2/10] Batch [395/469] Loss D: -0.2574188709259033, loss G: -0.32600390911102295\n",
      "Epoch [2/10] Batch [396/469] Loss D: -0.220668762922287, loss G: -0.26363080739974976\n",
      "Epoch [2/10] Batch [397/469] Loss D: -0.2649412155151367, loss G: -0.34949684143066406\n",
      "Epoch [2/10] Batch [398/469] Loss D: -0.27639949321746826, loss G: -0.3016993999481201\n",
      "Epoch [2/10] Batch [399/469] Loss D: -0.33490240573883057, loss G: -0.18314313888549805\n",
      "Epoch [2/10] Batch [400/469] Loss D: -0.31420469284057617, loss G: -0.29219117760658264\n",
      "Epoch [2/10] Batch [401/469] Loss D: -0.30004850029945374, loss G: -0.34295016527175903\n",
      "Epoch [2/10] Batch [402/469] Loss D: -0.2509213984012604, loss G: -0.29383575916290283\n",
      "Epoch [2/10] Batch [403/469] Loss D: -0.3254714608192444, loss G: -0.25381678342819214\n",
      "Epoch [2/10] Batch [404/469] Loss D: -0.3204333484172821, loss G: -0.18955117464065552\n",
      "Epoch [2/10] Batch [405/469] Loss D: -0.32959413528442383, loss G: -0.3842361569404602\n",
      "Epoch [2/10] Batch [406/469] Loss D: -0.25845271348953247, loss G: -0.2674559950828552\n",
      "Epoch [2/10] Batch [407/469] Loss D: -0.2105666697025299, loss G: -0.2233962118625641\n",
      "Epoch [2/10] Batch [408/469] Loss D: -0.23295313119888306, loss G: -0.39900827407836914\n",
      "Epoch [2/10] Batch [409/469] Loss D: -0.19603443145751953, loss G: -0.334262490272522\n",
      "Epoch [2/10] Batch [410/469] Loss D: -0.1827317476272583, loss G: -0.3219158351421356\n",
      "Epoch [2/10] Batch [411/469] Loss D: -0.20862486958503723, loss G: -0.26848047971725464\n",
      "Epoch [2/10] Batch [412/469] Loss D: -0.17397984862327576, loss G: -0.34278106689453125\n",
      "Epoch [2/10] Batch [413/469] Loss D: -0.21030020713806152, loss G: -0.30693474411964417\n",
      "Epoch [2/10] Batch [414/469] Loss D: -0.26182639598846436, loss G: -0.3418934643268585\n",
      "Epoch [2/10] Batch [415/469] Loss D: -0.22561794519424438, loss G: -0.30790644884109497\n",
      "Epoch [2/10] Batch [416/469] Loss D: -0.20869866013526917, loss G: -0.35979339480400085\n",
      "Epoch [2/10] Batch [417/469] Loss D: -0.3082110285758972, loss G: -0.31277281045913696\n",
      "Epoch [2/10] Batch [418/469] Loss D: -0.2513222396373749, loss G: -0.4090677499771118\n",
      "Epoch [2/10] Batch [419/469] Loss D: -0.2694556713104248, loss G: -0.3026852011680603\n",
      "Epoch [2/10] Batch [420/469] Loss D: -0.29410499334335327, loss G: -0.26777857542037964\n",
      "Epoch [2/10] Batch [421/469] Loss D: -0.23445147275924683, loss G: -0.4090467691421509\n",
      "Epoch [2/10] Batch [422/469] Loss D: -0.21666204929351807, loss G: -0.31603503227233887\n",
      "Epoch [2/10] Batch [423/469] Loss D: -0.24231162667274475, loss G: -0.31952667236328125\n",
      "Epoch [2/10] Batch [424/469] Loss D: -0.21980911493301392, loss G: -0.28586292266845703\n",
      "Epoch [2/10] Batch [425/469] Loss D: -0.2328435778617859, loss G: -0.36738744378089905\n",
      "Epoch [2/10] Batch [426/469] Loss D: -0.24728244543075562, loss G: -0.27512049674987793\n",
      "Epoch [2/10] Batch [427/469] Loss D: -0.26130563020706177, loss G: -0.29351484775543213\n",
      "Epoch [2/10] Batch [428/469] Loss D: -0.2682158946990967, loss G: -0.33056432008743286\n",
      "Epoch [2/10] Batch [429/469] Loss D: -0.2951912581920624, loss G: -0.3568251132965088\n",
      "Epoch [2/10] Batch [430/469] Loss D: -0.24267426133155823, loss G: -0.3096546530723572\n",
      "Epoch [2/10] Batch [431/469] Loss D: -0.2720019519329071, loss G: -0.2915802597999573\n",
      "Epoch [2/10] Batch [432/469] Loss D: -0.22145557403564453, loss G: -0.3323758840560913\n",
      "Epoch [2/10] Batch [433/469] Loss D: -0.2240949273109436, loss G: -0.357837438583374\n",
      "Epoch [2/10] Batch [434/469] Loss D: -0.2150876522064209, loss G: -0.2896912097930908\n",
      "Epoch [2/10] Batch [435/469] Loss D: -0.20637565851211548, loss G: -0.2692643105983734\n",
      "Epoch [2/10] Batch [436/469] Loss D: -0.2290371060371399, loss G: -0.3407028317451477\n",
      "Epoch [2/10] Batch [437/469] Loss D: -0.2829678952693939, loss G: -0.31847143173217773\n",
      "Epoch [2/10] Batch [438/469] Loss D: -0.3189757466316223, loss G: -0.25461262464523315\n",
      "Epoch [2/10] Batch [439/469] Loss D: -0.29276353120803833, loss G: -0.25196248292922974\n",
      "Epoch [2/10] Batch [440/469] Loss D: -0.3097127079963684, loss G: -0.31166183948516846\n",
      "Epoch [2/10] Batch [441/469] Loss D: -0.2554352879524231, loss G: -0.32584407925605774\n",
      "Epoch [2/10] Batch [442/469] Loss D: -0.32574722170829773, loss G: -0.20865193009376526\n",
      "Epoch [2/10] Batch [443/469] Loss D: -0.24935315549373627, loss G: -0.3103303611278534\n",
      "Epoch [2/10] Batch [444/469] Loss D: -0.24984896183013916, loss G: -0.31357401609420776\n",
      "Epoch [2/10] Batch [445/469] Loss D: -0.3673815131187439, loss G: -0.19545041024684906\n",
      "Epoch [2/10] Batch [446/469] Loss D: -0.29716822504997253, loss G: -0.4057486057281494\n",
      "Epoch [2/10] Batch [447/469] Loss D: -0.31152230501174927, loss G: -0.27739018201828003\n",
      "Epoch [2/10] Batch [448/469] Loss D: -0.31255465745925903, loss G: -0.22815224528312683\n",
      "Epoch [2/10] Batch [449/469] Loss D: -0.2906462550163269, loss G: -0.3807089328765869\n",
      "Epoch [2/10] Batch [450/469] Loss D: -0.26821914315223694, loss G: -0.3191872239112854\n",
      "Epoch [2/10] Batch [451/469] Loss D: -0.21339571475982666, loss G: -0.28706714510917664\n",
      "Epoch [2/10] Batch [452/469] Loss D: -0.21112555265426636, loss G: -0.3523278534412384\n",
      "Epoch [2/10] Batch [453/469] Loss D: -0.23675215244293213, loss G: -0.3149438202381134\n",
      "Epoch [2/10] Batch [454/469] Loss D: -0.25343841314315796, loss G: -0.24520975351333618\n",
      "Epoch [2/10] Batch [455/469] Loss D: -0.2715301513671875, loss G: -0.3243600130081177\n",
      "Epoch [2/10] Batch [456/469] Loss D: -0.2905771732330322, loss G: -0.3506805896759033\n",
      "Epoch [2/10] Batch [457/469] Loss D: -0.2621355652809143, loss G: -0.31193163990974426\n",
      "Epoch [2/10] Batch [458/469] Loss D: -0.29426276683807373, loss G: -0.22781191766262054\n",
      "Epoch [2/10] Batch [459/469] Loss D: -0.19810813665390015, loss G: -0.3199712038040161\n",
      "Epoch [2/10] Batch [460/469] Loss D: -0.21359649300575256, loss G: -0.30312085151672363\n",
      "Epoch [2/10] Batch [461/469] Loss D: -0.23372089862823486, loss G: -0.3796476721763611\n",
      "Epoch [2/10] Batch [462/469] Loss D: -0.18704676628112793, loss G: -0.4266199469566345\n",
      "Epoch [2/10] Batch [463/469] Loss D: -0.2066141963005066, loss G: -0.27841341495513916\n",
      "Epoch [2/10] Batch [464/469] Loss D: -0.22236675024032593, loss G: -0.26815512776374817\n",
      "Epoch [2/10] Batch [465/469] Loss D: -0.1917228102684021, loss G: -0.3831791281700134\n",
      "Epoch [2/10] Batch [466/469] Loss D: -0.2783749997615814, loss G: -0.2835980951786041\n",
      "Epoch [2/10] Batch [467/469] Loss D: -0.32553234696388245, loss G: -0.20920199155807495\n",
      "Epoch [2/10] Batch [468/469] Loss D: -0.2690804898738861, loss G: -0.3202182948589325\n",
      "Epoch [2/10] Batch [469/469] Loss D: -0.30897998809814453, loss G: -0.350676029920578\n",
      "Epoch [3/10] Batch [1/469] Loss D: -0.29084908962249756, loss G: -0.3080403208732605\n",
      "Epoch [3/10] Batch [2/469] Loss D: -0.2963674068450928, loss G: -0.23066210746765137\n",
      "Epoch [3/10] Batch [3/469] Loss D: -0.28926610946655273, loss G: -0.24800801277160645\n",
      "Epoch [3/10] Batch [4/469] Loss D: -0.28462135791778564, loss G: -0.3149622678756714\n",
      "Epoch [3/10] Batch [5/469] Loss D: -0.29657262563705444, loss G: -0.22896990180015564\n",
      "Epoch [3/10] Batch [6/469] Loss D: -0.28094717860221863, loss G: -0.3044678866863251\n",
      "Epoch [3/10] Batch [7/469] Loss D: -0.2892952561378479, loss G: -0.3265712261199951\n",
      "Epoch [3/10] Batch [8/469] Loss D: -0.2829439043998718, loss G: -0.31729763746261597\n",
      "Epoch [3/10] Batch [9/469] Loss D: -0.2881210446357727, loss G: -0.27934032678604126\n",
      "Epoch [3/10] Batch [10/469] Loss D: -0.31149718165397644, loss G: -0.24838843941688538\n",
      "Epoch [3/10] Batch [11/469] Loss D: -0.2987484931945801, loss G: -0.39464443922042847\n",
      "Epoch [3/10] Batch [12/469] Loss D: -0.269789457321167, loss G: -0.24089820683002472\n",
      "Epoch [3/10] Batch [13/469] Loss D: -0.30041056871414185, loss G: -0.2972199618816376\n",
      "Epoch [3/10] Batch [14/469] Loss D: -0.24244049191474915, loss G: -0.30782461166381836\n",
      "Epoch [3/10] Batch [15/469] Loss D: -0.320547878742218, loss G: -0.29821616411209106\n",
      "Epoch [3/10] Batch [16/469] Loss D: -0.31993821263313293, loss G: -0.2392958402633667\n",
      "Epoch [3/10] Batch [17/469] Loss D: -0.22513079643249512, loss G: -0.39216864109039307\n",
      "Epoch [3/10] Batch [18/469] Loss D: -0.1907203197479248, loss G: -0.36511144042015076\n",
      "Epoch [3/10] Batch [19/469] Loss D: -0.3176829516887665, loss G: -0.17199309170246124\n",
      "Epoch [3/10] Batch [20/469] Loss D: -0.2459806501865387, loss G: -0.33116263151168823\n",
      "Epoch [3/10] Batch [21/469] Loss D: -0.2521519064903259, loss G: -0.3273260295391083\n",
      "Epoch [3/10] Batch [22/469] Loss D: -0.2090991735458374, loss G: -0.22677437961101532\n",
      "Epoch [3/10] Batch [23/469] Loss D: -0.1467379927635193, loss G: -0.33842554688453674\n",
      "Epoch [3/10] Batch [24/469] Loss D: -0.21509987115859985, loss G: -0.5401803255081177\n",
      "Epoch [3/10] Batch [25/469] Loss D: -0.2747180461883545, loss G: -0.24471741914749146\n",
      "Epoch [3/10] Batch [26/469] Loss D: -0.3239407241344452, loss G: -0.17195019125938416\n",
      "Epoch [3/10] Batch [27/469] Loss D: -0.23445510864257812, loss G: -0.3702135682106018\n",
      "Epoch [3/10] Batch [28/469] Loss D: -0.27977654337882996, loss G: -0.41747480630874634\n",
      "Epoch [3/10] Batch [29/469] Loss D: -0.23828285932540894, loss G: -0.2956872284412384\n",
      "Epoch [3/10] Batch [30/469] Loss D: -0.31353959441185, loss G: -0.22134160995483398\n",
      "Epoch [3/10] Batch [31/469] Loss D: -0.19851401448249817, loss G: -0.35307371616363525\n",
      "Epoch [3/10] Batch [32/469] Loss D: -0.24320769309997559, loss G: -0.34100884199142456\n",
      "Epoch [3/10] Batch [33/469] Loss D: -0.10976859927177429, loss G: -0.32479333877563477\n",
      "Epoch [3/10] Batch [34/469] Loss D: -0.2354581356048584, loss G: -0.25347572565078735\n",
      "Epoch [3/10] Batch [35/469] Loss D: -0.15108975768089294, loss G: -0.3105539381504059\n",
      "Epoch [3/10] Batch [36/469] Loss D: -0.24055838584899902, loss G: -0.34802162647247314\n",
      "Epoch [3/10] Batch [37/469] Loss D: -0.3070141673088074, loss G: -0.25151652097702026\n",
      "Epoch [3/10] Batch [38/469] Loss D: -0.2889191806316376, loss G: -0.2662886381149292\n",
      "Epoch [3/10] Batch [39/469] Loss D: -0.26271724700927734, loss G: -0.30274510383605957\n",
      "Epoch [3/10] Batch [40/469] Loss D: -0.3038199543952942, loss G: -0.298823744058609\n",
      "Epoch [3/10] Batch [41/469] Loss D: -0.34805619716644287, loss G: -0.21540597081184387\n",
      "Epoch [3/10] Batch [42/469] Loss D: -0.3697987496852875, loss G: -0.28321582078933716\n",
      "Epoch [3/10] Batch [43/469] Loss D: -0.31907302141189575, loss G: -0.33752039074897766\n",
      "Epoch [3/10] Batch [44/469] Loss D: -0.25045743584632874, loss G: -0.33953332901000977\n",
      "Epoch [3/10] Batch [45/469] Loss D: -0.29543423652648926, loss G: -0.2555409073829651\n",
      "Epoch [3/10] Batch [46/469] Loss D: -0.2794913351535797, loss G: -0.21715790033340454\n",
      "Epoch [3/10] Batch [47/469] Loss D: -0.3011712431907654, loss G: -0.2983255386352539\n",
      "Epoch [3/10] Batch [48/469] Loss D: -0.28069791197776794, loss G: -0.3937753438949585\n",
      "Epoch [3/10] Batch [49/469] Loss D: -0.2956402599811554, loss G: -0.32785865664482117\n",
      "Epoch [3/10] Batch [50/469] Loss D: -0.25020137429237366, loss G: -0.2263411283493042\n",
      "Epoch [3/10] Batch [51/469] Loss D: -0.2497614622116089, loss G: -0.30916881561279297\n",
      "Epoch [3/10] Batch [52/469] Loss D: -0.3179698586463928, loss G: -0.35797518491744995\n",
      "Epoch [3/10] Batch [53/469] Loss D: -0.2515551447868347, loss G: -0.2772802412509918\n",
      "Epoch [3/10] Batch [54/469] Loss D: -0.32651862502098083, loss G: -0.2670624256134033\n",
      "Epoch [3/10] Batch [55/469] Loss D: -0.2839527130126953, loss G: -0.31557032465934753\n",
      "Epoch [3/10] Batch [56/469] Loss D: -0.31236520409584045, loss G: -0.22886767983436584\n",
      "Epoch [3/10] Batch [57/469] Loss D: -0.29177772998809814, loss G: -0.2724111080169678\n",
      "Epoch [3/10] Batch [58/469] Loss D: -0.2769668996334076, loss G: -0.357606440782547\n",
      "Epoch [3/10] Batch [59/469] Loss D: -0.28141626715660095, loss G: -0.37089598178863525\n",
      "Epoch [3/10] Batch [60/469] Loss D: -0.2570532560348511, loss G: -0.25830525159835815\n",
      "Epoch [3/10] Batch [61/469] Loss D: -0.3822159767150879, loss G: -0.2871705889701843\n",
      "Epoch [3/10] Batch [62/469] Loss D: -0.14326530694961548, loss G: -0.41530388593673706\n",
      "Epoch [3/10] Batch [63/469] Loss D: -0.19907450675964355, loss G: -0.2713385224342346\n",
      "Epoch [3/10] Batch [64/469] Loss D: -0.3185993731021881, loss G: -0.26153725385665894\n",
      "Epoch [3/10] Batch [65/469] Loss D: -0.31239813566207886, loss G: -0.33005398511886597\n",
      "Epoch [3/10] Batch [66/469] Loss D: -0.2655990421772003, loss G: -0.3192041218280792\n",
      "Epoch [3/10] Batch [67/469] Loss D: -0.26990142464637756, loss G: -0.3377322852611542\n",
      "Epoch [3/10] Batch [68/469] Loss D: -0.2291710376739502, loss G: -0.35191813111305237\n",
      "Epoch [3/10] Batch [69/469] Loss D: -0.2166372835636139, loss G: -0.22940880060195923\n",
      "Epoch [3/10] Batch [70/469] Loss D: -0.1817081868648529, loss G: -0.33263713121414185\n",
      "Epoch [3/10] Batch [71/469] Loss D: -0.27438613772392273, loss G: -0.25267452001571655\n",
      "Epoch [3/10] Batch [72/469] Loss D: -0.2158043384552002, loss G: -0.3628169298171997\n",
      "Epoch [3/10] Batch [73/469] Loss D: -0.23278048634529114, loss G: -0.2800930142402649\n",
      "Epoch [3/10] Batch [74/469] Loss D: -0.3328703045845032, loss G: -0.3370588719844818\n",
      "Epoch [3/10] Batch [75/469] Loss D: -0.289620041847229, loss G: -0.18353313207626343\n",
      "Epoch [3/10] Batch [76/469] Loss D: -0.23091572523117065, loss G: -0.2593209743499756\n",
      "Epoch [3/10] Batch [77/469] Loss D: -0.3910229206085205, loss G: -0.3529188930988312\n",
      "Epoch [3/10] Batch [78/469] Loss D: -0.33753955364227295, loss G: -0.28308340907096863\n",
      "Epoch [3/10] Batch [79/469] Loss D: -0.33248305320739746, loss G: -0.28018277883529663\n",
      "Epoch [3/10] Batch [80/469] Loss D: -0.3203563392162323, loss G: -0.3239890933036804\n",
      "Epoch [3/10] Batch [81/469] Loss D: -0.33108648657798767, loss G: -0.3351253867149353\n",
      "Epoch [3/10] Batch [82/469] Loss D: -0.3351273536682129, loss G: -0.20753887295722961\n",
      "Epoch [3/10] Batch [83/469] Loss D: -0.34637826681137085, loss G: -0.24405671656131744\n",
      "Epoch [3/10] Batch [84/469] Loss D: -0.27202099561691284, loss G: -0.38412585854530334\n",
      "Epoch [3/10] Batch [85/469] Loss D: -0.28377485275268555, loss G: -0.39385780692100525\n",
      "Epoch [3/10] Batch [86/469] Loss D: -0.2623138129711151, loss G: -0.335213840007782\n",
      "Epoch [3/10] Batch [87/469] Loss D: -0.2773136496543884, loss G: -0.2340795248746872\n",
      "Epoch [3/10] Batch [88/469] Loss D: -0.2780247926712036, loss G: -0.3693729043006897\n",
      "Epoch [3/10] Batch [89/469] Loss D: -0.2909988462924957, loss G: -0.31516045331954956\n",
      "Epoch [3/10] Batch [90/469] Loss D: -0.2613137364387512, loss G: -0.3396221399307251\n",
      "Epoch [3/10] Batch [91/469] Loss D: -0.2783201336860657, loss G: -0.30233001708984375\n",
      "Epoch [3/10] Batch [92/469] Loss D: -0.28930217027664185, loss G: -0.321370393037796\n",
      "Epoch [3/10] Batch [93/469] Loss D: -0.29424047470092773, loss G: -0.2757840156555176\n",
      "Epoch [3/10] Batch [94/469] Loss D: -0.3248410224914551, loss G: -0.2651456594467163\n",
      "Epoch [3/10] Batch [95/469] Loss D: -0.2622835636138916, loss G: -0.3214120864868164\n",
      "Epoch [3/10] Batch [96/469] Loss D: -0.24054807424545288, loss G: -0.34476161003112793\n",
      "Epoch [3/10] Batch [97/469] Loss D: -0.2306937575340271, loss G: -0.41945183277130127\n",
      "Epoch [3/10] Batch [98/469] Loss D: -0.27205193042755127, loss G: -0.24242287874221802\n",
      "Epoch [3/10] Batch [99/469] Loss D: -0.3277336657047272, loss G: -0.2948926091194153\n",
      "Epoch [3/10] Batch [100/469] Loss D: -0.32913029193878174, loss G: -0.2873063087463379\n",
      "Epoch [3/10] Batch [101/469] Loss D: -0.33170145750045776, loss G: -0.27789565920829773\n",
      "Epoch [3/10] Batch [102/469] Loss D: -0.3459661900997162, loss G: -0.2789151668548584\n",
      "Epoch [3/10] Batch [103/469] Loss D: -0.27757662534713745, loss G: -0.2317669540643692\n",
      "Epoch [3/10] Batch [104/469] Loss D: -0.2874167561531067, loss G: -0.4481421709060669\n",
      "Epoch [3/10] Batch [105/469] Loss D: -0.24822616577148438, loss G: -0.32902857661247253\n",
      "Epoch [3/10] Batch [106/469] Loss D: -0.2898906171321869, loss G: -0.2191321849822998\n",
      "Epoch [3/10] Batch [107/469] Loss D: -0.2995373010635376, loss G: -0.23790565133094788\n",
      "Epoch [3/10] Batch [108/469] Loss D: -0.16666215658187866, loss G: -0.38487708568573\n",
      "Epoch [3/10] Batch [109/469] Loss D: -0.2602585554122925, loss G: -0.3873453140258789\n",
      "Epoch [3/10] Batch [110/469] Loss D: -0.2528683841228485, loss G: -0.22544065117835999\n",
      "Epoch [3/10] Batch [111/469] Loss D: -0.2736368179321289, loss G: -0.3525296449661255\n",
      "Epoch [3/10] Batch [112/469] Loss D: -0.25805017352104187, loss G: -0.3434387743473053\n",
      "Epoch [3/10] Batch [113/469] Loss D: -0.323941707611084, loss G: -0.2154110223054886\n",
      "Epoch [3/10] Batch [114/469] Loss D: -0.3021618127822876, loss G: -0.34764212369918823\n",
      "Epoch [3/10] Batch [115/469] Loss D: -0.3200860619544983, loss G: -0.17818176746368408\n",
      "Epoch [3/10] Batch [116/469] Loss D: -0.3579658269882202, loss G: -0.3163970708847046\n",
      "Epoch [3/10] Batch [117/469] Loss D: -0.32557642459869385, loss G: -0.20264068245887756\n",
      "Epoch [3/10] Batch [118/469] Loss D: -0.31828486919403076, loss G: -0.2734670042991638\n",
      "Epoch [3/10] Batch [119/469] Loss D: -0.2920249104499817, loss G: -0.41203609108924866\n",
      "Epoch [3/10] Batch [120/469] Loss D: -0.28641587495803833, loss G: -0.298267662525177\n",
      "Epoch [3/10] Batch [121/469] Loss D: -0.32628875970840454, loss G: -0.23382946848869324\n",
      "Epoch [3/10] Batch [122/469] Loss D: -0.21216025948524475, loss G: -0.46284541487693787\n",
      "Epoch [3/10] Batch [123/469] Loss D: -0.19300216436386108, loss G: -0.46725916862487793\n",
      "Epoch [3/10] Batch [124/469] Loss D: -0.19191759824752808, loss G: -0.34399551153182983\n",
      "Epoch [3/10] Batch [125/469] Loss D: -0.21779805421829224, loss G: -0.26506248116493225\n",
      "Epoch [3/10] Batch [126/469] Loss D: -0.2817900776863098, loss G: -0.2528574466705322\n",
      "Epoch [3/10] Batch [127/469] Loss D: -0.2516152560710907, loss G: -0.25498294830322266\n",
      "Epoch [3/10] Batch [128/469] Loss D: -0.3089308738708496, loss G: -0.3082859218120575\n",
      "Epoch [3/10] Batch [129/469] Loss D: -0.35962361097335815, loss G: -0.25345516204833984\n",
      "Epoch [3/10] Batch [130/469] Loss D: -0.28057989478111267, loss G: -0.3299545645713806\n",
      "Epoch [3/10] Batch [131/469] Loss D: -0.2787003517150879, loss G: -0.40783464908599854\n",
      "Epoch [3/10] Batch [132/469] Loss D: -0.22638750076293945, loss G: -0.26604461669921875\n",
      "Epoch [3/10] Batch [133/469] Loss D: -0.1892077922821045, loss G: -0.19988681375980377\n",
      "Epoch [3/10] Batch [134/469] Loss D: -0.19157519936561584, loss G: -0.4000575542449951\n",
      "Epoch [3/10] Batch [135/469] Loss D: -0.19898730516433716, loss G: -0.39642009139060974\n",
      "Epoch [3/10] Batch [136/469] Loss D: -0.2574452757835388, loss G: -0.3139626085758209\n",
      "Epoch [3/10] Batch [137/469] Loss D: -0.20827916264533997, loss G: -0.20759156346321106\n",
      "Epoch [3/10] Batch [138/469] Loss D: -0.24264144897460938, loss G: -0.17650039494037628\n",
      "Epoch [3/10] Batch [139/469] Loss D: -0.2812459468841553, loss G: -0.40456268191337585\n",
      "Epoch [3/10] Batch [140/469] Loss D: -0.24744999408721924, loss G: -0.36909109354019165\n",
      "Epoch [3/10] Batch [141/469] Loss D: -0.2460862100124359, loss G: -0.23595917224884033\n",
      "Epoch [3/10] Batch [142/469] Loss D: -0.30475127696990967, loss G: -0.24841207265853882\n",
      "Epoch [3/10] Batch [143/469] Loss D: -0.31896933913230896, loss G: -0.256244421005249\n",
      "Epoch [3/10] Batch [144/469] Loss D: -0.30492380261421204, loss G: -0.3136516213417053\n",
      "Epoch [3/10] Batch [145/469] Loss D: -0.24174118041992188, loss G: -0.39590948820114136\n",
      "Epoch [3/10] Batch [146/469] Loss D: -0.24629205465316772, loss G: -0.25597265362739563\n",
      "Epoch [3/10] Batch [147/469] Loss D: -0.18558651208877563, loss G: -0.25274360179901123\n",
      "Epoch [3/10] Batch [148/469] Loss D: -0.22630691528320312, loss G: -0.3275856375694275\n",
      "Epoch [3/10] Batch [149/469] Loss D: -0.20758724212646484, loss G: -0.4404921233654022\n",
      "Epoch [3/10] Batch [150/469] Loss D: -0.23952677845954895, loss G: -0.23151008784770966\n",
      "Epoch [3/10] Batch [151/469] Loss D: -0.25850602984428406, loss G: -0.30291274189949036\n",
      "Epoch [3/10] Batch [152/469] Loss D: -0.3308854103088379, loss G: -0.25396424531936646\n",
      "Epoch [3/10] Batch [153/469] Loss D: -0.3346517086029053, loss G: -0.335835337638855\n",
      "Epoch [3/10] Batch [154/469] Loss D: -0.2729533314704895, loss G: -0.31717613339424133\n",
      "Epoch [3/10] Batch [155/469] Loss D: -0.3141321539878845, loss G: -0.22806036472320557\n",
      "Epoch [3/10] Batch [156/469] Loss D: -0.25956231355667114, loss G: -0.4694819450378418\n",
      "Epoch [3/10] Batch [157/469] Loss D: -0.2943999767303467, loss G: -0.20983846485614777\n",
      "Epoch [3/10] Batch [158/469] Loss D: -0.2538047730922699, loss G: -0.292389452457428\n",
      "Epoch [3/10] Batch [159/469] Loss D: -0.23605501651763916, loss G: -0.43215513229370117\n",
      "Epoch [3/10] Batch [160/469] Loss D: -0.3012588620185852, loss G: -0.17590203881263733\n",
      "Epoch [3/10] Batch [161/469] Loss D: -0.32990026473999023, loss G: -0.3932250738143921\n",
      "Epoch [3/10] Batch [162/469] Loss D: -0.31179332733154297, loss G: -0.19147619605064392\n",
      "Epoch [3/10] Batch [163/469] Loss D: -0.31623411178588867, loss G: -0.22244521975517273\n",
      "Epoch [3/10] Batch [164/469] Loss D: -0.3474554419517517, loss G: -0.36628612875938416\n",
      "Epoch [3/10] Batch [165/469] Loss D: -0.34465402364730835, loss G: -0.24309226870536804\n",
      "Epoch [3/10] Batch [166/469] Loss D: -0.19877582788467407, loss G: -0.3656328618526459\n",
      "Epoch [3/10] Batch [167/469] Loss D: -0.28058624267578125, loss G: -0.33414918184280396\n",
      "Epoch [3/10] Batch [168/469] Loss D: -0.1445942223072052, loss G: -0.4877057373523712\n",
      "Epoch [3/10] Batch [169/469] Loss D: -0.27160364389419556, loss G: -0.252136766910553\n",
      "Epoch [3/10] Batch [170/469] Loss D: -0.2763262987136841, loss G: -0.3266672194004059\n",
      "Epoch [3/10] Batch [171/469] Loss D: -0.27762341499328613, loss G: -0.2766909897327423\n",
      "Epoch [3/10] Batch [172/469] Loss D: -0.23496657609939575, loss G: -0.2816984951496124\n",
      "Epoch [3/10] Batch [173/469] Loss D: -0.2741961181163788, loss G: -0.2558474540710449\n",
      "Epoch [3/10] Batch [174/469] Loss D: -0.2856748700141907, loss G: -0.3714602589607239\n",
      "Epoch [3/10] Batch [175/469] Loss D: -0.2007235586643219, loss G: -0.3780350089073181\n",
      "Epoch [3/10] Batch [176/469] Loss D: -0.23184391856193542, loss G: -0.3598077893257141\n",
      "Epoch [3/10] Batch [177/469] Loss D: -0.32096388936042786, loss G: -0.26955491304397583\n",
      "Epoch [3/10] Batch [178/469] Loss D: -0.37215498089790344, loss G: -0.18889904022216797\n",
      "Epoch [3/10] Batch [179/469] Loss D: -0.28155750036239624, loss G: -0.4400375485420227\n",
      "Epoch [3/10] Batch [180/469] Loss D: -0.2943597435951233, loss G: -0.2943505644798279\n",
      "Epoch [3/10] Batch [181/469] Loss D: -0.284392774105072, loss G: -0.15867048501968384\n",
      "Epoch [3/10] Batch [182/469] Loss D: -0.36043059825897217, loss G: -0.3710006773471832\n",
      "Epoch [3/10] Batch [183/469] Loss D: -0.2583293616771698, loss G: -0.447397917509079\n",
      "Epoch [3/10] Batch [184/469] Loss D: -0.27479857206344604, loss G: -0.17814670503139496\n",
      "Epoch [3/10] Batch [185/469] Loss D: -0.2304014414548874, loss G: -0.30725207924842834\n",
      "Epoch [3/10] Batch [186/469] Loss D: -0.27706772089004517, loss G: -0.3233442008495331\n",
      "Epoch [3/10] Batch [187/469] Loss D: -0.2979077100753784, loss G: -0.2781217694282532\n",
      "Epoch [3/10] Batch [188/469] Loss D: -0.29155030846595764, loss G: -0.22710677981376648\n",
      "Epoch [3/10] Batch [189/469] Loss D: -0.291515588760376, loss G: -0.32103443145751953\n",
      "Epoch [3/10] Batch [190/469] Loss D: -0.26675164699554443, loss G: -0.3041127920150757\n",
      "Epoch [3/10] Batch [191/469] Loss D: -0.343927800655365, loss G: -0.2520088255405426\n",
      "Epoch [3/10] Batch [192/469] Loss D: -0.24584531784057617, loss G: -0.33884936571121216\n",
      "Epoch [3/10] Batch [193/469] Loss D: -0.30376237630844116, loss G: -0.3667681813240051\n",
      "Epoch [3/10] Batch [194/469] Loss D: -0.2854975461959839, loss G: -0.3073161542415619\n",
      "Epoch [3/10] Batch [195/469] Loss D: -0.29102832078933716, loss G: -0.2723456025123596\n",
      "Epoch [3/10] Batch [196/469] Loss D: -0.27698418498039246, loss G: -0.24384158849716187\n",
      "Epoch [3/10] Batch [197/469] Loss D: -0.35470759868621826, loss G: -0.3378486931324005\n",
      "Epoch [3/10] Batch [198/469] Loss D: -0.3354976773262024, loss G: -0.29468315839767456\n",
      "Epoch [3/10] Batch [199/469] Loss D: -0.34159886837005615, loss G: -0.17262814939022064\n",
      "Epoch [3/10] Batch [200/469] Loss D: -0.30147403478622437, loss G: -0.378559947013855\n",
      "Epoch [3/10] Batch [201/469] Loss D: -0.2502514719963074, loss G: -0.35483503341674805\n",
      "Epoch [3/10] Batch [202/469] Loss D: -0.2675834894180298, loss G: -0.20186744630336761\n",
      "Epoch [3/10] Batch [203/469] Loss D: -0.2893158793449402, loss G: -0.3469490110874176\n",
      "Epoch [3/10] Batch [204/469] Loss D: -0.2675771415233612, loss G: -0.3315286934375763\n",
      "Epoch [3/10] Batch [205/469] Loss D: -0.3079946041107178, loss G: -0.22387245297431946\n",
      "Epoch [3/10] Batch [206/469] Loss D: -0.3247729539871216, loss G: -0.24789303541183472\n",
      "Epoch [3/10] Batch [207/469] Loss D: -0.28969329595565796, loss G: -0.26501208543777466\n",
      "Epoch [3/10] Batch [208/469] Loss D: -0.3272138833999634, loss G: -0.2974814772605896\n",
      "Epoch [3/10] Batch [209/469] Loss D: -0.3896276354789734, loss G: -0.1969178020954132\n",
      "Epoch [3/10] Batch [210/469] Loss D: -0.3648911714553833, loss G: -0.2813495397567749\n",
      "Epoch [3/10] Batch [211/469] Loss D: -0.35909098386764526, loss G: -0.20471879839897156\n",
      "Epoch [3/10] Batch [212/469] Loss D: -0.3500058650970459, loss G: -0.3363794684410095\n",
      "Epoch [3/10] Batch [213/469] Loss D: -0.20212948322296143, loss G: -0.3581663966178894\n",
      "Epoch [3/10] Batch [214/469] Loss D: -0.328871488571167, loss G: -0.23353493213653564\n",
      "Epoch [3/10] Batch [215/469] Loss D: -0.31537455320358276, loss G: -0.23325705528259277\n",
      "Epoch [3/10] Batch [216/469] Loss D: -0.23187190294265747, loss G: -0.3484272360801697\n",
      "Epoch [3/10] Batch [217/469] Loss D: -0.30842965841293335, loss G: -0.18828649818897247\n",
      "Epoch [3/10] Batch [218/469] Loss D: -0.31132280826568604, loss G: -0.30058008432388306\n",
      "Epoch [3/10] Batch [219/469] Loss D: -0.2990878224372864, loss G: -0.4356657564640045\n",
      "Epoch [3/10] Batch [220/469] Loss D: -0.2588123679161072, loss G: -0.17994235455989838\n",
      "Epoch [3/10] Batch [221/469] Loss D: -0.34721463918685913, loss G: -0.31069156527519226\n",
      "Epoch [3/10] Batch [222/469] Loss D: -0.3427680730819702, loss G: -0.22457647323608398\n",
      "Epoch [3/10] Batch [223/469] Loss D: -0.33062851428985596, loss G: -0.24829597771167755\n",
      "Epoch [3/10] Batch [224/469] Loss D: -0.35865843296051025, loss G: -0.29533645510673523\n",
      "Epoch [3/10] Batch [225/469] Loss D: -0.27875983715057373, loss G: -0.2707274556159973\n",
      "Epoch [3/10] Batch [226/469] Loss D: -0.3140134811401367, loss G: -0.2125302255153656\n",
      "Epoch [3/10] Batch [227/469] Loss D: -0.30985063314437866, loss G: -0.365509957075119\n",
      "Epoch [3/10] Batch [228/469] Loss D: -0.31504058837890625, loss G: -0.316597044467926\n",
      "Epoch [3/10] Batch [229/469] Loss D: -0.39247655868530273, loss G: -0.16040125489234924\n",
      "Epoch [3/10] Batch [230/469] Loss D: -0.3657067120075226, loss G: -0.35924601554870605\n",
      "Epoch [3/10] Batch [231/469] Loss D: -0.33603435754776, loss G: -0.20123571157455444\n",
      "Epoch [3/10] Batch [232/469] Loss D: -0.2796647548675537, loss G: -0.26852110028266907\n",
      "Epoch [3/10] Batch [233/469] Loss D: -0.3290534019470215, loss G: -0.2664676010608673\n",
      "Epoch [3/10] Batch [234/469] Loss D: -0.2544156312942505, loss G: -0.3808703124523163\n",
      "Epoch [3/10] Batch [235/469] Loss D: -0.24220001697540283, loss G: -0.2780524492263794\n",
      "Epoch [3/10] Batch [236/469] Loss D: -0.3285233676433563, loss G: -0.2633838951587677\n",
      "Epoch [3/10] Batch [237/469] Loss D: -0.2804543375968933, loss G: -0.20440062880516052\n",
      "Epoch [3/10] Batch [238/469] Loss D: -0.33266448974609375, loss G: -0.2702717185020447\n",
      "Epoch [3/10] Batch [239/469] Loss D: -0.31345033645629883, loss G: -0.20955592393875122\n",
      "Epoch [3/10] Batch [240/469] Loss D: -0.31476932764053345, loss G: -0.3027808666229248\n",
      "Epoch [3/10] Batch [241/469] Loss D: -0.4169798791408539, loss G: -0.17750614881515503\n",
      "Epoch [3/10] Batch [242/469] Loss D: -0.32767966389656067, loss G: -0.253042608499527\n",
      "Epoch [3/10] Batch [243/469] Loss D: -0.29418182373046875, loss G: -0.3718581795692444\n",
      "Epoch [3/10] Batch [244/469] Loss D: -0.28283631801605225, loss G: -0.16397695243358612\n",
      "Epoch [3/10] Batch [245/469] Loss D: -0.2820754647254944, loss G: -0.24141114950180054\n",
      "Epoch [3/10] Batch [246/469] Loss D: -0.2656917870044708, loss G: -0.40287190675735474\n",
      "Epoch [3/10] Batch [247/469] Loss D: -0.21991360187530518, loss G: -0.19642680883407593\n",
      "Epoch [3/10] Batch [248/469] Loss D: -0.2898901104927063, loss G: -0.293484628200531\n",
      "Epoch [3/10] Batch [249/469] Loss D: -0.29142701625823975, loss G: -0.3652559518814087\n",
      "Epoch [3/10] Batch [250/469] Loss D: -0.3441571891307831, loss G: -0.2764285206794739\n",
      "Epoch [3/10] Batch [251/469] Loss D: -0.3410997986793518, loss G: -0.14752286672592163\n",
      "Epoch [3/10] Batch [252/469] Loss D: -0.25899580121040344, loss G: -0.37789928913116455\n",
      "Epoch [3/10] Batch [253/469] Loss D: -0.37271836400032043, loss G: -0.23420356214046478\n",
      "Epoch [3/10] Batch [254/469] Loss D: -0.33822301030158997, loss G: -0.36969655752182007\n",
      "Epoch [3/10] Batch [255/469] Loss D: -0.3234705924987793, loss G: -0.1965046226978302\n",
      "Epoch [3/10] Batch [256/469] Loss D: -0.38368213176727295, loss G: -0.3893510103225708\n",
      "Epoch [3/10] Batch [257/469] Loss D: -0.24320125579833984, loss G: -0.3159124553203583\n",
      "Epoch [3/10] Batch [258/469] Loss D: -0.3437572121620178, loss G: -0.14115673303604126\n",
      "Epoch [3/10] Batch [259/469] Loss D: -0.2948041260242462, loss G: -0.31807076930999756\n",
      "Epoch [3/10] Batch [260/469] Loss D: -0.3577497601509094, loss G: -0.27223438024520874\n",
      "Epoch [3/10] Batch [261/469] Loss D: -0.31886032223701477, loss G: -0.18545246124267578\n",
      "Epoch [3/10] Batch [262/469] Loss D: -0.3042338490486145, loss G: -0.276112824678421\n",
      "Epoch [3/10] Batch [263/469] Loss D: -0.31764641404151917, loss G: -0.326051265001297\n",
      "Epoch [3/10] Batch [264/469] Loss D: -0.2582472562789917, loss G: -0.33246859908103943\n",
      "Epoch [3/10] Batch [265/469] Loss D: -0.26878809928894043, loss G: -0.27173614501953125\n",
      "Epoch [3/10] Batch [266/469] Loss D: -0.3650588393211365, loss G: -0.23469895124435425\n",
      "Epoch [3/10] Batch [267/469] Loss D: -0.3554297089576721, loss G: -0.3012542128562927\n",
      "Epoch [3/10] Batch [268/469] Loss D: -0.34155702590942383, loss G: -0.18627171218395233\n",
      "Epoch [3/10] Batch [269/469] Loss D: -0.29203295707702637, loss G: -0.37085747718811035\n",
      "Epoch [3/10] Batch [270/469] Loss D: -0.2578580379486084, loss G: -0.21998751163482666\n",
      "Epoch [3/10] Batch [271/469] Loss D: -0.2562376856803894, loss G: -0.2193828970193863\n",
      "Epoch [3/10] Batch [272/469] Loss D: -0.2761676013469696, loss G: -0.4939095675945282\n",
      "Epoch [3/10] Batch [273/469] Loss D: -0.23525190353393555, loss G: -0.41329365968704224\n",
      "Epoch [3/10] Batch [274/469] Loss D: -0.2883725166320801, loss G: -0.19004672765731812\n",
      "Epoch [3/10] Batch [275/469] Loss D: -0.24273556470870972, loss G: -0.3542855978012085\n",
      "Epoch [3/10] Batch [276/469] Loss D: -0.2552220821380615, loss G: -0.33291611075401306\n",
      "Epoch [3/10] Batch [277/469] Loss D: -0.17413657903671265, loss G: -0.3232780694961548\n",
      "Epoch [3/10] Batch [278/469] Loss D: -0.3107231855392456, loss G: -0.3147684335708618\n",
      "Epoch [3/10] Batch [279/469] Loss D: -0.2114112675189972, loss G: -0.3724243938922882\n",
      "Epoch [3/10] Batch [280/469] Loss D: -0.30191633105278015, loss G: -0.2157856523990631\n",
      "Epoch [3/10] Batch [281/469] Loss D: -0.3194347023963928, loss G: -0.3040250241756439\n",
      "Epoch [3/10] Batch [282/469] Loss D: -0.3146935701370239, loss G: -0.30530089139938354\n",
      "Epoch [3/10] Batch [283/469] Loss D: -0.41151970624923706, loss G: -0.20620113611221313\n",
      "Epoch [3/10] Batch [284/469] Loss D: -0.3584740161895752, loss G: -0.2355012744665146\n",
      "Epoch [3/10] Batch [285/469] Loss D: -0.3065544664859772, loss G: -0.34467613697052\n",
      "Epoch [3/10] Batch [286/469] Loss D: -0.26029837131500244, loss G: -0.18076077103614807\n",
      "Epoch [3/10] Batch [287/469] Loss D: -0.32819604873657227, loss G: -0.37396126985549927\n",
      "Epoch [3/10] Batch [288/469] Loss D: -0.3950667083263397, loss G: -0.1763181835412979\n",
      "Epoch [3/10] Batch [289/469] Loss D: -0.35056272149086, loss G: -0.28863510489463806\n",
      "Epoch [3/10] Batch [290/469] Loss D: -0.31554362177848816, loss G: -0.33440732955932617\n",
      "Epoch [3/10] Batch [291/469] Loss D: -0.2905566990375519, loss G: -0.15643751621246338\n",
      "Epoch [3/10] Batch [292/469] Loss D: -0.30398350954055786, loss G: -0.35891449451446533\n",
      "Epoch [3/10] Batch [293/469] Loss D: -0.3270476460456848, loss G: -0.24323120713233948\n",
      "Epoch [3/10] Batch [294/469] Loss D: -0.21969494223594666, loss G: -0.3139197528362274\n",
      "Epoch [3/10] Batch [295/469] Loss D: -0.2245137095451355, loss G: -0.2592785954475403\n",
      "Epoch [3/10] Batch [296/469] Loss D: -0.2584182620048523, loss G: -0.31098806858062744\n",
      "Epoch [3/10] Batch [297/469] Loss D: -0.31721460819244385, loss G: -0.1940510869026184\n",
      "Epoch [3/10] Batch [298/469] Loss D: -0.2575431764125824, loss G: -0.3700019121170044\n",
      "Epoch [3/10] Batch [299/469] Loss D: -0.3148047924041748, loss G: -0.27180927991867065\n",
      "Epoch [3/10] Batch [300/469] Loss D: -0.40013787150382996, loss G: -0.17302942276000977\n",
      "Epoch [3/10] Batch [301/469] Loss D: -0.3381834924221039, loss G: -0.3135429322719574\n",
      "Epoch [3/10] Batch [302/469] Loss D: -0.33688220381736755, loss G: -0.25353533029556274\n",
      "Epoch [3/10] Batch [303/469] Loss D: -0.32979995012283325, loss G: -0.30118221044540405\n",
      "Epoch [3/10] Batch [304/469] Loss D: -0.3093603253364563, loss G: -0.2694413959980011\n",
      "Epoch [3/10] Batch [305/469] Loss D: -0.29480546712875366, loss G: -0.23813524842262268\n",
      "Epoch [3/10] Batch [306/469] Loss D: -0.2436973750591278, loss G: -0.39144542813301086\n",
      "Epoch [3/10] Batch [307/469] Loss D: -0.3047219514846802, loss G: -0.36506563425064087\n",
      "Epoch [3/10] Batch [308/469] Loss D: -0.3600810766220093, loss G: -0.14838732779026031\n",
      "Epoch [3/10] Batch [309/469] Loss D: -0.35562068223953247, loss G: -0.27175045013427734\n",
      "Epoch [3/10] Batch [310/469] Loss D: -0.3903970420360565, loss G: -0.357708603143692\n",
      "Epoch [3/10] Batch [311/469] Loss D: -0.3273018002510071, loss G: -0.1759217232465744\n",
      "Epoch [3/10] Batch [312/469] Loss D: -0.2986011505126953, loss G: -0.30936044454574585\n",
      "Epoch [3/10] Batch [313/469] Loss D: -0.33972346782684326, loss G: -0.43206191062927246\n",
      "Epoch [3/10] Batch [314/469] Loss D: -0.3399105668067932, loss G: -0.18972188234329224\n",
      "Epoch [3/10] Batch [315/469] Loss D: -0.3588949143886566, loss G: -0.2512897849082947\n",
      "Epoch [3/10] Batch [316/469] Loss D: -0.34007537364959717, loss G: -0.36555081605911255\n",
      "Epoch [3/10] Batch [317/469] Loss D: -0.3035019040107727, loss G: -0.19228670001029968\n",
      "Epoch [3/10] Batch [318/469] Loss D: -0.36118751764297485, loss G: -0.2316625714302063\n",
      "Epoch [3/10] Batch [319/469] Loss D: -0.338797390460968, loss G: -0.4706958532333374\n",
      "Epoch [3/10] Batch [320/469] Loss D: -0.3022751808166504, loss G: -0.21138405799865723\n",
      "Epoch [3/10] Batch [321/469] Loss D: -0.3835267424583435, loss G: -0.16432316601276398\n",
      "Epoch [3/10] Batch [322/469] Loss D: -0.39789894223213196, loss G: -0.45638471841812134\n",
      "Epoch [3/10] Batch [323/469] Loss D: -0.2906215190887451, loss G: -0.2722938060760498\n",
      "Epoch [3/10] Batch [324/469] Loss D: -0.33449673652648926, loss G: -0.20072193443775177\n",
      "Epoch [3/10] Batch [325/469] Loss D: -0.3050198554992676, loss G: -0.3116149306297302\n",
      "Epoch [3/10] Batch [326/469] Loss D: -0.3388611972332001, loss G: -0.23253023624420166\n",
      "Epoch [3/10] Batch [327/469] Loss D: -0.35514771938323975, loss G: -0.2545958459377289\n",
      "Epoch [3/10] Batch [328/469] Loss D: -0.33549758791923523, loss G: -0.27625253796577454\n",
      "Epoch [3/10] Batch [329/469] Loss D: -0.2980915307998657, loss G: -0.201681986451149\n",
      "Epoch [3/10] Batch [330/469] Loss D: -0.31293362379074097, loss G: -0.250116229057312\n",
      "Epoch [3/10] Batch [331/469] Loss D: -0.3744692802429199, loss G: -0.41187000274658203\n",
      "Epoch [3/10] Batch [332/469] Loss D: -0.3069438934326172, loss G: -0.12674102187156677\n",
      "Epoch [3/10] Batch [333/469] Loss D: -0.2762377858161926, loss G: -0.26058387756347656\n",
      "Epoch [3/10] Batch [334/469] Loss D: -0.34382250905036926, loss G: -0.2916070222854614\n",
      "Epoch [3/10] Batch [335/469] Loss D: -0.3811110258102417, loss G: -0.19915255904197693\n",
      "Epoch [3/10] Batch [336/469] Loss D: -0.2957984209060669, loss G: -0.34803226590156555\n",
      "Epoch [3/10] Batch [337/469] Loss D: -0.3129950165748596, loss G: -0.3263990581035614\n",
      "Epoch [3/10] Batch [338/469] Loss D: -0.28641778230667114, loss G: -0.1988704949617386\n",
      "Epoch [3/10] Batch [339/469] Loss D: -0.32133182883262634, loss G: -0.39365440607070923\n",
      "Epoch [3/10] Batch [340/469] Loss D: -0.3290596902370453, loss G: -0.18281246721744537\n",
      "Epoch [3/10] Batch [341/469] Loss D: -0.3129119575023651, loss G: -0.2021738588809967\n",
      "Epoch [3/10] Batch [342/469] Loss D: -0.3780541718006134, loss G: -0.45113852620124817\n",
      "Epoch [3/10] Batch [343/469] Loss D: -0.2589230537414551, loss G: -0.2654741406440735\n",
      "Epoch [3/10] Batch [344/469] Loss D: -0.3533710837364197, loss G: -0.27443644404411316\n",
      "Epoch [3/10] Batch [345/469] Loss D: -0.291887491941452, loss G: -0.37009885907173157\n",
      "Epoch [3/10] Batch [346/469] Loss D: -0.3987365663051605, loss G: -0.1804397702217102\n",
      "Epoch [3/10] Batch [347/469] Loss D: -0.3880687355995178, loss G: -0.2884281873703003\n",
      "Epoch [3/10] Batch [348/469] Loss D: -0.36106738448143005, loss G: -0.20369747281074524\n",
      "Epoch [3/10] Batch [349/469] Loss D: -0.34713685512542725, loss G: -0.36982083320617676\n",
      "Epoch [3/10] Batch [350/469] Loss D: -0.2937600016593933, loss G: -0.3107534348964691\n",
      "Epoch [3/10] Batch [351/469] Loss D: -0.33303844928741455, loss G: -0.14243978261947632\n",
      "Epoch [3/10] Batch [352/469] Loss D: -0.31184253096580505, loss G: -0.46570518612861633\n",
      "Epoch [3/10] Batch [353/469] Loss D: -0.21176844835281372, loss G: -0.33199113607406616\n",
      "Epoch [3/10] Batch [354/469] Loss D: -0.21966925263404846, loss G: -0.32883965969085693\n",
      "Epoch [3/10] Batch [355/469] Loss D: -0.31913626194000244, loss G: -0.21990586817264557\n",
      "Epoch [3/10] Batch [356/469] Loss D: -0.27328479290008545, loss G: -0.2896728217601776\n",
      "Epoch [3/10] Batch [357/469] Loss D: -0.33846810460090637, loss G: -0.18813271820545197\n",
      "Epoch [3/10] Batch [358/469] Loss D: -0.25844186544418335, loss G: -0.4065956473350525\n",
      "Epoch [3/10] Batch [359/469] Loss D: -0.3276204764842987, loss G: -0.23340168595314026\n",
      "Epoch [3/10] Batch [360/469] Loss D: -0.36151835322380066, loss G: -0.21050027012825012\n",
      "Epoch [3/10] Batch [361/469] Loss D: -0.4408596158027649, loss G: -0.26966041326522827\n",
      "Epoch [3/10] Batch [362/469] Loss D: -0.38653767108917236, loss G: -0.21184778213500977\n",
      "Epoch [3/10] Batch [363/469] Loss D: -0.3347267806529999, loss G: -0.31277015805244446\n",
      "Epoch [3/10] Batch [364/469] Loss D: -0.3494306206703186, loss G: -0.3138594627380371\n",
      "Epoch [3/10] Batch [365/469] Loss D: -0.3257352113723755, loss G: -0.23089122772216797\n",
      "Epoch [3/10] Batch [366/469] Loss D: -0.27281850576400757, loss G: -0.2540047764778137\n",
      "Epoch [3/10] Batch [367/469] Loss D: -0.34605473279953003, loss G: -0.2755579352378845\n",
      "Epoch [3/10] Batch [368/469] Loss D: -0.33688920736312866, loss G: -0.3461909294128418\n",
      "Epoch [3/10] Batch [369/469] Loss D: -0.3425365686416626, loss G: -0.15482619404792786\n",
      "Epoch [3/10] Batch [370/469] Loss D: -0.3651040196418762, loss G: -0.29427123069763184\n",
      "Epoch [3/10] Batch [371/469] Loss D: -0.4251295328140259, loss G: -0.2753449082374573\n",
      "Epoch [3/10] Batch [372/469] Loss D: -0.41169190406799316, loss G: -0.18235929310321808\n",
      "Epoch [3/10] Batch [373/469] Loss D: -0.3262176215648651, loss G: -0.31488412618637085\n",
      "Epoch [3/10] Batch [374/469] Loss D: -0.4118090271949768, loss G: -0.22871777415275574\n",
      "Epoch [3/10] Batch [375/469] Loss D: -0.3208461403846741, loss G: -0.25876331329345703\n",
      "Epoch [3/10] Batch [376/469] Loss D: -0.3177047371864319, loss G: -0.2897324562072754\n",
      "Epoch [3/10] Batch [377/469] Loss D: -0.4001814126968384, loss G: -0.29201361536979675\n",
      "Epoch [3/10] Batch [378/469] Loss D: -0.26419469714164734, loss G: -0.28588998317718506\n",
      "Epoch [3/10] Batch [379/469] Loss D: -0.29453372955322266, loss G: -0.32653823494911194\n",
      "Epoch [3/10] Batch [380/469] Loss D: -0.42241230607032776, loss G: -0.1739482581615448\n",
      "Epoch [3/10] Batch [381/469] Loss D: -0.34453967213630676, loss G: -0.21112939715385437\n",
      "Epoch [3/10] Batch [382/469] Loss D: -0.31109949946403503, loss G: -0.3868030905723572\n",
      "Epoch [3/10] Batch [383/469] Loss D: -0.395510196685791, loss G: -0.10003732144832611\n",
      "Epoch [3/10] Batch [384/469] Loss D: -0.3397585153579712, loss G: -0.3027037978172302\n",
      "Epoch [3/10] Batch [385/469] Loss D: -0.33371812105178833, loss G: -0.3227507472038269\n",
      "Epoch [3/10] Batch [386/469] Loss D: -0.3040243983268738, loss G: -0.1768050193786621\n",
      "Epoch [3/10] Batch [387/469] Loss D: -0.24820134043693542, loss G: -0.30850598216056824\n",
      "Epoch [3/10] Batch [388/469] Loss D: -0.31566768884658813, loss G: -0.3484346270561218\n",
      "Epoch [3/10] Batch [389/469] Loss D: -0.3872230052947998, loss G: -0.14464515447616577\n",
      "Epoch [3/10] Batch [390/469] Loss D: -0.289471298456192, loss G: -0.2790703773498535\n",
      "Epoch [3/10] Batch [391/469] Loss D: -0.28378742933273315, loss G: -0.3304399847984314\n",
      "Epoch [3/10] Batch [392/469] Loss D: -0.3150831460952759, loss G: -0.2659284472465515\n",
      "Epoch [3/10] Batch [393/469] Loss D: -0.2805268168449402, loss G: -0.3010759651660919\n",
      "Epoch [3/10] Batch [394/469] Loss D: -0.3389597237110138, loss G: -0.23927225172519684\n",
      "Epoch [3/10] Batch [395/469] Loss D: -0.40087124705314636, loss G: -0.1822744756937027\n",
      "Epoch [3/10] Batch [396/469] Loss D: -0.46290767192840576, loss G: -0.2542356550693512\n",
      "Epoch [3/10] Batch [397/469] Loss D: -0.3728500306606293, loss G: -0.19532093405723572\n",
      "Epoch [3/10] Batch [398/469] Loss D: -0.40081438422203064, loss G: -0.3799792528152466\n",
      "Epoch [3/10] Batch [399/469] Loss D: -0.3731279969215393, loss G: -0.10919252783060074\n",
      "Epoch [3/10] Batch [400/469] Loss D: -0.32374081015586853, loss G: -0.29801011085510254\n",
      "Epoch [3/10] Batch [401/469] Loss D: -0.3465575873851776, loss G: -0.30728858709335327\n",
      "Epoch [3/10] Batch [402/469] Loss D: -0.4010583758354187, loss G: -0.18904206156730652\n",
      "Epoch [3/10] Batch [403/469] Loss D: -0.33245402574539185, loss G: -0.3116215169429779\n",
      "Epoch [3/10] Batch [404/469] Loss D: -0.31717824935913086, loss G: -0.2533189654350281\n",
      "Epoch [3/10] Batch [405/469] Loss D: -0.28652238845825195, loss G: -0.24688288569450378\n",
      "Epoch [3/10] Batch [406/469] Loss D: -0.21039152145385742, loss G: -0.1650582253932953\n",
      "Epoch [3/10] Batch [407/469] Loss D: -0.2737705409526825, loss G: -0.43291175365448\n",
      "Epoch [3/10] Batch [408/469] Loss D: -0.38634902238845825, loss G: -0.1602245569229126\n",
      "Epoch [3/10] Batch [409/469] Loss D: -0.433108389377594, loss G: -0.16256433725357056\n",
      "Epoch [3/10] Batch [410/469] Loss D: -0.39933741092681885, loss G: -0.3042503893375397\n",
      "Epoch [3/10] Batch [411/469] Loss D: -0.3366308808326721, loss G: -0.2099638134241104\n",
      "Epoch [3/10] Batch [412/469] Loss D: -0.31100282073020935, loss G: -0.2969765365123749\n",
      "Epoch [3/10] Batch [413/469] Loss D: -0.3188084065914154, loss G: -0.2941272258758545\n",
      "Epoch [3/10] Batch [414/469] Loss D: -0.26352164149284363, loss G: -0.16049599647521973\n",
      "Epoch [3/10] Batch [415/469] Loss D: -0.2777416706085205, loss G: -0.38124772906303406\n",
      "Epoch [3/10] Batch [416/469] Loss D: -0.33063650131225586, loss G: -0.32365256547927856\n",
      "Epoch [3/10] Batch [417/469] Loss D: -0.2897219657897949, loss G: -0.19483454525470734\n",
      "Epoch [3/10] Batch [418/469] Loss D: -0.27885493636131287, loss G: -0.2305009663105011\n",
      "Epoch [3/10] Batch [419/469] Loss D: -0.34685471653938293, loss G: -0.32085031270980835\n",
      "Epoch [3/10] Batch [420/469] Loss D: -0.34702879190444946, loss G: -0.11934545636177063\n",
      "Epoch [3/10] Batch [421/469] Loss D: -0.3250143527984619, loss G: -0.3087596297264099\n",
      "Epoch [3/10] Batch [422/469] Loss D: -0.32725316286087036, loss G: -0.39939385652542114\n",
      "Epoch [3/10] Batch [423/469] Loss D: -0.282637357711792, loss G: -0.14684641361236572\n",
      "Epoch [3/10] Batch [424/469] Loss D: -0.3535151481628418, loss G: -0.221164733171463\n",
      "Epoch [3/10] Batch [425/469] Loss D: -0.3141019642353058, loss G: -0.30114033818244934\n",
      "Epoch [3/10] Batch [426/469] Loss D: -0.3545268774032593, loss G: -0.28672757744789124\n",
      "Epoch [3/10] Batch [427/469] Loss D: -0.2795386016368866, loss G: -0.27085673809051514\n",
      "Epoch [3/10] Batch [428/469] Loss D: -0.33178994059562683, loss G: -0.3118149936199188\n",
      "Epoch [3/10] Batch [429/469] Loss D: -0.4058402180671692, loss G: -0.2314322590827942\n",
      "Epoch [3/10] Batch [430/469] Loss D: -0.3267451226711273, loss G: -0.3560543656349182\n",
      "Epoch [3/10] Batch [431/469] Loss D: -0.3309563398361206, loss G: -0.146630197763443\n",
      "Epoch [3/10] Batch [432/469] Loss D: -0.28532904386520386, loss G: -0.31708475947380066\n",
      "Epoch [3/10] Batch [433/469] Loss D: -0.374938428401947, loss G: -0.16651323437690735\n",
      "Epoch [3/10] Batch [434/469] Loss D: -0.32983964681625366, loss G: -0.3769608736038208\n",
      "Epoch [3/10] Batch [435/469] Loss D: -0.32480186223983765, loss G: -0.21151500940322876\n",
      "Epoch [3/10] Batch [436/469] Loss D: -0.27998578548431396, loss G: -0.3912883400917053\n",
      "Epoch [3/10] Batch [437/469] Loss D: -0.3833067715167999, loss G: -0.16883818805217743\n",
      "Epoch [3/10] Batch [438/469] Loss D: -0.4422241151332855, loss G: -0.3050178289413452\n",
      "Epoch [3/10] Batch [439/469] Loss D: -0.39109355211257935, loss G: -0.09920214116573334\n",
      "Epoch [3/10] Batch [440/469] Loss D: -0.37361425161361694, loss G: -0.3126419484615326\n",
      "Epoch [3/10] Batch [441/469] Loss D: -0.41273143887519836, loss G: -0.17646916210651398\n",
      "Epoch [3/10] Batch [442/469] Loss D: -0.41329947113990784, loss G: -0.20559126138687134\n",
      "Epoch [3/10] Batch [443/469] Loss D: -0.394700288772583, loss G: -0.3090393543243408\n",
      "Epoch [3/10] Batch [444/469] Loss D: -0.3406793475151062, loss G: -0.11702588200569153\n",
      "Epoch [3/10] Batch [445/469] Loss D: -0.3113968074321747, loss G: -0.2633519470691681\n",
      "Epoch [3/10] Batch [446/469] Loss D: -0.3617391586303711, loss G: -0.3079763650894165\n",
      "Epoch [3/10] Batch [447/469] Loss D: -0.3132582902908325, loss G: -0.23835524916648865\n",
      "Epoch [3/10] Batch [448/469] Loss D: -0.37033557891845703, loss G: -0.21570858359336853\n",
      "Epoch [3/10] Batch [449/469] Loss D: -0.4125310182571411, loss G: -0.19090288877487183\n",
      "Epoch [3/10] Batch [450/469] Loss D: -0.4325631856918335, loss G: -0.3670162558555603\n",
      "Epoch [3/10] Batch [451/469] Loss D: -0.38776278495788574, loss G: -0.08487018942832947\n",
      "Epoch [3/10] Batch [452/469] Loss D: -0.37918782234191895, loss G: -0.43941470980644226\n",
      "Epoch [3/10] Batch [453/469] Loss D: -0.3446556329727173, loss G: -0.19065719842910767\n",
      "Epoch [3/10] Batch [454/469] Loss D: -0.39909711480140686, loss G: -0.19756722450256348\n",
      "Epoch [3/10] Batch [455/469] Loss D: -0.41677141189575195, loss G: -0.4343288242816925\n",
      "Epoch [3/10] Batch [456/469] Loss D: -0.29446107149124146, loss G: -0.13160346448421478\n",
      "Epoch [3/10] Batch [457/469] Loss D: -0.3004576563835144, loss G: -0.30477309226989746\n",
      "Epoch [3/10] Batch [458/469] Loss D: -0.32964852452278137, loss G: -0.28146886825561523\n",
      "Epoch [3/10] Batch [459/469] Loss D: -0.3863166570663452, loss G: -0.15845519304275513\n",
      "Epoch [3/10] Batch [460/469] Loss D: -0.31833118200302124, loss G: -0.3147108554840088\n",
      "Epoch [3/10] Batch [461/469] Loss D: -0.38176000118255615, loss G: -0.2338055968284607\n",
      "Epoch [3/10] Batch [462/469] Loss D: -0.3833940923213959, loss G: -0.12925726175308228\n",
      "Epoch [3/10] Batch [463/469] Loss D: -0.3211667537689209, loss G: -0.41008108854293823\n",
      "Epoch [3/10] Batch [464/469] Loss D: -0.3935315012931824, loss G: -0.14325493574142456\n",
      "Epoch [3/10] Batch [465/469] Loss D: -0.35592126846313477, loss G: -0.3359537720680237\n",
      "Epoch [3/10] Batch [466/469] Loss D: -0.37820136547088623, loss G: -0.2073337733745575\n",
      "Epoch [3/10] Batch [467/469] Loss D: -0.4911261796951294, loss G: -0.11847537755966187\n",
      "Epoch [3/10] Batch [468/469] Loss D: -0.3843602240085602, loss G: -0.4007797837257385\n",
      "Epoch [3/10] Batch [469/469] Loss D: -0.334961473941803, loss G: -0.20439569652080536\n",
      "Epoch [4/10] Batch [1/469] Loss D: -0.39841917157173157, loss G: -0.1548604816198349\n",
      "Epoch [4/10] Batch [2/469] Loss D: -0.3707209527492523, loss G: -0.3152087330818176\n",
      "Epoch [4/10] Batch [3/469] Loss D: -0.314028799533844, loss G: -0.24721433222293854\n",
      "Epoch [4/10] Batch [4/469] Loss D: -0.3347054123878479, loss G: -0.17270877957344055\n",
      "Epoch [4/10] Batch [5/469] Loss D: -0.27412933111190796, loss G: -0.39476919174194336\n",
      "Epoch [4/10] Batch [6/469] Loss D: -0.3287857174873352, loss G: -0.25665372610092163\n",
      "Epoch [4/10] Batch [7/469] Loss D: -0.3428855538368225, loss G: -0.14812937378883362\n",
      "Epoch [4/10] Batch [8/469] Loss D: -0.2726823091506958, loss G: -0.32561880350112915\n",
      "Epoch [4/10] Batch [9/469] Loss D: -0.354259192943573, loss G: -0.25259172916412354\n",
      "Epoch [4/10] Batch [10/469] Loss D: -0.42890360951423645, loss G: -0.17564794421195984\n",
      "Epoch [4/10] Batch [11/469] Loss D: -0.37097418308258057, loss G: -0.29572898149490356\n",
      "Epoch [4/10] Batch [12/469] Loss D: -0.4236143231391907, loss G: -0.18226996064186096\n",
      "Epoch [4/10] Batch [13/469] Loss D: -0.4029972553253174, loss G: -0.23872439563274384\n",
      "Epoch [4/10] Batch [14/469] Loss D: -0.40744590759277344, loss G: -0.21468237042427063\n",
      "Epoch [4/10] Batch [15/469] Loss D: -0.4059911072254181, loss G: -0.3050065338611603\n",
      "Epoch [4/10] Batch [16/469] Loss D: -0.4263754189014435, loss G: -0.11258254945278168\n",
      "Epoch [4/10] Batch [17/469] Loss D: -0.40389448404312134, loss G: -0.4541623592376709\n",
      "Epoch [4/10] Batch [18/469] Loss D: -0.33647608757019043, loss G: -0.1376616507768631\n",
      "Epoch [4/10] Batch [19/469] Loss D: -0.4346763491630554, loss G: -0.2802572250366211\n",
      "Epoch [4/10] Batch [20/469] Loss D: -0.3718365728855133, loss G: -0.23694458603858948\n",
      "Epoch [4/10] Batch [21/469] Loss D: -0.37659940123558044, loss G: -0.16783878207206726\n",
      "Epoch [4/10] Batch [22/469] Loss D: -0.3417845666408539, loss G: -0.3663042187690735\n",
      "Epoch [4/10] Batch [23/469] Loss D: -0.3128175139427185, loss G: -0.1327410489320755\n",
      "Epoch [4/10] Batch [24/469] Loss D: -0.3309278190135956, loss G: -0.34929734468460083\n",
      "Epoch [4/10] Batch [25/469] Loss D: -0.45517677068710327, loss G: -0.16759945452213287\n",
      "Epoch [4/10] Batch [26/469] Loss D: -0.44721516966819763, loss G: -0.19304385781288147\n",
      "Epoch [4/10] Batch [27/469] Loss D: -0.4220694899559021, loss G: -0.26991018652915955\n",
      "Epoch [4/10] Batch [28/469] Loss D: -0.36418479681015015, loss G: -0.15760362148284912\n",
      "Epoch [4/10] Batch [29/469] Loss D: -0.4206465482711792, loss G: -0.32362866401672363\n",
      "Epoch [4/10] Batch [30/469] Loss D: -0.3424932062625885, loss G: -0.20404665172100067\n",
      "Epoch [4/10] Batch [31/469] Loss D: -0.3520655632019043, loss G: -0.2705395221710205\n",
      "Epoch [4/10] Batch [32/469] Loss D: -0.4202346205711365, loss G: -0.13083893060684204\n",
      "Epoch [4/10] Batch [33/469] Loss D: -0.5253217220306396, loss G: -0.261821985244751\n",
      "Epoch [4/10] Batch [34/469] Loss D: -0.39417436718940735, loss G: -0.22604644298553467\n",
      "Epoch [4/10] Batch [35/469] Loss D: -0.43486273288726807, loss G: -0.2269369661808014\n",
      "Epoch [4/10] Batch [36/469] Loss D: -0.47288423776626587, loss G: -0.1491924375295639\n",
      "Epoch [4/10] Batch [37/469] Loss D: -0.4377654194831848, loss G: -0.33249419927597046\n",
      "Epoch [4/10] Batch [38/469] Loss D: -0.368104487657547, loss G: -0.1595539152622223\n",
      "Epoch [4/10] Batch [39/469] Loss D: -0.28147727251052856, loss G: -0.28772348165512085\n",
      "Epoch [4/10] Batch [40/469] Loss D: -0.3845697045326233, loss G: -0.25680989027023315\n",
      "Epoch [4/10] Batch [41/469] Loss D: -0.3765292763710022, loss G: -0.16584932804107666\n",
      "Epoch [4/10] Batch [42/469] Loss D: -0.4084234833717346, loss G: -0.34951847791671753\n",
      "Epoch [4/10] Batch [43/469] Loss D: -0.37734490633010864, loss G: -0.20536470413208008\n",
      "Epoch [4/10] Batch [44/469] Loss D: -0.4250202775001526, loss G: -0.1785828173160553\n",
      "Epoch [4/10] Batch [45/469] Loss D: -0.38098645210266113, loss G: -0.2921183109283447\n",
      "Epoch [4/10] Batch [46/469] Loss D: -0.3740183711051941, loss G: -0.1966254860162735\n",
      "Epoch [4/10] Batch [47/469] Loss D: -0.3715103566646576, loss G: -0.2507287263870239\n",
      "Epoch [4/10] Batch [48/469] Loss D: -0.43950238823890686, loss G: -0.1576797515153885\n",
      "Epoch [4/10] Batch [49/469] Loss D: -0.39212173223495483, loss G: -0.2996448278427124\n",
      "Epoch [4/10] Batch [50/469] Loss D: -0.4045949876308441, loss G: -0.2525036931037903\n",
      "Epoch [4/10] Batch [51/469] Loss D: -0.38915663957595825, loss G: -0.08973349630832672\n",
      "Epoch [4/10] Batch [52/469] Loss D: -0.3475029468536377, loss G: -0.36412981152534485\n",
      "Epoch [4/10] Batch [53/469] Loss D: -0.3464662432670593, loss G: -0.23196625709533691\n",
      "Epoch [4/10] Batch [54/469] Loss D: -0.40101712942123413, loss G: -0.15005293488502502\n",
      "Epoch [4/10] Batch [55/469] Loss D: -0.31215035915374756, loss G: -0.40175241231918335\n",
      "Epoch [4/10] Batch [56/469] Loss D: -0.3618318736553192, loss G: -0.2573328912258148\n",
      "Epoch [4/10] Batch [57/469] Loss D: -0.4632284939289093, loss G: -0.08000841736793518\n",
      "Epoch [4/10] Batch [58/469] Loss D: -0.40491411089897156, loss G: -0.42835262417793274\n",
      "Epoch [4/10] Batch [59/469] Loss D: -0.35856425762176514, loss G: -0.11466799676418304\n",
      "Epoch [4/10] Batch [60/469] Loss D: -0.4200359582901001, loss G: -0.3203248977661133\n",
      "Epoch [4/10] Batch [61/469] Loss D: -0.3875628709793091, loss G: -0.11668675392866135\n",
      "Epoch [4/10] Batch [62/469] Loss D: -0.3295530080795288, loss G: -0.1949060559272766\n",
      "Epoch [4/10] Batch [63/469] Loss D: -0.34758543968200684, loss G: -0.40869078040122986\n",
      "Epoch [4/10] Batch [64/469] Loss D: -0.4165499210357666, loss G: -0.12443685531616211\n",
      "Epoch [4/10] Batch [65/469] Loss D: -0.3323403000831604, loss G: -0.3649624288082123\n",
      "Epoch [4/10] Batch [66/469] Loss D: -0.40381038188934326, loss G: -0.11572575569152832\n",
      "Epoch [4/10] Batch [67/469] Loss D: -0.418176531791687, loss G: -0.39402222633361816\n",
      "Epoch [4/10] Batch [68/469] Loss D: -0.3958587646484375, loss G: -0.06143342703580856\n",
      "Epoch [4/10] Batch [69/469] Loss D: -0.36032354831695557, loss G: -0.36347144842147827\n",
      "Epoch [4/10] Batch [70/469] Loss D: -0.3440829813480377, loss G: -0.2443716824054718\n",
      "Epoch [4/10] Batch [71/469] Loss D: -0.41550499200820923, loss G: -0.18619152903556824\n",
      "Epoch [4/10] Batch [72/469] Loss D: -0.37580370903015137, loss G: -0.24654585123062134\n",
      "Epoch [4/10] Batch [73/469] Loss D: -0.41413554549217224, loss G: -0.2196020632982254\n",
      "Epoch [4/10] Batch [74/469] Loss D: -0.43974724411964417, loss G: -0.19485580921173096\n",
      "Epoch [4/10] Batch [75/469] Loss D: -0.3865524232387543, loss G: -0.2845960259437561\n",
      "Epoch [4/10] Batch [76/469] Loss D: -0.4988829791545868, loss G: -0.14677150547504425\n",
      "Epoch [4/10] Batch [77/469] Loss D: -0.41315239667892456, loss G: -0.23636546730995178\n",
      "Epoch [4/10] Batch [78/469] Loss D: -0.4483630061149597, loss G: -0.208357572555542\n",
      "Epoch [4/10] Batch [79/469] Loss D: -0.4482819437980652, loss G: -0.38593789935112\n",
      "Epoch [4/10] Batch [80/469] Loss D: -0.3891025185585022, loss G: -0.09776557236909866\n",
      "Epoch [4/10] Batch [81/469] Loss D: -0.34517890214920044, loss G: -0.2701053023338318\n",
      "Epoch [4/10] Batch [82/469] Loss D: -0.3413403034210205, loss G: -0.4090680480003357\n",
      "Epoch [4/10] Batch [83/469] Loss D: -0.33826395869255066, loss G: -0.16602858901023865\n",
      "Epoch [4/10] Batch [84/469] Loss D: -0.35682666301727295, loss G: -0.28075429797172546\n",
      "Epoch [4/10] Batch [85/469] Loss D: -0.39733701944351196, loss G: -0.2667396068572998\n",
      "Epoch [4/10] Batch [86/469] Loss D: -0.3764628469944, loss G: -0.19561348855495453\n",
      "Epoch [4/10] Batch [87/469] Loss D: -0.3965660631656647, loss G: -0.4024340510368347\n",
      "Epoch [4/10] Batch [88/469] Loss D: -0.28349220752716064, loss G: -0.24866974353790283\n",
      "Epoch [4/10] Batch [89/469] Loss D: -0.3129540681838989, loss G: -0.23174403607845306\n",
      "Epoch [4/10] Batch [90/469] Loss D: -0.35654544830322266, loss G: -0.22188948094844818\n",
      "Epoch [4/10] Batch [91/469] Loss D: -0.34417080879211426, loss G: -0.3206790089607239\n",
      "Epoch [4/10] Batch [92/469] Loss D: -0.33850836753845215, loss G: -0.2434486448764801\n",
      "Epoch [4/10] Batch [93/469] Loss D: -0.4613490402698517, loss G: -0.11893109232187271\n",
      "Epoch [4/10] Batch [94/469] Loss D: -0.3553026020526886, loss G: -0.44316720962524414\n",
      "Epoch [4/10] Batch [95/469] Loss D: -0.3504558801651001, loss G: -0.17868179082870483\n",
      "Epoch [4/10] Batch [96/469] Loss D: -0.4674385190010071, loss G: -0.21924306452274323\n",
      "Epoch [4/10] Batch [97/469] Loss D: -0.4576365053653717, loss G: -0.2038435935974121\n",
      "Epoch [4/10] Batch [98/469] Loss D: -0.4404834508895874, loss G: -0.33351606130599976\n",
      "Epoch [4/10] Batch [99/469] Loss D: -0.4137572646141052, loss G: -0.11576290428638458\n",
      "Epoch [4/10] Batch [100/469] Loss D: -0.3690515160560608, loss G: -0.36012476682662964\n",
      "Epoch [4/10] Batch [101/469] Loss D: -0.4002527892589569, loss G: -0.13170598447322845\n",
      "Epoch [4/10] Batch [102/469] Loss D: -0.43539950251579285, loss G: -0.26041874289512634\n",
      "Epoch [4/10] Batch [103/469] Loss D: -0.45630237460136414, loss G: -0.20244291424751282\n",
      "Epoch [4/10] Batch [104/469] Loss D: -0.47623562812805176, loss G: -0.15509885549545288\n",
      "Epoch [4/10] Batch [105/469] Loss D: -0.3425136208534241, loss G: -0.4127408266067505\n",
      "Epoch [4/10] Batch [106/469] Loss D: -0.4042415916919708, loss G: -0.09034345299005508\n",
      "Epoch [4/10] Batch [107/469] Loss D: -0.35953065752983093, loss G: -0.4377533197402954\n",
      "Epoch [4/10] Batch [108/469] Loss D: -0.4128352999687195, loss G: -0.2241819202899933\n",
      "Epoch [4/10] Batch [109/469] Loss D: -0.3764387369155884, loss G: -0.13260780274868011\n",
      "Epoch [4/10] Batch [110/469] Loss D: -0.3800019323825836, loss G: -0.38559627532958984\n",
      "Epoch [4/10] Batch [111/469] Loss D: -0.33314281702041626, loss G: -0.2056005895137787\n",
      "Epoch [4/10] Batch [112/469] Loss D: -0.3931159973144531, loss G: -0.18032291531562805\n",
      "Epoch [4/10] Batch [113/469] Loss D: -0.440216600894928, loss G: -0.29811373353004456\n",
      "Epoch [4/10] Batch [114/469] Loss D: -0.4498431086540222, loss G: -0.14477133750915527\n",
      "Epoch [4/10] Batch [115/469] Loss D: -0.492360919713974, loss G: -0.3738258481025696\n",
      "Epoch [4/10] Batch [116/469] Loss D: -0.40442711114883423, loss G: -0.12621769309043884\n",
      "Epoch [4/10] Batch [117/469] Loss D: -0.47508126497268677, loss G: -0.16585537791252136\n",
      "Epoch [4/10] Batch [118/469] Loss D: -0.48271644115448, loss G: -0.35477378964424133\n",
      "Epoch [4/10] Batch [119/469] Loss D: -0.4349106252193451, loss G: -0.1099884957075119\n",
      "Epoch [4/10] Batch [120/469] Loss D: -0.46744540333747864, loss G: -0.30723947286605835\n",
      "Epoch [4/10] Batch [121/469] Loss D: -0.3550252914428711, loss G: -0.14378780126571655\n",
      "Epoch [4/10] Batch [122/469] Loss D: -0.25380340218544006, loss G: -0.2415061891078949\n",
      "Epoch [4/10] Batch [123/469] Loss D: -0.4111466407775879, loss G: -0.3056713938713074\n",
      "Epoch [4/10] Batch [124/469] Loss D: -0.3522515892982483, loss G: -0.16951686143875122\n",
      "Epoch [4/10] Batch [125/469] Loss D: -0.3423925042152405, loss G: -0.3671324551105499\n",
      "Epoch [4/10] Batch [126/469] Loss D: -0.4411054849624634, loss G: -0.14400728046894073\n",
      "Epoch [4/10] Batch [127/469] Loss D: -0.45365914702415466, loss G: -0.2711431384086609\n",
      "Epoch [4/10] Batch [128/469] Loss D: -0.4354719817638397, loss G: -0.13171029090881348\n",
      "Epoch [4/10] Batch [129/469] Loss D: -0.37269115447998047, loss G: -0.30561357736587524\n",
      "Epoch [4/10] Batch [130/469] Loss D: -0.4605817496776581, loss G: -0.10749933123588562\n",
      "Epoch [4/10] Batch [131/469] Loss D: -0.4021327495574951, loss G: -0.4508395791053772\n",
      "Epoch [4/10] Batch [132/469] Loss D: -0.3838144540786743, loss G: -0.1730480194091797\n",
      "Epoch [4/10] Batch [133/469] Loss D: -0.37543758749961853, loss G: -0.17827531695365906\n",
      "Epoch [4/10] Batch [134/469] Loss D: -0.4035521149635315, loss G: -0.30118340253829956\n",
      "Epoch [4/10] Batch [135/469] Loss D: -0.3697415590286255, loss G: -0.21803419291973114\n",
      "Epoch [4/10] Batch [136/469] Loss D: -0.4983048141002655, loss G: -0.09310594201087952\n",
      "Epoch [4/10] Batch [137/469] Loss D: -0.449361652135849, loss G: -0.49051591753959656\n",
      "Epoch [4/10] Batch [138/469] Loss D: -0.320667564868927, loss G: -0.1532140076160431\n",
      "Epoch [4/10] Batch [139/469] Loss D: -0.4017612636089325, loss G: -0.17402391135692596\n",
      "Epoch [4/10] Batch [140/469] Loss D: -0.5038324594497681, loss G: -0.21229633688926697\n",
      "Epoch [4/10] Batch [141/469] Loss D: -0.482769638299942, loss G: -0.21749347448349\n",
      "Epoch [4/10] Batch [142/469] Loss D: -0.46856194734573364, loss G: -0.17916923761367798\n",
      "Epoch [4/10] Batch [143/469] Loss D: -0.43597736954689026, loss G: -0.18773190677165985\n",
      "Epoch [4/10] Batch [144/469] Loss D: -0.3284913897514343, loss G: -0.2987585663795471\n",
      "Epoch [4/10] Batch [145/469] Loss D: -0.42736220359802246, loss G: -0.2218530923128128\n",
      "Epoch [4/10] Batch [146/469] Loss D: -0.34047001600265503, loss G: -0.20009933412075043\n",
      "Epoch [4/10] Batch [147/469] Loss D: -0.39140331745147705, loss G: -0.25297635793685913\n",
      "Epoch [4/10] Batch [148/469] Loss D: -0.4618561267852783, loss G: -0.08726425468921661\n",
      "Epoch [4/10] Batch [149/469] Loss D: -0.4471333622932434, loss G: -0.44167381525039673\n",
      "Epoch [4/10] Batch [150/469] Loss D: -0.3498515486717224, loss G: -0.13316485285758972\n",
      "Epoch [4/10] Batch [151/469] Loss D: -0.5345814228057861, loss G: -0.22613470256328583\n",
      "Epoch [4/10] Batch [152/469] Loss D: -0.44470030069351196, loss G: -0.26167982816696167\n",
      "Epoch [4/10] Batch [153/469] Loss D: -0.5021864771842957, loss G: -0.2181566208600998\n",
      "Epoch [4/10] Batch [154/469] Loss D: -0.42116686701774597, loss G: -0.138914555311203\n",
      "Epoch [4/10] Batch [155/469] Loss D: -0.42962175607681274, loss G: -0.3972747325897217\n",
      "Epoch [4/10] Batch [156/469] Loss D: -0.34894073009490967, loss G: -0.14371894299983978\n",
      "Epoch [4/10] Batch [157/469] Loss D: -0.39050525426864624, loss G: -0.23867636919021606\n",
      "Epoch [4/10] Batch [158/469] Loss D: -0.4413639307022095, loss G: -0.24337220191955566\n",
      "Epoch [4/10] Batch [159/469] Loss D: -0.4427078068256378, loss G: -0.14220570027828217\n",
      "Epoch [4/10] Batch [160/469] Loss D: -0.46251001954078674, loss G: -0.44566789269447327\n",
      "Epoch [4/10] Batch [161/469] Loss D: -0.2949798107147217, loss G: -0.24359463155269623\n",
      "Epoch [4/10] Batch [162/469] Loss D: -0.2971514165401459, loss G: -0.1810806393623352\n",
      "Epoch [4/10] Batch [163/469] Loss D: -0.4697439968585968, loss G: -0.1935817152261734\n",
      "Epoch [4/10] Batch [164/469] Loss D: -0.4340212643146515, loss G: -0.2553989887237549\n",
      "Epoch [4/10] Batch [165/469] Loss D: -0.43315061926841736, loss G: -0.12654730677604675\n",
      "Epoch [4/10] Batch [166/469] Loss D: -0.4586290121078491, loss G: -0.3229988217353821\n",
      "Epoch [4/10] Batch [167/469] Loss D: -0.45736950635910034, loss G: -0.11899625509977341\n",
      "Epoch [4/10] Batch [168/469] Loss D: -0.4146145284175873, loss G: -0.2545734941959381\n",
      "Epoch [4/10] Batch [169/469] Loss D: -0.44748032093048096, loss G: -0.21132832765579224\n",
      "Epoch [4/10] Batch [170/469] Loss D: -0.35332390666007996, loss G: -0.27110910415649414\n",
      "Epoch [4/10] Batch [171/469] Loss D: -0.3778764307498932, loss G: -0.23815417289733887\n",
      "Epoch [4/10] Batch [172/469] Loss D: -0.34734439849853516, loss G: -0.20421604812145233\n",
      "Epoch [4/10] Batch [173/469] Loss D: -0.36106136441230774, loss G: -0.3536301255226135\n",
      "Epoch [4/10] Batch [174/469] Loss D: -0.3559526801109314, loss G: -0.17987951636314392\n",
      "Epoch [4/10] Batch [175/469] Loss D: -0.4455392062664032, loss G: -0.2408865988254547\n",
      "Epoch [4/10] Batch [176/469] Loss D: -0.4712204039096832, loss G: -0.060051411390304565\n",
      "Epoch [4/10] Batch [177/469] Loss D: -0.4050108790397644, loss G: -0.3924024999141693\n",
      "Epoch [4/10] Batch [178/469] Loss D: -0.39886537194252014, loss G: -0.14526808261871338\n",
      "Epoch [4/10] Batch [179/469] Loss D: -0.5202475786209106, loss G: -0.0579514354467392\n",
      "Epoch [4/10] Batch [180/469] Loss D: -0.25800013542175293, loss G: -0.3841942846775055\n",
      "Epoch [4/10] Batch [181/469] Loss D: -0.3512348234653473, loss G: -0.27912434935569763\n",
      "Epoch [4/10] Batch [182/469] Loss D: -0.385059654712677, loss G: -0.09946543723344803\n",
      "Epoch [4/10] Batch [183/469] Loss D: -0.3273426294326782, loss G: -0.33077162504196167\n",
      "Epoch [4/10] Batch [184/469] Loss D: -0.3274179697036743, loss G: -0.17291884124279022\n",
      "Epoch [4/10] Batch [185/469] Loss D: -0.34832680225372314, loss G: -0.3244055509567261\n",
      "Epoch [4/10] Batch [186/469] Loss D: -0.3097773790359497, loss G: -0.16816653311252594\n",
      "Epoch [4/10] Batch [187/469] Loss D: -0.4386124610900879, loss G: -0.24210338294506073\n",
      "Epoch [4/10] Batch [188/469] Loss D: -0.3926602602005005, loss G: -0.25485023856163025\n",
      "Epoch [4/10] Batch [189/469] Loss D: -0.46058130264282227, loss G: -0.1994069218635559\n",
      "Epoch [4/10] Batch [190/469] Loss D: -0.4023674726486206, loss G: -0.17530237138271332\n",
      "Epoch [4/10] Batch [191/469] Loss D: -0.4141779839992523, loss G: -0.1812901794910431\n",
      "Epoch [4/10] Batch [192/469] Loss D: -0.3928280472755432, loss G: -0.3798902630805969\n",
      "Epoch [4/10] Batch [193/469] Loss D: -0.4284147620201111, loss G: -0.1274758279323578\n",
      "Epoch [4/10] Batch [194/469] Loss D: -0.36628443002700806, loss G: -0.20664173364639282\n",
      "Epoch [4/10] Batch [195/469] Loss D: -0.42335009574890137, loss G: -0.3062095642089844\n",
      "Epoch [4/10] Batch [196/469] Loss D: -0.3075326085090637, loss G: -0.24701498448848724\n",
      "Epoch [4/10] Batch [197/469] Loss D: -0.3627593517303467, loss G: -0.12094514071941376\n",
      "Epoch [4/10] Batch [198/469] Loss D: -0.5082550644874573, loss G: -0.2498408854007721\n",
      "Epoch [4/10] Batch [199/469] Loss D: -0.3070257306098938, loss G: -0.36814016103744507\n",
      "Epoch [4/10] Batch [200/469] Loss D: -0.36657318472862244, loss G: -0.11207972466945648\n",
      "Epoch [4/10] Batch [201/469] Loss D: -0.4317454695701599, loss G: -0.321166455745697\n",
      "Epoch [4/10] Batch [202/469] Loss D: -0.3801078796386719, loss G: -0.16627228260040283\n",
      "Epoch [4/10] Batch [203/469] Loss D: -0.46461573243141174, loss G: -0.271983802318573\n",
      "Epoch [4/10] Batch [204/469] Loss D: -0.4424530565738678, loss G: -0.128353551030159\n",
      "Epoch [4/10] Batch [205/469] Loss D: -0.424913227558136, loss G: -0.341922789812088\n",
      "Epoch [4/10] Batch [206/469] Loss D: -0.3912625312805176, loss G: -0.15023308992385864\n",
      "Epoch [4/10] Batch [207/469] Loss D: -0.4196861982345581, loss G: -0.28789716958999634\n",
      "Epoch [4/10] Batch [208/469] Loss D: -0.48274827003479004, loss G: -0.11496245861053467\n",
      "Epoch [4/10] Batch [209/469] Loss D: -0.45883995294570923, loss G: -0.2185233235359192\n",
      "Epoch [4/10] Batch [210/469] Loss D: -0.42469513416290283, loss G: -0.2507326602935791\n",
      "Epoch [4/10] Batch [211/469] Loss D: -0.431632399559021, loss G: -0.15576955676078796\n",
      "Epoch [4/10] Batch [212/469] Loss D: -0.44318628311157227, loss G: -0.4009908139705658\n",
      "Epoch [4/10] Batch [213/469] Loss D: -0.3733745813369751, loss G: -0.09983333945274353\n",
      "Epoch [4/10] Batch [214/469] Loss D: -0.4814295172691345, loss G: -0.24504628777503967\n",
      "Epoch [4/10] Batch [215/469] Loss D: -0.4853331446647644, loss G: -0.14268669486045837\n",
      "Epoch [4/10] Batch [216/469] Loss D: -0.41168323159217834, loss G: -0.2976849675178528\n",
      "Epoch [4/10] Batch [217/469] Loss D: -0.3874000906944275, loss G: -0.2530558705329895\n",
      "Epoch [4/10] Batch [218/469] Loss D: -0.42914652824401855, loss G: -0.13172951340675354\n",
      "Epoch [4/10] Batch [219/469] Loss D: -0.41480255126953125, loss G: -0.39132604002952576\n",
      "Epoch [4/10] Batch [220/469] Loss D: -0.36669135093688965, loss G: -0.20189759135246277\n",
      "Epoch [4/10] Batch [221/469] Loss D: -0.49494659900665283, loss G: -0.15816164016723633\n",
      "Epoch [4/10] Batch [222/469] Loss D: -0.518982470035553, loss G: -0.18441423773765564\n",
      "Epoch [4/10] Batch [223/469] Loss D: -0.48009610176086426, loss G: -0.3129968047142029\n",
      "Epoch [4/10] Batch [224/469] Loss D: -0.4145445227622986, loss G: -0.11648496985435486\n",
      "Epoch [4/10] Batch [225/469] Loss D: -0.3994651138782501, loss G: -0.38810622692108154\n",
      "Epoch [4/10] Batch [226/469] Loss D: -0.4446437358856201, loss G: -0.07557213306427002\n",
      "Epoch [4/10] Batch [227/469] Loss D: -0.4259733557701111, loss G: -0.29741936922073364\n",
      "Epoch [4/10] Batch [228/469] Loss D: -0.44357770681381226, loss G: -0.2039707601070404\n",
      "Epoch [4/10] Batch [229/469] Loss D: -0.42965167760849, loss G: -0.2660670280456543\n",
      "Epoch [4/10] Batch [230/469] Loss D: -0.4829951226711273, loss G: -0.11385856568813324\n",
      "Epoch [4/10] Batch [231/469] Loss D: -0.4229970872402191, loss G: -0.28890693187713623\n",
      "Epoch [4/10] Batch [232/469] Loss D: -0.49495452642440796, loss G: -0.13065294921398163\n",
      "Epoch [4/10] Batch [233/469] Loss D: -0.4370768964290619, loss G: -0.23181989789009094\n",
      "Epoch [4/10] Batch [234/469] Loss D: -0.4434546232223511, loss G: -0.22828754782676697\n",
      "Epoch [4/10] Batch [235/469] Loss D: -0.4609820246696472, loss G: -0.10438130795955658\n",
      "Epoch [4/10] Batch [236/469] Loss D: -0.3910207152366638, loss G: -0.4640682339668274\n",
      "Epoch [4/10] Batch [237/469] Loss D: -0.40881800651550293, loss G: -0.09256240725517273\n",
      "Epoch [4/10] Batch [238/469] Loss D: -0.4374005198478699, loss G: -0.29290199279785156\n",
      "Epoch [4/10] Batch [239/469] Loss D: -0.4575667977333069, loss G: -0.1334962695837021\n",
      "Epoch [4/10] Batch [240/469] Loss D: -0.45370566844940186, loss G: -0.28725430369377136\n",
      "Epoch [4/10] Batch [241/469] Loss D: -0.5460472106933594, loss G: -0.10931997746229172\n",
      "Epoch [4/10] Batch [242/469] Loss D: -0.4539472162723541, loss G: -0.4192529320716858\n",
      "Epoch [4/10] Batch [243/469] Loss D: -0.33478087186813354, loss G: -0.09738065302371979\n",
      "Epoch [4/10] Batch [244/469] Loss D: -0.35193488001823425, loss G: -0.2467387318611145\n",
      "Epoch [4/10] Batch [245/469] Loss D: -0.4066060781478882, loss G: -0.4469206929206848\n",
      "Epoch [4/10] Batch [246/469] Loss D: -0.38072288036346436, loss G: -0.08077400177717209\n",
      "Epoch [4/10] Batch [247/469] Loss D: -0.35158663988113403, loss G: -0.2901771664619446\n",
      "Epoch [4/10] Batch [248/469] Loss D: -0.3755602240562439, loss G: -0.45624327659606934\n",
      "Epoch [4/10] Batch [249/469] Loss D: -0.2839736342430115, loss G: -0.2310430407524109\n",
      "Epoch [4/10] Batch [250/469] Loss D: -0.48934662342071533, loss G: -0.12886275351047516\n",
      "Epoch [4/10] Batch [251/469] Loss D: -0.4574536681175232, loss G: -0.45276376605033875\n",
      "Epoch [4/10] Batch [252/469] Loss D: -0.30162250995635986, loss G: -0.12258759140968323\n",
      "Epoch [4/10] Batch [253/469] Loss D: -0.4643501043319702, loss G: -0.1598806083202362\n",
      "Epoch [4/10] Batch [254/469] Loss D: -0.4113459587097168, loss G: -0.3510361909866333\n",
      "Epoch [4/10] Batch [255/469] Loss D: -0.413506418466568, loss G: -0.18481740355491638\n",
      "Epoch [4/10] Batch [256/469] Loss D: -0.43933266401290894, loss G: -0.19216108322143555\n",
      "Epoch [4/10] Batch [257/469] Loss D: -0.4677281677722931, loss G: -0.3372911810874939\n",
      "Epoch [4/10] Batch [258/469] Loss D: -0.40217339992523193, loss G: -0.13168635964393616\n",
      "Epoch [4/10] Batch [259/469] Loss D: -0.4301810562610626, loss G: -0.32214874029159546\n",
      "Epoch [4/10] Batch [260/469] Loss D: -0.4251282215118408, loss G: -0.16925148665905\n",
      "Epoch [4/10] Batch [261/469] Loss D: -0.5476089715957642, loss G: -0.24612492322921753\n",
      "Epoch [4/10] Batch [262/469] Loss D: -0.3894064128398895, loss G: -0.2075318694114685\n",
      "Epoch [4/10] Batch [263/469] Loss D: -0.5117319226264954, loss G: -0.23240193724632263\n",
      "Epoch [4/10] Batch [264/469] Loss D: -0.4125854969024658, loss G: -0.2309970110654831\n",
      "Epoch [4/10] Batch [265/469] Loss D: -0.3997557759284973, loss G: -0.15684130787849426\n",
      "Epoch [4/10] Batch [266/469] Loss D: -0.4545230567455292, loss G: -0.20382699370384216\n",
      "Epoch [4/10] Batch [267/469] Loss D: -0.4914724826812744, loss G: -0.2894125282764435\n",
      "Epoch [4/10] Batch [268/469] Loss D: -0.37207841873168945, loss G: -0.17988380789756775\n",
      "Epoch [4/10] Batch [269/469] Loss D: -0.437692254781723, loss G: -0.3780127167701721\n",
      "Epoch [4/10] Batch [270/469] Loss D: -0.2742006778717041, loss G: -0.2026701271533966\n",
      "Epoch [4/10] Batch [271/469] Loss D: -0.3786963224411011, loss G: -0.3233489692211151\n",
      "Epoch [4/10] Batch [272/469] Loss D: -0.4120030701160431, loss G: -0.12661036849021912\n",
      "Epoch [4/10] Batch [273/469] Loss D: -0.5236325860023499, loss G: -0.26332345604896545\n",
      "Epoch [4/10] Batch [274/469] Loss D: -0.46273961663246155, loss G: -0.05404580384492874\n",
      "Epoch [4/10] Batch [275/469] Loss D: -0.46307915449142456, loss G: -0.3401485085487366\n",
      "Epoch [4/10] Batch [276/469] Loss D: -0.3895943760871887, loss G: -0.11577451974153519\n",
      "Epoch [4/10] Batch [277/469] Loss D: -0.5398050546646118, loss G: -0.2645069360733032\n",
      "Epoch [4/10] Batch [278/469] Loss D: -0.41910678148269653, loss G: -0.0853879302740097\n",
      "Epoch [4/10] Batch [279/469] Loss D: -0.2853648364543915, loss G: -0.3743916153907776\n",
      "Epoch [4/10] Batch [280/469] Loss D: -0.42628204822540283, loss G: -0.12138095498085022\n",
      "Epoch [4/10] Batch [281/469] Loss D: -0.3607668876647949, loss G: -0.30303955078125\n",
      "Epoch [4/10] Batch [282/469] Loss D: -0.4554961025714874, loss G: -0.14488813281059265\n",
      "Epoch [4/10] Batch [283/469] Loss D: -0.4350876808166504, loss G: -0.3293215036392212\n",
      "Epoch [4/10] Batch [284/469] Loss D: -0.35377031564712524, loss G: -0.14582405984401703\n",
      "Epoch [4/10] Batch [285/469] Loss D: -0.49109357595443726, loss G: -0.2731490433216095\n",
      "Epoch [4/10] Batch [286/469] Loss D: -0.38452261686325073, loss G: -0.19784851372241974\n",
      "Epoch [4/10] Batch [287/469] Loss D: -0.4507322609424591, loss G: -0.1603224277496338\n",
      "Epoch [4/10] Batch [288/469] Loss D: -0.4304575026035309, loss G: -0.3715950846672058\n",
      "Epoch [4/10] Batch [289/469] Loss D: -0.26244091987609863, loss G: -0.32826587557792664\n",
      "Epoch [4/10] Batch [290/469] Loss D: -0.41778552532196045, loss G: -0.14593636989593506\n",
      "Epoch [4/10] Batch [291/469] Loss D: -0.3951638638973236, loss G: -0.3572627305984497\n",
      "Epoch [4/10] Batch [292/469] Loss D: -0.4356994032859802, loss G: -0.13839955627918243\n",
      "Epoch [4/10] Batch [293/469] Loss D: -0.41396084427833557, loss G: -0.3701954782009125\n",
      "Epoch [4/10] Batch [294/469] Loss D: -0.34685850143432617, loss G: -0.14253538846969604\n",
      "Epoch [4/10] Batch [295/469] Loss D: -0.3781277537345886, loss G: -0.1820860505104065\n",
      "Epoch [4/10] Batch [296/469] Loss D: -0.507168710231781, loss G: -0.3552607297897339\n",
      "Epoch [4/10] Batch [297/469] Loss D: -0.3544650673866272, loss G: -0.2025548219680786\n",
      "Epoch [4/10] Batch [298/469] Loss D: -0.2714996039867401, loss G: -0.0917375385761261\n",
      "Epoch [4/10] Batch [299/469] Loss D: -0.30021724104881287, loss G: -0.3376013934612274\n",
      "Epoch [4/10] Batch [300/469] Loss D: -0.4435765743255615, loss G: -0.16418364644050598\n",
      "Epoch [4/10] Batch [301/469] Loss D: -0.5457215309143066, loss G: -0.13022463023662567\n",
      "Epoch [4/10] Batch [302/469] Loss D: -0.5022808313369751, loss G: -0.26162222027778625\n",
      "Epoch [4/10] Batch [303/469] Loss D: -0.5210741758346558, loss G: -0.06620264053344727\n",
      "Epoch [4/10] Batch [304/469] Loss D: -0.4266071915626526, loss G: -0.3712952136993408\n",
      "Epoch [4/10] Batch [305/469] Loss D: -0.3542075753211975, loss G: -0.13788461685180664\n",
      "Epoch [4/10] Batch [306/469] Loss D: -0.4694806933403015, loss G: -0.27522337436676025\n",
      "Epoch [4/10] Batch [307/469] Loss D: -0.4345141053199768, loss G: -0.16060173511505127\n",
      "Epoch [4/10] Batch [308/469] Loss D: -0.4074462056159973, loss G: -0.2720559239387512\n",
      "Epoch [4/10] Batch [309/469] Loss D: -0.46217596530914307, loss G: -0.28101152181625366\n",
      "Epoch [4/10] Batch [310/469] Loss D: -0.4515524208545685, loss G: -0.09780680388212204\n",
      "Epoch [4/10] Batch [311/469] Loss D: -0.4251737892627716, loss G: -0.30776673555374146\n",
      "Epoch [4/10] Batch [312/469] Loss D: -0.45804375410079956, loss G: -0.11860360205173492\n",
      "Epoch [4/10] Batch [313/469] Loss D: -0.3637692332267761, loss G: -0.3957791030406952\n",
      "Epoch [4/10] Batch [314/469] Loss D: -0.3587857484817505, loss G: -0.10407063364982605\n",
      "Epoch [4/10] Batch [315/469] Loss D: -0.3399280309677124, loss G: -0.2865925431251526\n",
      "Epoch [4/10] Batch [316/469] Loss D: -0.42621511220932007, loss G: -0.13872386515140533\n",
      "Epoch [4/10] Batch [317/469] Loss D: -0.4217861294746399, loss G: -0.28656697273254395\n",
      "Epoch [4/10] Batch [318/469] Loss D: -0.4914208650588989, loss G: -0.2219872772693634\n",
      "Epoch [4/10] Batch [319/469] Loss D: -0.464376837015152, loss G: -0.11612635105848312\n",
      "Epoch [4/10] Batch [320/469] Loss D: -0.4538533091545105, loss G: -0.26243388652801514\n",
      "Epoch [4/10] Batch [321/469] Loss D: -0.49761253595352173, loss G: -0.25167879462242126\n",
      "Epoch [4/10] Batch [322/469] Loss D: -0.45111650228500366, loss G: -0.15089541673660278\n",
      "Epoch [4/10] Batch [323/469] Loss D: -0.4546121656894684, loss G: -0.21125641465187073\n",
      "Epoch [4/10] Batch [324/469] Loss D: -0.4463878870010376, loss G: -0.23360422253608704\n",
      "Epoch [4/10] Batch [325/469] Loss D: -0.5054692029953003, loss G: -0.13805153965950012\n",
      "Epoch [4/10] Batch [326/469] Loss D: -0.3294868469238281, loss G: -0.49246078729629517\n",
      "Epoch [4/10] Batch [327/469] Loss D: -0.3704836964607239, loss G: -0.1674918830394745\n",
      "Epoch [4/10] Batch [328/469] Loss D: -0.4226571023464203, loss G: -0.20140597224235535\n",
      "Epoch [4/10] Batch [329/469] Loss D: -0.44716355204582214, loss G: -0.19939109683036804\n",
      "Epoch [4/10] Batch [330/469] Loss D: -0.4877873957157135, loss G: -0.19328241050243378\n",
      "Epoch [4/10] Batch [331/469] Loss D: -0.4414479732513428, loss G: -0.3263280391693115\n",
      "Epoch [4/10] Batch [332/469] Loss D: -0.43736451864242554, loss G: -0.09793639928102493\n",
      "Epoch [4/10] Batch [333/469] Loss D: -0.5150015354156494, loss G: -0.2648097276687622\n",
      "Epoch [4/10] Batch [334/469] Loss D: -0.5030121207237244, loss G: -0.08702254295349121\n",
      "Epoch [4/10] Batch [335/469] Loss D: -0.4381014406681061, loss G: -0.3723846673965454\n",
      "Epoch [4/10] Batch [336/469] Loss D: -0.32572096586227417, loss G: -0.17898084223270416\n",
      "Epoch [4/10] Batch [337/469] Loss D: -0.4179936349391937, loss G: -0.21635383367538452\n",
      "Epoch [4/10] Batch [338/469] Loss D: -0.42711037397384644, loss G: -0.27606266736984253\n",
      "Epoch [4/10] Batch [339/469] Loss D: -0.3325845003128052, loss G: -0.2675563097000122\n",
      "Epoch [4/10] Batch [340/469] Loss D: -0.36402496695518494, loss G: -0.302848219871521\n",
      "Epoch [4/10] Batch [341/469] Loss D: -0.4676350951194763, loss G: -0.11027489602565765\n",
      "Epoch [4/10] Batch [342/469] Loss D: -0.38927632570266724, loss G: -0.39772361516952515\n",
      "Epoch [4/10] Batch [343/469] Loss D: -0.35685741901397705, loss G: -0.09311360120773315\n",
      "Epoch [4/10] Batch [344/469] Loss D: -0.35079866647720337, loss G: -0.3546109199523926\n",
      "Epoch [4/10] Batch [345/469] Loss D: -0.40794113278388977, loss G: -0.2291279137134552\n",
      "Epoch [4/10] Batch [346/469] Loss D: -0.43496060371398926, loss G: -0.18769586086273193\n",
      "Epoch [4/10] Batch [347/469] Loss D: -0.48276934027671814, loss G: -0.3143845796585083\n",
      "Epoch [4/10] Batch [348/469] Loss D: -0.41188114881515503, loss G: -0.15488705039024353\n",
      "Epoch [4/10] Batch [349/469] Loss D: -0.4005339741706848, loss G: -0.3381465971469879\n",
      "Epoch [4/10] Batch [350/469] Loss D: -0.38517141342163086, loss G: -0.18241141736507416\n",
      "Epoch [4/10] Batch [351/469] Loss D: -0.5486890077590942, loss G: -0.18018771708011627\n",
      "Epoch [4/10] Batch [352/469] Loss D: -0.48010244965553284, loss G: -0.27678054571151733\n",
      "Epoch [4/10] Batch [353/469] Loss D: -0.4634194076061249, loss G: -0.0956805869936943\n",
      "Epoch [4/10] Batch [354/469] Loss D: -0.4469076097011566, loss G: -0.37816303968429565\n",
      "Epoch [4/10] Batch [355/469] Loss D: -0.404691219329834, loss G: -0.09993505477905273\n",
      "Epoch [4/10] Batch [356/469] Loss D: -0.3863601088523865, loss G: -0.30331504344940186\n",
      "Epoch [4/10] Batch [357/469] Loss D: -0.41565656661987305, loss G: -0.21223798394203186\n",
      "Epoch [4/10] Batch [358/469] Loss D: -0.3781540095806122, loss G: -0.2976955771446228\n",
      "Epoch [4/10] Batch [359/469] Loss D: -0.4134633243083954, loss G: -0.212558776140213\n",
      "Epoch [4/10] Batch [360/469] Loss D: -0.4871390461921692, loss G: -0.25749093294143677\n",
      "Epoch [4/10] Batch [361/469] Loss D: -0.4992962181568146, loss G: -0.1110612228512764\n",
      "Epoch [4/10] Batch [362/469] Loss D: -0.5049905776977539, loss G: -0.20691969990730286\n",
      "Epoch [4/10] Batch [363/469] Loss D: -0.5008596777915955, loss G: -0.20269230008125305\n",
      "Epoch [4/10] Batch [364/469] Loss D: -0.4027388095855713, loss G: -0.2584773302078247\n",
      "Epoch [4/10] Batch [365/469] Loss D: -0.39209234714508057, loss G: -0.2171868085861206\n",
      "Epoch [4/10] Batch [366/469] Loss D: -0.4592730700969696, loss G: -0.11338022351264954\n",
      "Epoch [4/10] Batch [367/469] Loss D: -0.39846131205558777, loss G: -0.4197951853275299\n",
      "Epoch [4/10] Batch [368/469] Loss D: -0.3066818118095398, loss G: -0.21880775690078735\n",
      "Epoch [4/10] Batch [369/469] Loss D: -0.4400193691253662, loss G: -0.2380390167236328\n",
      "Epoch [4/10] Batch [370/469] Loss D: -0.46211904287338257, loss G: -0.08128537237644196\n",
      "Epoch [4/10] Batch [371/469] Loss D: -0.31680065393447876, loss G: -0.370758980512619\n",
      "Epoch [4/10] Batch [372/469] Loss D: -0.4756650924682617, loss G: -0.13856476545333862\n",
      "Epoch [4/10] Batch [373/469] Loss D: -0.48627328872680664, loss G: -0.21344251930713654\n",
      "Epoch [4/10] Batch [374/469] Loss D: -0.5141894817352295, loss G: -0.12547019124031067\n",
      "Epoch [4/10] Batch [375/469] Loss D: -0.4272990822792053, loss G: -0.4337916374206543\n",
      "Epoch [4/10] Batch [376/469] Loss D: -0.3644656538963318, loss G: -0.08242480456829071\n",
      "Epoch [4/10] Batch [377/469] Loss D: -0.3789442479610443, loss G: -0.3261663317680359\n",
      "Epoch [4/10] Batch [378/469] Loss D: -0.4277779459953308, loss G: -0.15366607904434204\n",
      "Epoch [4/10] Batch [379/469] Loss D: -0.3721233606338501, loss G: -0.2894446849822998\n",
      "Epoch [4/10] Batch [380/469] Loss D: -0.46455806493759155, loss G: -0.05421566590666771\n",
      "Epoch [4/10] Batch [381/469] Loss D: -0.40102657675743103, loss G: -0.37124401330947876\n",
      "Epoch [4/10] Batch [382/469] Loss D: -0.38892269134521484, loss G: -0.23503859341144562\n",
      "Epoch [4/10] Batch [383/469] Loss D: -0.516112208366394, loss G: -0.059775371104478836\n",
      "Epoch [4/10] Batch [384/469] Loss D: -0.49760907888412476, loss G: -0.37468862533569336\n",
      "Epoch [4/10] Batch [385/469] Loss D: -0.44202494621276855, loss G: -0.10644225776195526\n",
      "Epoch [4/10] Batch [386/469] Loss D: -0.5176255702972412, loss G: -0.21886923909187317\n",
      "Epoch [4/10] Batch [387/469] Loss D: -0.40187832713127136, loss G: -0.2410091608762741\n",
      "Epoch [4/10] Batch [388/469] Loss D: -0.39687681198120117, loss G: -0.21437029540538788\n",
      "Epoch [4/10] Batch [389/469] Loss D: -0.44637492299079895, loss G: -0.15199798345565796\n",
      "Epoch [4/10] Batch [390/469] Loss D: -0.47260263562202454, loss G: -0.2128935158252716\n",
      "Epoch [4/10] Batch [391/469] Loss D: -0.46762529015541077, loss G: -0.24592027068138123\n",
      "Epoch [4/10] Batch [392/469] Loss D: -0.3904339671134949, loss G: -0.23639102280139923\n",
      "Epoch [4/10] Batch [393/469] Loss D: -0.40693196654319763, loss G: -0.18505996465682983\n",
      "Epoch [4/10] Batch [394/469] Loss D: -0.41789132356643677, loss G: -0.3427773714065552\n",
      "Epoch [4/10] Batch [395/469] Loss D: -0.45256307721138, loss G: -0.11684654653072357\n",
      "Epoch [4/10] Batch [396/469] Loss D: -0.284789502620697, loss G: -0.32901227474212646\n",
      "Epoch [4/10] Batch [397/469] Loss D: -0.4656357169151306, loss G: -0.09882135689258575\n",
      "Epoch [4/10] Batch [398/469] Loss D: -0.3226487934589386, loss G: -0.35742679238319397\n",
      "Epoch [4/10] Batch [399/469] Loss D: -0.4133267402648926, loss G: -0.20637810230255127\n",
      "Epoch [4/10] Batch [400/469] Loss D: -0.44345808029174805, loss G: -0.18100234866142273\n",
      "Epoch [4/10] Batch [401/469] Loss D: -0.35343432426452637, loss G: -0.25312021374702454\n",
      "Epoch [4/10] Batch [402/469] Loss D: -0.43831783533096313, loss G: -0.30253803730010986\n",
      "Epoch [4/10] Batch [403/469] Loss D: -0.467880517244339, loss G: -0.12155838310718536\n",
      "Epoch [4/10] Batch [404/469] Loss D: -0.31084954738616943, loss G: -0.26009601354599\n",
      "Epoch [4/10] Batch [405/469] Loss D: -0.49172669649124146, loss G: -0.1928601861000061\n",
      "Epoch [4/10] Batch [406/469] Loss D: -0.4639420807361603, loss G: -0.2213355153799057\n",
      "Epoch [4/10] Batch [407/469] Loss D: -0.3395875096321106, loss G: -0.29066002368927\n",
      "Epoch [4/10] Batch [408/469] Loss D: -0.4378696084022522, loss G: -0.12419896572828293\n",
      "Epoch [4/10] Batch [409/469] Loss D: -0.3394598364830017, loss G: -0.37910565733909607\n",
      "Epoch [4/10] Batch [410/469] Loss D: -0.4195028245449066, loss G: -0.2096833884716034\n",
      "Epoch [4/10] Batch [411/469] Loss D: -0.47403937578201294, loss G: -0.1297081708908081\n",
      "Epoch [4/10] Batch [412/469] Loss D: -0.4342310428619385, loss G: -0.34845367074012756\n",
      "Epoch [4/10] Batch [413/469] Loss D: -0.5629258155822754, loss G: -0.08802495151758194\n",
      "Epoch [4/10] Batch [414/469] Loss D: -0.38751399517059326, loss G: -0.3797425329685211\n",
      "Epoch [4/10] Batch [415/469] Loss D: -0.3435550928115845, loss G: -0.13901694118976593\n",
      "Epoch [4/10] Batch [416/469] Loss D: -0.44010406732559204, loss G: -0.31313180923461914\n",
      "Epoch [4/10] Batch [417/469] Loss D: -0.4243181049823761, loss G: -0.22367750108242035\n",
      "Epoch [4/10] Batch [418/469] Loss D: -0.45622673630714417, loss G: -0.23830917477607727\n",
      "Epoch [4/10] Batch [419/469] Loss D: -0.4973887801170349, loss G: -0.15781955420970917\n",
      "Epoch [4/10] Batch [420/469] Loss D: -0.4901963472366333, loss G: -0.24717187881469727\n",
      "Epoch [4/10] Batch [421/469] Loss D: -0.3972722291946411, loss G: -0.29166415333747864\n",
      "Epoch [4/10] Batch [422/469] Loss D: -0.3694118857383728, loss G: -0.14803680777549744\n",
      "Epoch [4/10] Batch [423/469] Loss D: -0.45091184973716736, loss G: -0.2453274428844452\n",
      "Epoch [4/10] Batch [424/469] Loss D: -0.39852258563041687, loss G: -0.22598165273666382\n",
      "Epoch [4/10] Batch [425/469] Loss D: -0.48342734575271606, loss G: -0.16072086989879608\n",
      "Epoch [4/10] Batch [426/469] Loss D: -0.4414823055267334, loss G: -0.23867720365524292\n",
      "Epoch [4/10] Batch [427/469] Loss D: -0.41013386845588684, loss G: -0.24903668463230133\n",
      "Epoch [4/10] Batch [428/469] Loss D: -0.44580650329589844, loss G: -0.19545908272266388\n",
      "Epoch [4/10] Batch [429/469] Loss D: -0.3344497084617615, loss G: -0.37902021408081055\n",
      "Epoch [4/10] Batch [430/469] Loss D: -0.4306543171405792, loss G: -0.07604975253343582\n",
      "Epoch [4/10] Batch [431/469] Loss D: -0.47964444756507874, loss G: -0.3388751149177551\n",
      "Epoch [4/10] Batch [432/469] Loss D: -0.4889388680458069, loss G: -0.15608437359333038\n",
      "Epoch [4/10] Batch [433/469] Loss D: -0.4417807161808014, loss G: -0.3115723729133606\n",
      "Epoch [4/10] Batch [434/469] Loss D: -0.4351069927215576, loss G: -0.100332111120224\n",
      "Epoch [4/10] Batch [435/469] Loss D: -0.3760184347629547, loss G: -0.3885047435760498\n",
      "Epoch [4/10] Batch [436/469] Loss D: -0.40398120880126953, loss G: -0.21929237246513367\n",
      "Epoch [4/10] Batch [437/469] Loss D: -0.5013034343719482, loss G: -0.15041974186897278\n",
      "Epoch [4/10] Batch [438/469] Loss D: -0.5770605802536011, loss G: -0.16012609004974365\n",
      "Epoch [4/10] Batch [439/469] Loss D: -0.40409407019615173, loss G: -0.3754258453845978\n",
      "Epoch [4/10] Batch [440/469] Loss D: -0.3987869322299957, loss G: -0.21382397413253784\n",
      "Epoch [4/10] Batch [441/469] Loss D: -0.46578529477119446, loss G: -0.1501430720090866\n",
      "Epoch [4/10] Batch [442/469] Loss D: -0.4541839361190796, loss G: -0.3781033754348755\n",
      "Epoch [4/10] Batch [443/469] Loss D: -0.41536229848861694, loss G: -0.15438781678676605\n",
      "Epoch [4/10] Batch [444/469] Loss D: -0.44116514921188354, loss G: -0.2900336980819702\n",
      "Epoch [4/10] Batch [445/469] Loss D: -0.44865167140960693, loss G: -0.19754350185394287\n",
      "Epoch [4/10] Batch [446/469] Loss D: -0.48731350898742676, loss G: -0.10022944957017899\n",
      "Epoch [4/10] Batch [447/469] Loss D: -0.38504818081855774, loss G: -0.4370308220386505\n",
      "Epoch [4/10] Batch [448/469] Loss D: -0.3768383264541626, loss G: -0.19185037910938263\n",
      "Epoch [4/10] Batch [449/469] Loss D: -0.48620927333831787, loss G: -0.13765792548656464\n",
      "Epoch [4/10] Batch [450/469] Loss D: -0.4330946207046509, loss G: -0.3260148763656616\n",
      "Epoch [4/10] Batch [451/469] Loss D: -0.41112709045410156, loss G: -0.17902401089668274\n",
      "Epoch [4/10] Batch [452/469] Loss D: -0.42002058029174805, loss G: -0.2804550528526306\n",
      "Epoch [4/10] Batch [453/469] Loss D: -0.45717868208885193, loss G: -0.27974551916122437\n",
      "Epoch [4/10] Batch [454/469] Loss D: -0.4388008117675781, loss G: -0.20144522190093994\n",
      "Epoch [4/10] Batch [455/469] Loss D: -0.41415277123451233, loss G: -0.2284325510263443\n",
      "Epoch [4/10] Batch [456/469] Loss D: -0.3486528992652893, loss G: -0.3012734055519104\n",
      "Epoch [4/10] Batch [457/469] Loss D: -0.44110867381095886, loss G: -0.15357089042663574\n",
      "Epoch [4/10] Batch [458/469] Loss D: -0.37858304381370544, loss G: -0.3498179316520691\n",
      "Epoch [4/10] Batch [459/469] Loss D: -0.3679109811782837, loss G: -0.194789856672287\n",
      "Epoch [4/10] Batch [460/469] Loss D: -0.46457937359809875, loss G: -0.2991563379764557\n",
      "Epoch [4/10] Batch [461/469] Loss D: -0.4141763746738434, loss G: -0.18072380125522614\n",
      "Epoch [4/10] Batch [462/469] Loss D: -0.49133554100990295, loss G: -0.24424923956394196\n",
      "Epoch [4/10] Batch [463/469] Loss D: -0.5039361715316772, loss G: -0.1516939252614975\n",
      "Epoch [4/10] Batch [464/469] Loss D: -0.4291573464870453, loss G: -0.2450651228427887\n",
      "Epoch [4/10] Batch [465/469] Loss D: -0.3360448479652405, loss G: -0.3152026832103729\n",
      "Epoch [4/10] Batch [466/469] Loss D: -0.39985206723213196, loss G: -0.19406157732009888\n",
      "Epoch [4/10] Batch [467/469] Loss D: -0.44953715801239014, loss G: -0.2600531578063965\n",
      "Epoch [4/10] Batch [468/469] Loss D: -0.4296000003814697, loss G: -0.08826231956481934\n",
      "Epoch [4/10] Batch [469/469] Loss D: -0.4187160134315491, loss G: -0.39184457063674927\n",
      "Epoch [5/10] Batch [1/469] Loss D: -0.43589964509010315, loss G: -0.19556152820587158\n",
      "Epoch [5/10] Batch [2/469] Loss D: -0.44289061427116394, loss G: -0.14128407835960388\n",
      "Epoch [5/10] Batch [3/469] Loss D: -0.4842386841773987, loss G: -0.4274941384792328\n",
      "Epoch [5/10] Batch [4/469] Loss D: -0.40201616287231445, loss G: -0.202255517244339\n",
      "Epoch [5/10] Batch [5/469] Loss D: -0.4666808843612671, loss G: -0.16056925058364868\n",
      "Epoch [5/10] Batch [6/469] Loss D: -0.478847861289978, loss G: -0.2786470353603363\n",
      "Epoch [5/10] Batch [7/469] Loss D: -0.4778013229370117, loss G: -0.21706783771514893\n",
      "Epoch [5/10] Batch [8/469] Loss D: -0.4247973561286926, loss G: -0.2543427348136902\n",
      "Epoch [5/10] Batch [9/469] Loss D: -0.4672084450721741, loss G: -0.20715579390525818\n",
      "Epoch [5/10] Batch [10/469] Loss D: -0.4775763750076294, loss G: -0.2774609625339508\n",
      "Epoch [5/10] Batch [11/469] Loss D: -0.30406057834625244, loss G: -0.33155012130737305\n",
      "Epoch [5/10] Batch [12/469] Loss D: -0.44518333673477173, loss G: -0.16308164596557617\n",
      "Epoch [5/10] Batch [13/469] Loss D: -0.458332896232605, loss G: -0.43243470788002014\n",
      "Epoch [5/10] Batch [14/469] Loss D: -0.332547664642334, loss G: -0.2707534432411194\n",
      "Epoch [5/10] Batch [15/469] Loss D: -0.38415780663490295, loss G: -0.19206762313842773\n",
      "Epoch [5/10] Batch [16/469] Loss D: -0.46703729033470154, loss G: -0.2554720342159271\n",
      "Epoch [5/10] Batch [17/469] Loss D: -0.4884936809539795, loss G: -0.20395389199256897\n",
      "Epoch [5/10] Batch [18/469] Loss D: -0.5389437675476074, loss G: -0.08250600099563599\n",
      "Epoch [5/10] Batch [19/469] Loss D: -0.37872838973999023, loss G: -0.4116683006286621\n",
      "Epoch [5/10] Batch [20/469] Loss D: -0.33652687072753906, loss G: -0.08804463595151901\n",
      "Epoch [5/10] Batch [21/469] Loss D: -0.45969581604003906, loss G: -0.3415294289588928\n",
      "Epoch [5/10] Batch [22/469] Loss D: -0.3965573310852051, loss G: -0.1745520681142807\n",
      "Epoch [5/10] Batch [23/469] Loss D: -0.40563276410102844, loss G: -0.2065853476524353\n",
      "Epoch [5/10] Batch [24/469] Loss D: -0.49717867374420166, loss G: -0.18756414949893951\n",
      "Epoch [5/10] Batch [25/469] Loss D: -0.49129894375801086, loss G: -0.15685981512069702\n",
      "Epoch [5/10] Batch [26/469] Loss D: -0.49087825417518616, loss G: -0.20474952459335327\n",
      "Epoch [5/10] Batch [27/469] Loss D: -0.4768093228340149, loss G: -0.14646893739700317\n",
      "Epoch [5/10] Batch [28/469] Loss D: -0.4984646439552307, loss G: -0.23912714421749115\n",
      "Epoch [5/10] Batch [29/469] Loss D: -0.4465716481208801, loss G: -0.16085213422775269\n",
      "Epoch [5/10] Batch [30/469] Loss D: -0.4795626401901245, loss G: -0.2407378852367401\n",
      "Epoch [5/10] Batch [31/469] Loss D: -0.5050509572029114, loss G: -0.16266748309135437\n",
      "Epoch [5/10] Batch [32/469] Loss D: -0.4138522148132324, loss G: -0.4087088704109192\n",
      "Epoch [5/10] Batch [33/469] Loss D: -0.37077605724334717, loss G: -0.15673062205314636\n",
      "Epoch [5/10] Batch [34/469] Loss D: -0.3742830157279968, loss G: -0.3202354609966278\n",
      "Epoch [5/10] Batch [35/469] Loss D: -0.4504703879356384, loss G: -0.2465251237154007\n",
      "Epoch [5/10] Batch [36/469] Loss D: -0.43765324354171753, loss G: -0.21875226497650146\n",
      "Epoch [5/10] Batch [37/469] Loss D: -0.471941202878952, loss G: -0.15253359079360962\n",
      "Epoch [5/10] Batch [38/469] Loss D: -0.4168444871902466, loss G: -0.29586172103881836\n",
      "Epoch [5/10] Batch [39/469] Loss D: -0.4690924882888794, loss G: -0.20180541276931763\n",
      "Epoch [5/10] Batch [40/469] Loss D: -0.5323078632354736, loss G: -0.11706167459487915\n",
      "Epoch [5/10] Batch [41/469] Loss D: -0.4160574972629547, loss G: -0.46380284428596497\n",
      "Epoch [5/10] Batch [42/469] Loss D: -0.33618390560150146, loss G: -0.17465820908546448\n",
      "Epoch [5/10] Batch [43/469] Loss D: -0.47399282455444336, loss G: -0.10218693315982819\n",
      "Epoch [5/10] Batch [44/469] Loss D: -0.44323253631591797, loss G: -0.509290874004364\n",
      "Epoch [5/10] Batch [45/469] Loss D: -0.2809082865715027, loss G: -0.22439798712730408\n",
      "Epoch [5/10] Batch [46/469] Loss D: -0.42531535029411316, loss G: -0.15176738798618317\n",
      "Epoch [5/10] Batch [47/469] Loss D: -0.270652174949646, loss G: -0.35500553250312805\n",
      "Epoch [5/10] Batch [48/469] Loss D: -0.35192304849624634, loss G: -0.18814310431480408\n",
      "Epoch [5/10] Batch [49/469] Loss D: -0.2104356288909912, loss G: -0.2394288033246994\n",
      "Epoch [5/10] Batch [50/469] Loss D: -0.4051187336444855, loss G: -0.1940833330154419\n",
      "Epoch [5/10] Batch [51/469] Loss D: -0.43332186341285706, loss G: -0.34662145376205444\n",
      "Epoch [5/10] Batch [52/469] Loss D: -0.46489089727401733, loss G: -0.053983837366104126\n",
      "Epoch [5/10] Batch [53/469] Loss D: -0.5524435043334961, loss G: -0.2545008361339569\n",
      "Epoch [5/10] Batch [54/469] Loss D: -0.4247925281524658, loss G: -0.34263497591018677\n",
      "Epoch [5/10] Batch [55/469] Loss D: -0.35589632391929626, loss G: -0.14135602116584778\n",
      "Epoch [5/10] Batch [56/469] Loss D: -0.4310011565685272, loss G: -0.188945472240448\n",
      "Epoch [5/10] Batch [57/469] Loss D: -0.33710649609565735, loss G: -0.37940889596939087\n",
      "Epoch [5/10] Batch [58/469] Loss D: -0.35386475920677185, loss G: -0.2362804114818573\n",
      "Epoch [5/10] Batch [59/469] Loss D: -0.4799693524837494, loss G: -0.11175473779439926\n",
      "Epoch [5/10] Batch [60/469] Loss D: -0.40571874380111694, loss G: -0.38671886920928955\n",
      "Epoch [5/10] Batch [61/469] Loss D: -0.3847969174385071, loss G: -0.14979970455169678\n",
      "Epoch [5/10] Batch [62/469] Loss D: -0.4822700321674347, loss G: -0.20965933799743652\n",
      "Epoch [5/10] Batch [63/469] Loss D: -0.4134151339530945, loss G: -0.20107713341712952\n",
      "Epoch [5/10] Batch [64/469] Loss D: -0.5654931664466858, loss G: -0.1551581770181656\n",
      "Epoch [5/10] Batch [65/469] Loss D: -0.4140528440475464, loss G: -0.18946953117847443\n",
      "Epoch [5/10] Batch [66/469] Loss D: -0.48515820503234863, loss G: -0.1739177405834198\n",
      "Epoch [5/10] Batch [67/469] Loss D: -0.5335938930511475, loss G: -0.12341918796300888\n",
      "Epoch [5/10] Batch [68/469] Loss D: -0.5039194822311401, loss G: -0.25464755296707153\n",
      "Epoch [5/10] Batch [69/469] Loss D: -0.501352071762085, loss G: -0.1757391095161438\n",
      "Epoch [5/10] Batch [70/469] Loss D: -0.4639667868614197, loss G: -0.14106398820877075\n",
      "Epoch [5/10] Batch [71/469] Loss D: -0.4832237958908081, loss G: -0.33171290159225464\n",
      "Epoch [5/10] Batch [72/469] Loss D: -0.4156686067581177, loss G: -0.13818912208080292\n",
      "Epoch [5/10] Batch [73/469] Loss D: -0.4148605763912201, loss G: -0.23858773708343506\n",
      "Epoch [5/10] Batch [74/469] Loss D: -0.4633696377277374, loss G: -0.11443782597780228\n",
      "Epoch [5/10] Batch [75/469] Loss D: -0.41039371490478516, loss G: -0.4559180736541748\n",
      "Epoch [5/10] Batch [76/469] Loss D: -0.3248201012611389, loss G: -0.1793414056301117\n",
      "Epoch [5/10] Batch [77/469] Loss D: -0.5189461708068848, loss G: -0.12092481553554535\n",
      "Epoch [5/10] Batch [78/469] Loss D: -0.3835270404815674, loss G: -0.4414374530315399\n",
      "Epoch [5/10] Batch [79/469] Loss D: -0.34688693284988403, loss G: -0.13742484152317047\n",
      "Epoch [5/10] Batch [80/469] Loss D: -0.41860562562942505, loss G: -0.2384144514799118\n",
      "Epoch [5/10] Batch [81/469] Loss D: -0.49329715967178345, loss G: -0.2811813950538635\n",
      "Epoch [5/10] Batch [82/469] Loss D: -0.4013133645057678, loss G: -0.10369285196065903\n",
      "Epoch [5/10] Batch [83/469] Loss D: -0.4439956843852997, loss G: -0.23227031528949738\n",
      "Epoch [5/10] Batch [84/469] Loss D: -0.44567254185676575, loss G: -0.2556484043598175\n",
      "Epoch [5/10] Batch [85/469] Loss D: -0.4057392179965973, loss G: -0.20567381381988525\n",
      "Epoch [5/10] Batch [86/469] Loss D: -0.4071740508079529, loss G: -0.31383639574050903\n",
      "Epoch [5/10] Batch [87/469] Loss D: -0.36317458748817444, loss G: -0.21599683165550232\n",
      "Epoch [5/10] Batch [88/469] Loss D: -0.41288697719573975, loss G: -0.23914265632629395\n",
      "Epoch [5/10] Batch [89/469] Loss D: -0.38988006114959717, loss G: -0.2490924596786499\n",
      "Epoch [5/10] Batch [90/469] Loss D: -0.40579211711883545, loss G: -0.18685752153396606\n",
      "Epoch [5/10] Batch [91/469] Loss D: -0.4317398965358734, loss G: -0.09841107577085495\n",
      "Epoch [5/10] Batch [92/469] Loss D: -0.38042232394218445, loss G: -0.4650818705558777\n",
      "Epoch [5/10] Batch [93/469] Loss D: -0.3966066241264343, loss G: -0.11413642019033432\n",
      "Epoch [5/10] Batch [94/469] Loss D: -0.4363115131855011, loss G: -0.17839813232421875\n",
      "Epoch [5/10] Batch [95/469] Loss D: -0.33575549721717834, loss G: -0.3521977663040161\n",
      "Epoch [5/10] Batch [96/469] Loss D: -0.40810030698776245, loss G: -0.212522953748703\n",
      "Epoch [5/10] Batch [97/469] Loss D: -0.5525847673416138, loss G: -0.10949154943227768\n",
      "Epoch [5/10] Batch [98/469] Loss D: -0.39477258920669556, loss G: -0.39134928584098816\n",
      "Epoch [5/10] Batch [99/469] Loss D: -0.36406126618385315, loss G: -0.2630181610584259\n",
      "Epoch [5/10] Batch [100/469] Loss D: -0.44135987758636475, loss G: -0.10425156354904175\n",
      "Epoch [5/10] Batch [101/469] Loss D: -0.38583675026893616, loss G: -0.3081330358982086\n",
      "Epoch [5/10] Batch [102/469] Loss D: -0.40991905331611633, loss G: -0.31468865275382996\n",
      "Epoch [5/10] Batch [103/469] Loss D: -0.4340248107910156, loss G: -0.10227938741445541\n",
      "Epoch [5/10] Batch [104/469] Loss D: -0.43155333399772644, loss G: -0.27927786111831665\n",
      "Epoch [5/10] Batch [105/469] Loss D: -0.34305357933044434, loss G: -0.35942524671554565\n",
      "Epoch [5/10] Batch [106/469] Loss D: -0.3008444309234619, loss G: -0.2203654646873474\n",
      "Epoch [5/10] Batch [107/469] Loss D: -0.4552856981754303, loss G: -0.18819062411785126\n",
      "Epoch [5/10] Batch [108/469] Loss D: -0.3861466646194458, loss G: -0.33608341217041016\n",
      "Epoch [5/10] Batch [109/469] Loss D: -0.44681787490844727, loss G: -0.18103089928627014\n",
      "Epoch [5/10] Batch [110/469] Loss D: -0.4703015685081482, loss G: -0.19965484738349915\n",
      "Epoch [5/10] Batch [111/469] Loss D: -0.4430569112300873, loss G: -0.29164227843284607\n",
      "Epoch [5/10] Batch [112/469] Loss D: -0.44713258743286133, loss G: -0.17981109023094177\n",
      "Epoch [5/10] Batch [113/469] Loss D: -0.46576768159866333, loss G: -0.2177431881427765\n",
      "Epoch [5/10] Batch [114/469] Loss D: -0.45806413888931274, loss G: -0.22175154089927673\n",
      "Epoch [5/10] Batch [115/469] Loss D: -0.48822617530822754, loss G: -0.34103554487228394\n",
      "Epoch [5/10] Batch [116/469] Loss D: -0.5254531502723694, loss G: -0.04774431884288788\n",
      "Epoch [5/10] Batch [117/469] Loss D: -0.34075844287872314, loss G: -0.3112381398677826\n",
      "Epoch [5/10] Batch [118/469] Loss D: -0.44143158197402954, loss G: -0.1815149486064911\n",
      "Epoch [5/10] Batch [119/469] Loss D: -0.4316976070404053, loss G: -0.2766704559326172\n",
      "Epoch [5/10] Batch [120/469] Loss D: -0.44024842977523804, loss G: -0.2066199779510498\n",
      "Epoch [5/10] Batch [121/469] Loss D: -0.4400486946105957, loss G: -0.28011658787727356\n",
      "Epoch [5/10] Batch [122/469] Loss D: -0.3878605365753174, loss G: -0.24202221632003784\n",
      "Epoch [5/10] Batch [123/469] Loss D: -0.4644494950771332, loss G: -0.19119617342948914\n",
      "Epoch [5/10] Batch [124/469] Loss D: -0.46536266803741455, loss G: -0.2400183379650116\n",
      "Epoch [5/10] Batch [125/469] Loss D: -0.42914721369743347, loss G: -0.34810149669647217\n",
      "Epoch [5/10] Batch [126/469] Loss D: -0.41321974992752075, loss G: -0.13563065230846405\n",
      "Epoch [5/10] Batch [127/469] Loss D: -0.33470821380615234, loss G: -0.3091725707054138\n",
      "Epoch [5/10] Batch [128/469] Loss D: -0.41492336988449097, loss G: -0.26807668805122375\n",
      "Epoch [5/10] Batch [129/469] Loss D: -0.4390367269515991, loss G: -0.16129964590072632\n",
      "Epoch [5/10] Batch [130/469] Loss D: -0.4329691529273987, loss G: -0.22294247150421143\n",
      "Epoch [5/10] Batch [131/469] Loss D: -0.4052630066871643, loss G: -0.3034706115722656\n",
      "Epoch [5/10] Batch [132/469] Loss D: -0.4295399785041809, loss G: -0.19389110803604126\n",
      "Epoch [5/10] Batch [133/469] Loss D: -0.45549601316452026, loss G: -0.15187443792819977\n",
      "Epoch [5/10] Batch [134/469] Loss D: -0.42066213488578796, loss G: -0.31364983320236206\n",
      "Epoch [5/10] Batch [135/469] Loss D: -0.4007715880870819, loss G: -0.16676436364650726\n",
      "Epoch [5/10] Batch [136/469] Loss D: -0.3424767255783081, loss G: -0.32431891560554504\n",
      "Epoch [5/10] Batch [137/469] Loss D: -0.3634488582611084, loss G: -0.25705263018608093\n",
      "Epoch [5/10] Batch [138/469] Loss D: -0.3793119192123413, loss G: -0.17318116128444672\n",
      "Epoch [5/10] Batch [139/469] Loss D: -0.4493669867515564, loss G: -0.3937831521034241\n",
      "Epoch [5/10] Batch [140/469] Loss D: -0.3910079598426819, loss G: -0.16769930720329285\n",
      "Epoch [5/10] Batch [141/469] Loss D: -0.4518478512763977, loss G: -0.24112744629383087\n",
      "Epoch [5/10] Batch [142/469] Loss D: -0.4361591637134552, loss G: -0.14662989974021912\n",
      "Epoch [5/10] Batch [143/469] Loss D: -0.4181813895702362, loss G: -0.35058990120887756\n",
      "Epoch [5/10] Batch [144/469] Loss D: -0.5025177001953125, loss G: -0.17432963848114014\n",
      "Epoch [5/10] Batch [145/469] Loss D: -0.4170292019844055, loss G: -0.15401417016983032\n",
      "Epoch [5/10] Batch [146/469] Loss D: -0.3556399643421173, loss G: -0.36797094345092773\n",
      "Epoch [5/10] Batch [147/469] Loss D: -0.4144480228424072, loss G: -0.17085525393486023\n",
      "Epoch [5/10] Batch [148/469] Loss D: -0.42107054591178894, loss G: -0.22176998853683472\n",
      "Epoch [5/10] Batch [149/469] Loss D: -0.488550066947937, loss G: -0.21483252942562103\n",
      "Epoch [5/10] Batch [150/469] Loss D: -0.40573495626449585, loss G: -0.2391844093799591\n",
      "Epoch [5/10] Batch [151/469] Loss D: -0.5449687838554382, loss G: -0.1720116138458252\n",
      "Epoch [5/10] Batch [152/469] Loss D: -0.4315147399902344, loss G: -0.28861138224601746\n",
      "Epoch [5/10] Batch [153/469] Loss D: -0.45035845041275024, loss G: -0.07749547064304352\n",
      "Epoch [5/10] Batch [154/469] Loss D: -0.4514228105545044, loss G: -0.3870774805545807\n",
      "Epoch [5/10] Batch [155/469] Loss D: -0.3733791708946228, loss G: -0.20784074068069458\n",
      "Epoch [5/10] Batch [156/469] Loss D: -0.36959558725357056, loss G: -0.165557861328125\n",
      "Epoch [5/10] Batch [157/469] Loss D: -0.39992207288742065, loss G: -0.3365647792816162\n",
      "Epoch [5/10] Batch [158/469] Loss D: -0.35349464416503906, loss G: -0.16928935050964355\n",
      "Epoch [5/10] Batch [159/469] Loss D: -0.3986319303512573, loss G: -0.32428908348083496\n",
      "Epoch [5/10] Batch [160/469] Loss D: -0.33352261781692505, loss G: -0.20964688062667847\n",
      "Epoch [5/10] Batch [161/469] Loss D: -0.4698438048362732, loss G: -0.1696229726076126\n",
      "Epoch [5/10] Batch [162/469] Loss D: -0.5106887817382812, loss G: -0.3315209746360779\n",
      "Epoch [5/10] Batch [163/469] Loss D: -0.398629367351532, loss G: -0.11284442245960236\n",
      "Epoch [5/10] Batch [164/469] Loss D: -0.3651230037212372, loss G: -0.2555348873138428\n",
      "Epoch [5/10] Batch [165/469] Loss D: -0.4600929617881775, loss G: -0.3824835419654846\n",
      "Epoch [5/10] Batch [166/469] Loss D: -0.40108048915863037, loss G: -0.10031675547361374\n",
      "Epoch [5/10] Batch [167/469] Loss D: -0.34075984358787537, loss G: -0.20017850399017334\n",
      "Epoch [5/10] Batch [168/469] Loss D: -0.4093061089515686, loss G: -0.4725666642189026\n",
      "Epoch [5/10] Batch [169/469] Loss D: -0.3082275986671448, loss G: -0.1607961803674698\n",
      "Epoch [5/10] Batch [170/469] Loss D: -0.37044641375541687, loss G: -0.15068376064300537\n",
      "Epoch [5/10] Batch [171/469] Loss D: -0.44700849056243896, loss G: -0.4080292582511902\n",
      "Epoch [5/10] Batch [172/469] Loss D: -0.3748963475227356, loss G: -0.20552301406860352\n",
      "Epoch [5/10] Batch [173/469] Loss D: -0.34688007831573486, loss G: -0.22437062859535217\n",
      "Epoch [5/10] Batch [174/469] Loss D: -0.4432356357574463, loss G: -0.2714214026927948\n",
      "Epoch [5/10] Batch [175/469] Loss D: -0.40083664655685425, loss G: -0.1440383791923523\n",
      "Epoch [5/10] Batch [176/469] Loss D: -0.3686300218105316, loss G: -0.35245639085769653\n",
      "Epoch [5/10] Batch [177/469] Loss D: -0.40106379985809326, loss G: -0.2520492970943451\n",
      "Epoch [5/10] Batch [178/469] Loss D: -0.3756895661354065, loss G: -0.18172895908355713\n",
      "Epoch [5/10] Batch [179/469] Loss D: -0.47243234515190125, loss G: -0.29136189818382263\n",
      "Epoch [5/10] Batch [180/469] Loss D: -0.4376649856567383, loss G: -0.18481799960136414\n",
      "Epoch [5/10] Batch [181/469] Loss D: -0.4230693578720093, loss G: -0.24966630339622498\n",
      "Epoch [5/10] Batch [182/469] Loss D: -0.43787866830825806, loss G: -0.2636896073818207\n",
      "Epoch [5/10] Batch [183/469] Loss D: -0.4251258075237274, loss G: -0.17793913185596466\n",
      "Epoch [5/10] Batch [184/469] Loss D: -0.45124515891075134, loss G: -0.2636280655860901\n",
      "Epoch [5/10] Batch [185/469] Loss D: -0.5046589374542236, loss G: -0.1220579743385315\n",
      "Epoch [5/10] Batch [186/469] Loss D: -0.44361037015914917, loss G: -0.4027101695537567\n",
      "Epoch [5/10] Batch [187/469] Loss D: -0.3609433174133301, loss G: -0.20214790105819702\n",
      "Epoch [5/10] Batch [188/469] Loss D: -0.35080939531326294, loss G: -0.24787423014640808\n",
      "Epoch [5/10] Batch [189/469] Loss D: -0.42804330587387085, loss G: -0.3036590814590454\n",
      "Epoch [5/10] Batch [190/469] Loss D: -0.4005695581436157, loss G: -0.20343005657196045\n",
      "Epoch [5/10] Batch [191/469] Loss D: -0.40980061888694763, loss G: -0.41505587100982666\n",
      "Epoch [5/10] Batch [192/469] Loss D: -0.3706463575363159, loss G: -0.2508144974708557\n",
      "Epoch [5/10] Batch [193/469] Loss D: -0.463990181684494, loss G: -0.11510002613067627\n",
      "Epoch [5/10] Batch [194/469] Loss D: -0.4027691185474396, loss G: -0.4205613434314728\n",
      "Epoch [5/10] Batch [195/469] Loss D: -0.41617894172668457, loss G: -0.13344629108905792\n",
      "Epoch [5/10] Batch [196/469] Loss D: -0.2781248390674591, loss G: -0.24790537357330322\n",
      "Epoch [5/10] Batch [197/469] Loss D: -0.47805511951446533, loss G: -0.1498389095067978\n",
      "Epoch [5/10] Batch [198/469] Loss D: -0.483502596616745, loss G: -0.31356197595596313\n",
      "Epoch [5/10] Batch [199/469] Loss D: -0.4492417871952057, loss G: -0.1488875448703766\n",
      "Epoch [5/10] Batch [200/469] Loss D: -0.389729768037796, loss G: -0.3143612742424011\n",
      "Epoch [5/10] Batch [201/469] Loss D: -0.42724111676216125, loss G: -0.13074123859405518\n",
      "Epoch [5/10] Batch [202/469] Loss D: -0.42736726999282837, loss G: -0.4169620871543884\n",
      "Epoch [5/10] Batch [203/469] Loss D: -0.3500584363937378, loss G: -0.1195874959230423\n",
      "Epoch [5/10] Batch [204/469] Loss D: -0.38001468777656555, loss G: -0.27773988246917725\n",
      "Epoch [5/10] Batch [205/469] Loss D: -0.46223747730255127, loss G: -0.22628086805343628\n",
      "Epoch [5/10] Batch [206/469] Loss D: -0.4241008162498474, loss G: -0.1856924295425415\n",
      "Epoch [5/10] Batch [207/469] Loss D: -0.398473858833313, loss G: -0.3240211009979248\n",
      "Epoch [5/10] Batch [208/469] Loss D: -0.37829211354255676, loss G: -0.2785071134567261\n",
      "Epoch [5/10] Batch [209/469] Loss D: -0.4435524642467499, loss G: -0.12860876321792603\n",
      "Epoch [5/10] Batch [210/469] Loss D: -0.3401232957839966, loss G: -0.34799695014953613\n",
      "Epoch [5/10] Batch [211/469] Loss D: -0.3904839754104614, loss G: -0.25442031025886536\n",
      "Epoch [5/10] Batch [212/469] Loss D: -0.39443445205688477, loss G: -0.28099220991134644\n",
      "Epoch [5/10] Batch [213/469] Loss D: -0.5021224617958069, loss G: -0.17703783512115479\n",
      "Epoch [5/10] Batch [214/469] Loss D: -0.40542149543762207, loss G: -0.29753997921943665\n",
      "Epoch [5/10] Batch [215/469] Loss D: -0.4459432363510132, loss G: -0.1757042109966278\n",
      "Epoch [5/10] Batch [216/469] Loss D: -0.4330078065395355, loss G: -0.23325327038764954\n",
      "Epoch [5/10] Batch [217/469] Loss D: -0.49555259943008423, loss G: -0.31159305572509766\n",
      "Epoch [5/10] Batch [218/469] Loss D: -0.4328339695930481, loss G: -0.09106139838695526\n",
      "Epoch [5/10] Batch [219/469] Loss D: -0.33295363187789917, loss G: -0.3134099841117859\n",
      "Epoch [5/10] Batch [220/469] Loss D: -0.38169237971305847, loss G: -0.3306957483291626\n",
      "Epoch [5/10] Batch [221/469] Loss D: -0.4702509343624115, loss G: -0.07843619585037231\n",
      "Epoch [5/10] Batch [222/469] Loss D: -0.33691731095314026, loss G: -0.3320958912372589\n",
      "Epoch [5/10] Batch [223/469] Loss D: -0.3916391134262085, loss G: -0.41366341710090637\n",
      "Epoch [5/10] Batch [224/469] Loss D: -0.35126346349716187, loss G: -0.11097899824380875\n",
      "Epoch [5/10] Batch [225/469] Loss D: -0.3924354016780853, loss G: -0.2732337713241577\n",
      "Epoch [5/10] Batch [226/469] Loss D: -0.4996785819530487, loss G: -0.30215561389923096\n",
      "Epoch [5/10] Batch [227/469] Loss D: -0.4644915461540222, loss G: -0.1097249761223793\n",
      "Epoch [5/10] Batch [228/469] Loss D: -0.4216831624507904, loss G: -0.22717010974884033\n",
      "Epoch [5/10] Batch [229/469] Loss D: -0.46432024240493774, loss G: -0.3534638285636902\n",
      "Epoch [5/10] Batch [230/469] Loss D: -0.43578872084617615, loss G: -0.16460749506950378\n",
      "Epoch [5/10] Batch [231/469] Loss D: -0.3700966238975525, loss G: -0.2938578724861145\n",
      "Epoch [5/10] Batch [232/469] Loss D: -0.45399120450019836, loss G: -0.1813977062702179\n",
      "Epoch [5/10] Batch [233/469] Loss D: -0.516563892364502, loss G: -0.21605147421360016\n",
      "Epoch [5/10] Batch [234/469] Loss D: -0.4263454079627991, loss G: -0.257629930973053\n",
      "Epoch [5/10] Batch [235/469] Loss D: -0.44462358951568604, loss G: -0.1071220189332962\n",
      "Epoch [5/10] Batch [236/469] Loss D: -0.3929353952407837, loss G: -0.37078166007995605\n",
      "Epoch [5/10] Batch [237/469] Loss D: -0.4109486937522888, loss G: -0.2606961727142334\n",
      "Epoch [5/10] Batch [238/469] Loss D: -0.4166805148124695, loss G: -0.14147761464118958\n",
      "Epoch [5/10] Batch [239/469] Loss D: -0.33213329315185547, loss G: -0.3758668005466461\n",
      "Epoch [5/10] Batch [240/469] Loss D: -0.4194406270980835, loss G: -0.12147192656993866\n",
      "Epoch [5/10] Batch [241/469] Loss D: -0.42140451073646545, loss G: -0.25968271493911743\n",
      "Epoch [5/10] Batch [242/469] Loss D: -0.3880288600921631, loss G: -0.3085033893585205\n",
      "Epoch [5/10] Batch [243/469] Loss D: -0.48898744583129883, loss G: -0.11238191276788712\n",
      "Epoch [5/10] Batch [244/469] Loss D: -0.47315889596939087, loss G: -0.25788408517837524\n",
      "Epoch [5/10] Batch [245/469] Loss D: -0.49351388216018677, loss G: -0.21048733592033386\n",
      "Epoch [5/10] Batch [246/469] Loss D: -0.4840937554836273, loss G: -0.1270642876625061\n",
      "Epoch [5/10] Batch [247/469] Loss D: -0.32090526819229126, loss G: -0.4652886390686035\n",
      "Epoch [5/10] Batch [248/469] Loss D: -0.32438892126083374, loss G: -0.2886320650577545\n",
      "Epoch [5/10] Batch [249/469] Loss D: -0.31176477670669556, loss G: -0.2018149197101593\n",
      "Epoch [5/10] Batch [250/469] Loss D: -0.39550650119781494, loss G: -0.28644251823425293\n",
      "Epoch [5/10] Batch [251/469] Loss D: -0.37868693470954895, loss G: -0.2704835534095764\n",
      "Epoch [5/10] Batch [252/469] Loss D: -0.4306906461715698, loss G: -0.19030718505382538\n",
      "Epoch [5/10] Batch [253/469] Loss D: -0.417580246925354, loss G: -0.21105211973190308\n",
      "Epoch [5/10] Batch [254/469] Loss D: -0.5206836462020874, loss G: -0.09951573610305786\n",
      "Epoch [5/10] Batch [255/469] Loss D: -0.3959394693374634, loss G: -0.4925137162208557\n",
      "Epoch [5/10] Batch [256/469] Loss D: -0.29772311449050903, loss G: -0.17194700241088867\n",
      "Epoch [5/10] Batch [257/469] Loss D: -0.50389564037323, loss G: -0.19211648404598236\n",
      "Epoch [5/10] Batch [258/469] Loss D: -0.47465837001800537, loss G: -0.2109178602695465\n",
      "Epoch [5/10] Batch [259/469] Loss D: -0.4136388897895813, loss G: -0.21410438418388367\n",
      "Epoch [5/10] Batch [260/469] Loss D: -0.43470191955566406, loss G: -0.26579469442367554\n",
      "Epoch [5/10] Batch [261/469] Loss D: -0.3439403772354126, loss G: -0.1472547948360443\n",
      "Epoch [5/10] Batch [262/469] Loss D: -0.4446350336074829, loss G: -0.34002235531806946\n",
      "Epoch [5/10] Batch [263/469] Loss D: -0.4858098030090332, loss G: -0.10190768539905548\n",
      "Epoch [5/10] Batch [264/469] Loss D: -0.377162903547287, loss G: -0.3366186320781708\n",
      "Epoch [5/10] Batch [265/469] Loss D: -0.45381006598472595, loss G: -0.1894681453704834\n",
      "Epoch [5/10] Batch [266/469] Loss D: -0.46537327766418457, loss G: -0.2341659665107727\n",
      "Epoch [5/10] Batch [267/469] Loss D: -0.4093068838119507, loss G: -0.20238018035888672\n",
      "Epoch [5/10] Batch [268/469] Loss D: -0.4739229679107666, loss G: -0.32543423771858215\n",
      "Epoch [5/10] Batch [269/469] Loss D: -0.40093541145324707, loss G: -0.17756502330303192\n",
      "Epoch [5/10] Batch [270/469] Loss D: -0.4388071894645691, loss G: -0.22020383179187775\n",
      "Epoch [5/10] Batch [271/469] Loss D: -0.374678373336792, loss G: -0.2265482097864151\n",
      "Epoch [5/10] Batch [272/469] Loss D: -0.4249976575374603, loss G: -0.2667050361633301\n",
      "Epoch [5/10] Batch [273/469] Loss D: -0.301222562789917, loss G: -0.2487330436706543\n",
      "Epoch [5/10] Batch [274/469] Loss D: -0.4213455319404602, loss G: -0.2980442941188812\n",
      "Epoch [5/10] Batch [275/469] Loss D: -0.4357404112815857, loss G: -0.20996971428394318\n",
      "Epoch [5/10] Batch [276/469] Loss D: -0.45396265387535095, loss G: -0.22573892772197723\n",
      "Epoch [5/10] Batch [277/469] Loss D: -0.49524468183517456, loss G: -0.23836320638656616\n",
      "Epoch [5/10] Batch [278/469] Loss D: -0.4440837502479553, loss G: -0.13319973647594452\n",
      "Epoch [5/10] Batch [279/469] Loss D: -0.3983798623085022, loss G: -0.29447048902511597\n",
      "Epoch [5/10] Batch [280/469] Loss D: -0.4406268000602722, loss G: -0.26426196098327637\n",
      "Epoch [5/10] Batch [281/469] Loss D: -0.4158483147621155, loss G: -0.15747323632240295\n",
      "Epoch [5/10] Batch [282/469] Loss D: -0.45065736770629883, loss G: -0.3120279908180237\n",
      "Epoch [5/10] Batch [283/469] Loss D: -0.37512218952178955, loss G: -0.16509512066841125\n",
      "Epoch [5/10] Batch [284/469] Loss D: -0.3247429132461548, loss G: -0.19057635962963104\n",
      "Epoch [5/10] Batch [285/469] Loss D: -0.4083954691886902, loss G: -0.34418654441833496\n",
      "Epoch [5/10] Batch [286/469] Loss D: -0.450547456741333, loss G: -0.11031714826822281\n",
      "Epoch [5/10] Batch [287/469] Loss D: -0.39527618885040283, loss G: -0.24231070280075073\n",
      "Epoch [5/10] Batch [288/469] Loss D: -0.4065389037132263, loss G: -0.25820600986480713\n",
      "Epoch [5/10] Batch [289/469] Loss D: -0.5086387991905212, loss G: -0.19587862491607666\n",
      "Epoch [5/10] Batch [290/469] Loss D: -0.4580773115158081, loss G: -0.17768512666225433\n",
      "Epoch [5/10] Batch [291/469] Loss D: -0.5396162271499634, loss G: -0.22111210227012634\n",
      "Epoch [5/10] Batch [292/469] Loss D: -0.43121132254600525, loss G: -0.19682995975017548\n",
      "Epoch [5/10] Batch [293/469] Loss D: -0.4591517150402069, loss G: -0.2141542136669159\n",
      "Epoch [5/10] Batch [294/469] Loss D: -0.5668784379959106, loss G: -0.14013363420963287\n",
      "Epoch [5/10] Batch [295/469] Loss D: -0.48904311656951904, loss G: -0.30494189262390137\n",
      "Epoch [5/10] Batch [296/469] Loss D: -0.42639482021331787, loss G: -0.21917441487312317\n",
      "Epoch [5/10] Batch [297/469] Loss D: -0.47267743945121765, loss G: -0.1819101870059967\n",
      "Epoch [5/10] Batch [298/469] Loss D: -0.5155167579650879, loss G: -0.2727949023246765\n",
      "Epoch [5/10] Batch [299/469] Loss D: -0.37365925312042236, loss G: -0.16984336078166962\n",
      "Epoch [5/10] Batch [300/469] Loss D: -0.39701512455940247, loss G: -0.24452678859233856\n",
      "Epoch [5/10] Batch [301/469] Loss D: -0.3886016309261322, loss G: -0.3815741240978241\n",
      "Epoch [5/10] Batch [302/469] Loss D: -0.3417632579803467, loss G: -0.23097485303878784\n",
      "Epoch [5/10] Batch [303/469] Loss D: -0.50548255443573, loss G: -0.1370861679315567\n",
      "Epoch [5/10] Batch [304/469] Loss D: -0.3360673189163208, loss G: -0.5838032960891724\n",
      "Epoch [5/10] Batch [305/469] Loss D: -0.2856489419937134, loss G: -0.16506479680538177\n",
      "Epoch [5/10] Batch [306/469] Loss D: -0.4445970952510834, loss G: -0.19936686754226685\n",
      "Epoch [5/10] Batch [307/469] Loss D: -0.4994652271270752, loss G: -0.21596336364746094\n",
      "Epoch [5/10] Batch [308/469] Loss D: -0.477097749710083, loss G: -0.22634488344192505\n",
      "Epoch [5/10] Batch [309/469] Loss D: -0.45964381098747253, loss G: -0.2568102180957794\n",
      "Epoch [5/10] Batch [310/469] Loss D: -0.4270727038383484, loss G: -0.30620691180229187\n",
      "Epoch [5/10] Batch [311/469] Loss D: -0.42052698135375977, loss G: -0.11257801949977875\n",
      "Epoch [5/10] Batch [312/469] Loss D: -0.5305863618850708, loss G: -0.2531282305717468\n",
      "Epoch [5/10] Batch [313/469] Loss D: -0.4688752293586731, loss G: -0.1973353922367096\n",
      "Epoch [5/10] Batch [314/469] Loss D: -0.556272029876709, loss G: -0.1771399825811386\n",
      "Epoch [5/10] Batch [315/469] Loss D: -0.35000094771385193, loss G: -0.2864810526371002\n",
      "Epoch [5/10] Batch [316/469] Loss D: -0.46320441365242004, loss G: -0.17005200684070587\n",
      "Epoch [5/10] Batch [317/469] Loss D: -0.4423937499523163, loss G: -0.3792169988155365\n",
      "Epoch [5/10] Batch [318/469] Loss D: -0.4534285068511963, loss G: -0.06595228612422943\n",
      "Epoch [5/10] Batch [319/469] Loss D: -0.3952315151691437, loss G: -0.34635129570961\n",
      "Epoch [5/10] Batch [320/469] Loss D: -0.4110872447490692, loss G: -0.1575220823287964\n",
      "Epoch [5/10] Batch [321/469] Loss D: -0.3823224604129791, loss G: -0.3628668189048767\n",
      "Epoch [5/10] Batch [322/469] Loss D: -0.33388400077819824, loss G: -0.18876531720161438\n",
      "Epoch [5/10] Batch [323/469] Loss D: -0.4400743246078491, loss G: -0.32841256260871887\n",
      "Epoch [5/10] Batch [324/469] Loss D: -0.4527069926261902, loss G: -0.09316688030958176\n",
      "Epoch [5/10] Batch [325/469] Loss D: -0.44548946619033813, loss G: -0.3792152404785156\n",
      "Epoch [5/10] Batch [326/469] Loss D: -0.3904232978820801, loss G: -0.24390192329883575\n",
      "Epoch [5/10] Batch [327/469] Loss D: -0.43934306502342224, loss G: -0.12942622601985931\n",
      "Epoch [5/10] Batch [328/469] Loss D: -0.48371922969818115, loss G: -0.3955312669277191\n",
      "Epoch [5/10] Batch [329/469] Loss D: -0.42952948808670044, loss G: -0.1029110699892044\n",
      "Epoch [5/10] Batch [330/469] Loss D: -0.3941769003868103, loss G: -0.27951711416244507\n",
      "Epoch [5/10] Batch [331/469] Loss D: -0.4470682442188263, loss G: -0.2580759823322296\n",
      "Epoch [5/10] Batch [332/469] Loss D: -0.4229283034801483, loss G: -0.2692491412162781\n",
      "Epoch [5/10] Batch [333/469] Loss D: -0.525490403175354, loss G: -0.18269646167755127\n",
      "Epoch [5/10] Batch [334/469] Loss D: -0.4266752004623413, loss G: -0.19060412049293518\n",
      "Epoch [5/10] Batch [335/469] Loss D: -0.4523516893386841, loss G: -0.2487604171037674\n",
      "Epoch [5/10] Batch [336/469] Loss D: -0.47044309973716736, loss G: -0.14241132140159607\n",
      "Epoch [5/10] Batch [337/469] Loss D: -0.40199267864227295, loss G: -0.33416759967803955\n",
      "Epoch [5/10] Batch [338/469] Loss D: -0.44333958625793457, loss G: -0.20415979623794556\n",
      "Epoch [5/10] Batch [339/469] Loss D: -0.5325391292572021, loss G: -0.22284945845603943\n",
      "Epoch [5/10] Batch [340/469] Loss D: -0.5312880873680115, loss G: -0.11003150045871735\n",
      "Epoch [5/10] Batch [341/469] Loss D: -0.4647026062011719, loss G: -0.26921066641807556\n",
      "Epoch [5/10] Batch [342/469] Loss D: -0.38283276557922363, loss G: -0.3086213767528534\n",
      "Epoch [5/10] Batch [343/469] Loss D: -0.41190576553344727, loss G: -0.16142132878303528\n",
      "Epoch [5/10] Batch [344/469] Loss D: -0.38010501861572266, loss G: -0.3673875331878662\n",
      "Epoch [5/10] Batch [345/469] Loss D: -0.2913963496685028, loss G: -0.3172570765018463\n",
      "Epoch [5/10] Batch [346/469] Loss D: -0.39129534363746643, loss G: -0.21779151260852814\n",
      "Epoch [5/10] Batch [347/469] Loss D: -0.517348051071167, loss G: -0.17466804385185242\n",
      "Epoch [5/10] Batch [348/469] Loss D: -0.4154646694660187, loss G: -0.39024361968040466\n",
      "Epoch [5/10] Batch [349/469] Loss D: -0.41578570008277893, loss G: -0.15992653369903564\n",
      "Epoch [5/10] Batch [350/469] Loss D: -0.44298499822616577, loss G: -0.26997700333595276\n",
      "Epoch [5/10] Batch [351/469] Loss D: -0.4625859260559082, loss G: -0.18289262056350708\n",
      "Epoch [5/10] Batch [352/469] Loss D: -0.3768603205680847, loss G: -0.3005989193916321\n",
      "Epoch [5/10] Batch [353/469] Loss D: -0.4661228656768799, loss G: -0.11127078533172607\n",
      "Epoch [5/10] Batch [354/469] Loss D: -0.4167078137397766, loss G: -0.4583278298377991\n",
      "Epoch [5/10] Batch [355/469] Loss D: -0.3785610795021057, loss G: -0.12366315722465515\n",
      "Epoch [5/10] Batch [356/469] Loss D: -0.40246936678886414, loss G: -0.2643519937992096\n",
      "Epoch [5/10] Batch [357/469] Loss D: -0.4604359269142151, loss G: -0.29991716146469116\n",
      "Epoch [5/10] Batch [358/469] Loss D: -0.37078332901000977, loss G: -0.18847116827964783\n",
      "Epoch [5/10] Batch [359/469] Loss D: -0.5113697052001953, loss G: -0.19158720970153809\n",
      "Epoch [5/10] Batch [360/469] Loss D: -0.5052992105484009, loss G: -0.3355652093887329\n",
      "Epoch [5/10] Batch [361/469] Loss D: -0.41744428873062134, loss G: -0.16158980131149292\n",
      "Epoch [5/10] Batch [362/469] Loss D: -0.40069639682769775, loss G: -0.25885215401649475\n",
      "Epoch [5/10] Batch [363/469] Loss D: -0.42465341091156006, loss G: -0.31475022435188293\n",
      "Epoch [5/10] Batch [364/469] Loss D: -0.4459386467933655, loss G: -0.07722404599189758\n",
      "Epoch [5/10] Batch [365/469] Loss D: -0.34902888536453247, loss G: -0.4020640254020691\n",
      "Epoch [5/10] Batch [366/469] Loss D: -0.37435728311538696, loss G: -0.21748648583889008\n",
      "Epoch [5/10] Batch [367/469] Loss D: -0.44019871950149536, loss G: -0.2816483974456787\n",
      "Epoch [5/10] Batch [368/469] Loss D: -0.4773549437522888, loss G: -0.20308558642864227\n",
      "Epoch [5/10] Batch [369/469] Loss D: -0.52857506275177, loss G: -0.16388262808322906\n",
      "Epoch [5/10] Batch [370/469] Loss D: -0.4220085144042969, loss G: -0.25769543647766113\n",
      "Epoch [5/10] Batch [371/469] Loss D: -0.412852942943573, loss G: -0.43630021810531616\n",
      "Epoch [5/10] Batch [372/469] Loss D: -0.3149663209915161, loss G: -0.24120569229125977\n",
      "Epoch [5/10] Batch [373/469] Loss D: -0.45899122953414917, loss G: -0.12392135709524155\n",
      "Epoch [5/10] Batch [374/469] Loss D: -0.4585186541080475, loss G: -0.482265830039978\n",
      "Epoch [5/10] Batch [375/469] Loss D: -0.35294270515441895, loss G: -0.17047572135925293\n",
      "Epoch [5/10] Batch [376/469] Loss D: -0.368122398853302, loss G: -0.2259913980960846\n",
      "Epoch [5/10] Batch [377/469] Loss D: -0.43759918212890625, loss G: -0.25698187947273254\n",
      "Epoch [5/10] Batch [378/469] Loss D: -0.33397895097732544, loss G: -0.29813146591186523\n",
      "Epoch [5/10] Batch [379/469] Loss D: -0.3880084753036499, loss G: -0.12520070374011993\n",
      "Epoch [5/10] Batch [380/469] Loss D: -0.4451912045478821, loss G: -0.3528595566749573\n",
      "Epoch [5/10] Batch [381/469] Loss D: -0.3616263270378113, loss G: -0.18283022940158844\n",
      "Epoch [5/10] Batch [382/469] Loss D: -0.5035789012908936, loss G: -0.12437357753515244\n",
      "Epoch [5/10] Batch [383/469] Loss D: -0.5464608669281006, loss G: -0.34081006050109863\n",
      "Epoch [5/10] Batch [384/469] Loss D: -0.407985121011734, loss G: -0.12139385938644409\n",
      "Epoch [5/10] Batch [385/469] Loss D: -0.3470739722251892, loss G: -0.4200829863548279\n",
      "Epoch [5/10] Batch [386/469] Loss D: -0.361328125, loss G: -0.19783878326416016\n",
      "Epoch [5/10] Batch [387/469] Loss D: -0.3665592074394226, loss G: -0.2724911570549011\n",
      "Epoch [5/10] Batch [388/469] Loss D: -0.44661635160446167, loss G: -0.21079488098621368\n",
      "Epoch [5/10] Batch [389/469] Loss D: -0.5347946286201477, loss G: -0.18400686979293823\n",
      "Epoch [5/10] Batch [390/469] Loss D: -0.47860121726989746, loss G: -0.18452471494674683\n",
      "Epoch [5/10] Batch [391/469] Loss D: -0.46700623631477356, loss G: -0.3798377513885498\n",
      "Epoch [5/10] Batch [392/469] Loss D: -0.33904707431793213, loss G: -0.15857410430908203\n",
      "Epoch [5/10] Batch [393/469] Loss D: -0.4276159703731537, loss G: -0.2314860224723816\n",
      "Epoch [5/10] Batch [394/469] Loss D: -0.35863620042800903, loss G: -0.397960901260376\n",
      "Epoch [5/10] Batch [395/469] Loss D: -0.35736459493637085, loss G: -0.1186712235212326\n",
      "Epoch [5/10] Batch [396/469] Loss D: -0.4154481589794159, loss G: -0.28568756580352783\n",
      "Epoch [5/10] Batch [397/469] Loss D: -0.4090665578842163, loss G: -0.32565629482269287\n",
      "Epoch [5/10] Batch [398/469] Loss D: -0.41670846939086914, loss G: -0.12661860883235931\n",
      "Epoch [5/10] Batch [399/469] Loss D: -0.48035672307014465, loss G: -0.42035630345344543\n",
      "Epoch [5/10] Batch [400/469] Loss D: -0.34066343307495117, loss G: -0.2196529060602188\n",
      "Epoch [5/10] Batch [401/469] Loss D: -0.4030977785587311, loss G: -0.16706059873104095\n",
      "Epoch [5/10] Batch [402/469] Loss D: -0.478240430355072, loss G: -0.2558135688304901\n",
      "Epoch [5/10] Batch [403/469] Loss D: -0.3760989308357239, loss G: -0.23011000454425812\n",
      "Epoch [5/10] Batch [404/469] Loss D: -0.5256280899047852, loss G: -0.2876213788986206\n",
      "Epoch [5/10] Batch [405/469] Loss D: -0.4756898283958435, loss G: -0.12110990285873413\n",
      "Epoch [5/10] Batch [406/469] Loss D: -0.5645814538002014, loss G: -0.2148228883743286\n",
      "Epoch [5/10] Batch [407/469] Loss D: -0.484001100063324, loss G: -0.20178773999214172\n",
      "Epoch [5/10] Batch [408/469] Loss D: -0.5152969360351562, loss G: -0.1143767237663269\n",
      "Epoch [5/10] Batch [409/469] Loss D: -0.4962597191333771, loss G: -0.3139568567276001\n",
      "Epoch [5/10] Batch [410/469] Loss D: -0.40755346417427063, loss G: -0.16947318613529205\n",
      "Epoch [5/10] Batch [411/469] Loss D: -0.39768022298812866, loss G: -0.25631698966026306\n",
      "Epoch [5/10] Batch [412/469] Loss D: -0.42257118225097656, loss G: -0.45324862003326416\n",
      "Epoch [5/10] Batch [413/469] Loss D: -0.34380048513412476, loss G: -0.1292320340871811\n",
      "Epoch [5/10] Batch [414/469] Loss D: -0.3243795931339264, loss G: -0.33819276094436646\n",
      "Epoch [5/10] Batch [415/469] Loss D: -0.45521819591522217, loss G: -0.1558569073677063\n",
      "Epoch [5/10] Batch [416/469] Loss D: -0.3883379399776459, loss G: -0.4023272395133972\n",
      "Epoch [5/10] Batch [417/469] Loss D: -0.42703962326049805, loss G: -0.16573254764080048\n",
      "Epoch [5/10] Batch [418/469] Loss D: -0.4746565818786621, loss G: -0.19156156480312347\n",
      "Epoch [5/10] Batch [419/469] Loss D: -0.41846537590026855, loss G: -0.4235684275627136\n",
      "Epoch [5/10] Batch [420/469] Loss D: -0.4018893539905548, loss G: -0.17584972083568573\n",
      "Epoch [5/10] Batch [421/469] Loss D: -0.46783414483070374, loss G: -0.16416215896606445\n",
      "Epoch [5/10] Batch [422/469] Loss D: -0.4361940324306488, loss G: -0.37134528160095215\n",
      "Epoch [5/10] Batch [423/469] Loss D: -0.35384654998779297, loss G: -0.22895795106887817\n",
      "Epoch [5/10] Batch [424/469] Loss D: -0.4345740079879761, loss G: -0.2556985020637512\n",
      "Epoch [5/10] Batch [425/469] Loss D: -0.4860379695892334, loss G: -0.12824557721614838\n",
      "Epoch [5/10] Batch [426/469] Loss D: -0.47185832262039185, loss G: -0.38478273153305054\n",
      "Epoch [5/10] Batch [427/469] Loss D: -0.4102364778518677, loss G: -0.18724770843982697\n",
      "Epoch [5/10] Batch [428/469] Loss D: -0.43746528029441833, loss G: -0.16167351603507996\n",
      "Epoch [5/10] Batch [429/469] Loss D: -0.35825783014297485, loss G: -0.4033556580543518\n",
      "Epoch [5/10] Batch [430/469] Loss D: -0.45011407136917114, loss G: -0.08097707480192184\n",
      "Epoch [5/10] Batch [431/469] Loss D: -0.3485414385795593, loss G: -0.2675037980079651\n",
      "Epoch [5/10] Batch [432/469] Loss D: -0.3127214312553406, loss G: -0.45999875664711\n",
      "Epoch [5/10] Batch [433/469] Loss D: -0.4382104277610779, loss G: -0.07366959750652313\n",
      "Epoch [5/10] Batch [434/469] Loss D: -0.32671844959259033, loss G: -0.2766120433807373\n",
      "Epoch [5/10] Batch [435/469] Loss D: -0.466794490814209, loss G: -0.26390373706817627\n",
      "Epoch [5/10] Batch [436/469] Loss D: -0.47899410128593445, loss G: -0.0675378367304802\n",
      "Epoch [5/10] Batch [437/469] Loss D: -0.311795175075531, loss G: -0.3042563796043396\n",
      "Epoch [5/10] Batch [438/469] Loss D: -0.46233704686164856, loss G: -0.16905222833156586\n",
      "Epoch [5/10] Batch [439/469] Loss D: -0.48792320489883423, loss G: -0.2443270981311798\n",
      "Epoch [5/10] Batch [440/469] Loss D: -0.439686119556427, loss G: -0.2044677436351776\n",
      "Epoch [5/10] Batch [441/469] Loss D: -0.40391188859939575, loss G: -0.18612894415855408\n",
      "Epoch [5/10] Batch [442/469] Loss D: -0.48075366020202637, loss G: -0.2104705274105072\n",
      "Epoch [5/10] Batch [443/469] Loss D: -0.37375184893608093, loss G: -0.3341871500015259\n",
      "Epoch [5/10] Batch [444/469] Loss D: -0.4876320958137512, loss G: -0.10954301059246063\n",
      "Epoch [5/10] Batch [445/469] Loss D: -0.4887199401855469, loss G: -0.2914597988128662\n",
      "Epoch [5/10] Batch [446/469] Loss D: -0.4637451171875, loss G: -0.19100715219974518\n",
      "Epoch [5/10] Batch [447/469] Loss D: -0.5204309225082397, loss G: -0.1272612065076828\n",
      "Epoch [5/10] Batch [448/469] Loss D: -0.45781874656677246, loss G: -0.2847983241081238\n",
      "Epoch [5/10] Batch [449/469] Loss D: -0.5082727670669556, loss G: -0.16757556796073914\n",
      "Epoch [5/10] Batch [450/469] Loss D: -0.46243181824684143, loss G: -0.31302547454833984\n",
      "Epoch [5/10] Batch [451/469] Loss D: -0.4434204399585724, loss G: -0.11053973436355591\n",
      "Epoch [5/10] Batch [452/469] Loss D: -0.45385798811912537, loss G: -0.3377426564693451\n",
      "Epoch [5/10] Batch [453/469] Loss D: -0.34115952253341675, loss G: -0.22448289394378662\n",
      "Epoch [5/10] Batch [454/469] Loss D: -0.4166550636291504, loss G: -0.2736814618110657\n",
      "Epoch [5/10] Batch [455/469] Loss D: -0.4354957640171051, loss G: -0.15506553649902344\n",
      "Epoch [5/10] Batch [456/469] Loss D: -0.40568089485168457, loss G: -0.23006132245063782\n",
      "Epoch [5/10] Batch [457/469] Loss D: -0.36706745624542236, loss G: -0.2942916750907898\n",
      "Epoch [5/10] Batch [458/469] Loss D: -0.3989260792732239, loss G: -0.20915403962135315\n",
      "Epoch [5/10] Batch [459/469] Loss D: -0.3781541585922241, loss G: -0.16063547134399414\n",
      "Epoch [5/10] Batch [460/469] Loss D: -0.43477851152420044, loss G: -0.21959830820560455\n",
      "Epoch [5/10] Batch [461/469] Loss D: -0.434948593378067, loss G: -0.30741801857948303\n",
      "Epoch [5/10] Batch [462/469] Loss D: -0.4523221254348755, loss G: -0.12176625430583954\n",
      "Epoch [5/10] Batch [463/469] Loss D: -0.42644792795181274, loss G: -0.2896840572357178\n",
      "Epoch [5/10] Batch [464/469] Loss D: -0.47452661395072937, loss G: -0.17925816774368286\n",
      "Epoch [5/10] Batch [465/469] Loss D: -0.5044822692871094, loss G: -0.1374669075012207\n",
      "Epoch [5/10] Batch [466/469] Loss D: -0.44081664085388184, loss G: -0.4220706820487976\n",
      "Epoch [5/10] Batch [467/469] Loss D: -0.3540306091308594, loss G: -0.20468975603580475\n",
      "Epoch [5/10] Batch [468/469] Loss D: -0.4788796305656433, loss G: -0.24804924428462982\n",
      "Epoch [5/10] Batch [469/469] Loss D: -0.4227864146232605, loss G: -0.28121015429496765\n",
      "Epoch [6/10] Batch [1/469] Loss D: -0.4154762327671051, loss G: -0.1659734696149826\n",
      "Epoch [6/10] Batch [2/469] Loss D: -0.4154624938964844, loss G: -0.2641616761684418\n",
      "Epoch [6/10] Batch [3/469] Loss D: -0.4318718910217285, loss G: -0.2022520750761032\n",
      "Epoch [6/10] Batch [4/469] Loss D: -0.46640297770500183, loss G: -0.2949708104133606\n",
      "Epoch [6/10] Batch [5/469] Loss D: -0.4606166481971741, loss G: -0.17075258493423462\n",
      "Epoch [6/10] Batch [6/469] Loss D: -0.4360644221305847, loss G: -0.2768045961856842\n",
      "Epoch [6/10] Batch [7/469] Loss D: -0.4550096094608307, loss G: -0.1808471828699112\n",
      "Epoch [6/10] Batch [8/469] Loss D: -0.41195249557495117, loss G: -0.27294987440109253\n",
      "Epoch [6/10] Batch [9/469] Loss D: -0.46615171432495117, loss G: -0.12418632209300995\n",
      "Epoch [6/10] Batch [10/469] Loss D: -0.4133012592792511, loss G: -0.4427599310874939\n",
      "Epoch [6/10] Batch [11/469] Loss D: -0.3675527572631836, loss G: -0.14474733173847198\n",
      "Epoch [6/10] Batch [12/469] Loss D: -0.44711989164352417, loss G: -0.20945294201374054\n",
      "Epoch [6/10] Batch [13/469] Loss D: -0.46879279613494873, loss G: -0.27876731753349304\n",
      "Epoch [6/10] Batch [14/469] Loss D: -0.5175173878669739, loss G: -0.18946681916713715\n",
      "Epoch [6/10] Batch [15/469] Loss D: -0.30151188373565674, loss G: -0.295229434967041\n",
      "Epoch [6/10] Batch [16/469] Loss D: -0.4683316946029663, loss G: -0.22087234258651733\n",
      "Epoch [6/10] Batch [17/469] Loss D: -0.46922892332077026, loss G: -0.24370072782039642\n",
      "Epoch [6/10] Batch [18/469] Loss D: -0.4214838743209839, loss G: -0.16937652230262756\n",
      "Epoch [6/10] Batch [19/469] Loss D: -0.4622895419597626, loss G: -0.23587046563625336\n",
      "Epoch [6/10] Batch [20/469] Loss D: -0.4997554421424866, loss G: -0.3229585587978363\n",
      "Epoch [6/10] Batch [21/469] Loss D: -0.510806679725647, loss G: -0.06231493502855301\n",
      "Epoch [6/10] Batch [22/469] Loss D: -0.3568432331085205, loss G: -0.3704414367675781\n",
      "Epoch [6/10] Batch [23/469] Loss D: -0.350477933883667, loss G: -0.2890337109565735\n",
      "Epoch [6/10] Batch [24/469] Loss D: -0.5075387358665466, loss G: -0.07601909339427948\n",
      "Epoch [6/10] Batch [25/469] Loss D: -0.3897401690483093, loss G: -0.4008063077926636\n",
      "Epoch [6/10] Batch [26/469] Loss D: -0.4553474187850952, loss G: -0.18148449063301086\n",
      "Epoch [6/10] Batch [27/469] Loss D: -0.4159546196460724, loss G: -0.2114911675453186\n",
      "Epoch [6/10] Batch [28/469] Loss D: -0.5050855875015259, loss G: -0.2659205198287964\n",
      "Epoch [6/10] Batch [29/469] Loss D: -0.5015088319778442, loss G: -0.08635307848453522\n",
      "Epoch [6/10] Batch [30/469] Loss D: -0.4215024411678314, loss G: -0.4078700840473175\n",
      "Epoch [6/10] Batch [31/469] Loss D: -0.4336923658847809, loss G: -0.11930875480175018\n",
      "Epoch [6/10] Batch [32/469] Loss D: -0.5266436338424683, loss G: -0.22363486886024475\n",
      "Epoch [6/10] Batch [33/469] Loss D: -0.558311939239502, loss G: -0.0980549305677414\n",
      "Epoch [6/10] Batch [34/469] Loss D: -0.4661112427711487, loss G: -0.3094826340675354\n",
      "Epoch [6/10] Batch [35/469] Loss D: -0.4624674916267395, loss G: -0.22850728034973145\n",
      "Epoch [6/10] Batch [36/469] Loss D: -0.392816960811615, loss G: -0.17028696835041046\n",
      "Epoch [6/10] Batch [37/469] Loss D: -0.3960336744785309, loss G: -0.24786847829818726\n",
      "Epoch [6/10] Batch [38/469] Loss D: -0.42119506001472473, loss G: -0.2795505225658417\n",
      "Epoch [6/10] Batch [39/469] Loss D: -0.417996883392334, loss G: -0.14376533031463623\n",
      "Epoch [6/10] Batch [40/469] Loss D: -0.5342315435409546, loss G: -0.2452910989522934\n",
      "Epoch [6/10] Batch [41/469] Loss D: -0.4917108714580536, loss G: -0.22434096038341522\n",
      "Epoch [6/10] Batch [42/469] Loss D: -0.5145972967147827, loss G: -0.18844538927078247\n",
      "Epoch [6/10] Batch [43/469] Loss D: -0.4974854588508606, loss G: -0.21498948335647583\n",
      "Epoch [6/10] Batch [44/469] Loss D: -0.5224422216415405, loss G: -0.14143875241279602\n",
      "Epoch [6/10] Batch [45/469] Loss D: -0.4581255316734314, loss G: -0.24660231173038483\n",
      "Epoch [6/10] Batch [46/469] Loss D: -0.45526182651519775, loss G: -0.18417683243751526\n",
      "Epoch [6/10] Batch [47/469] Loss D: -0.4850125014781952, loss G: -0.15961961448192596\n",
      "Epoch [6/10] Batch [48/469] Loss D: -0.42198288440704346, loss G: -0.44164934754371643\n",
      "Epoch [6/10] Batch [49/469] Loss D: -0.31539386510849, loss G: -0.22366492450237274\n",
      "Epoch [6/10] Batch [50/469] Loss D: -0.5251112580299377, loss G: -0.17355817556381226\n",
      "Epoch [6/10] Batch [51/469] Loss D: -0.4925609529018402, loss G: -0.2847795784473419\n",
      "Epoch [6/10] Batch [52/469] Loss D: -0.45566684007644653, loss G: -0.11007489264011383\n",
      "Epoch [6/10] Batch [53/469] Loss D: -0.5169611573219299, loss G: -0.321921169757843\n",
      "Epoch [6/10] Batch [54/469] Loss D: -0.44134843349456787, loss G: -0.14467638731002808\n",
      "Epoch [6/10] Batch [55/469] Loss D: -0.4840223789215088, loss G: -0.2593962252140045\n",
      "Epoch [6/10] Batch [56/469] Loss D: -0.4554888606071472, loss G: -0.14244665205478668\n",
      "Epoch [6/10] Batch [57/469] Loss D: -0.5183272957801819, loss G: -0.1274707317352295\n",
      "Epoch [6/10] Batch [58/469] Loss D: -0.44414055347442627, loss G: -0.35129809379577637\n",
      "Epoch [6/10] Batch [59/469] Loss D: -0.42771071195602417, loss G: -0.26747405529022217\n",
      "Epoch [6/10] Batch [60/469] Loss D: -0.38650816679000854, loss G: -0.16493907570838928\n",
      "Epoch [6/10] Batch [61/469] Loss D: -0.47727420926094055, loss G: -0.32827943563461304\n",
      "Epoch [6/10] Batch [62/469] Loss D: -0.4217261075973511, loss G: -0.19158940017223358\n",
      "Epoch [6/10] Batch [63/469] Loss D: -0.37378478050231934, loss G: -0.3027971684932709\n",
      "Epoch [6/10] Batch [64/469] Loss D: -0.4528992176055908, loss G: -0.14331378042697906\n",
      "Epoch [6/10] Batch [65/469] Loss D: -0.47479140758514404, loss G: -0.2697610557079315\n",
      "Epoch [6/10] Batch [66/469] Loss D: -0.4913069009780884, loss G: -0.134323388338089\n",
      "Epoch [6/10] Batch [67/469] Loss D: -0.5103816390037537, loss G: -0.307794451713562\n",
      "Epoch [6/10] Batch [68/469] Loss D: -0.5128878951072693, loss G: -0.09695036709308624\n",
      "Epoch [6/10] Batch [69/469] Loss D: -0.5001807808876038, loss G: -0.35179680585861206\n",
      "Epoch [6/10] Batch [70/469] Loss D: -0.37345847487449646, loss G: -0.23602581024169922\n",
      "Epoch [6/10] Batch [71/469] Loss D: -0.4873976707458496, loss G: -0.1409943401813507\n",
      "Epoch [6/10] Batch [72/469] Loss D: -0.5692492723464966, loss G: -0.17643143236637115\n",
      "Epoch [6/10] Batch [73/469] Loss D: -0.4599704444408417, loss G: -0.20367595553398132\n",
      "Epoch [6/10] Batch [74/469] Loss D: -0.4234848618507385, loss G: -0.357502281665802\n",
      "Epoch [6/10] Batch [75/469] Loss D: -0.36526668071746826, loss G: -0.14850705862045288\n",
      "Epoch [6/10] Batch [76/469] Loss D: -0.44865378737449646, loss G: -0.3651779294013977\n",
      "Epoch [6/10] Batch [77/469] Loss D: -0.4889565706253052, loss G: -0.11416834592819214\n",
      "Epoch [6/10] Batch [78/469] Loss D: -0.40408584475517273, loss G: -0.29652804136276245\n",
      "Epoch [6/10] Batch [79/469] Loss D: -0.44688326120376587, loss G: -0.17320728302001953\n",
      "Epoch [6/10] Batch [80/469] Loss D: -0.4075081944465637, loss G: -0.26648232340812683\n",
      "Epoch [6/10] Batch [81/469] Loss D: -0.492935448884964, loss G: -0.12194212526082993\n",
      "Epoch [6/10] Batch [82/469] Loss D: -0.4647252559661865, loss G: -0.40342962741851807\n",
      "Epoch [6/10] Batch [83/469] Loss D: -0.41177332401275635, loss G: -0.11350733041763306\n",
      "Epoch [6/10] Batch [84/469] Loss D: -0.4057541787624359, loss G: -0.3247823715209961\n",
      "Epoch [6/10] Batch [85/469] Loss D: -0.4753163158893585, loss G: -0.1325257420539856\n",
      "Epoch [6/10] Batch [86/469] Loss D: -0.43821653723716736, loss G: -0.3056500554084778\n",
      "Epoch [6/10] Batch [87/469] Loss D: -0.42030957341194153, loss G: -0.1323176473379135\n",
      "Epoch [6/10] Batch [88/469] Loss D: -0.4907958507537842, loss G: -0.3158714175224304\n",
      "Epoch [6/10] Batch [89/469] Loss D: -0.44290757179260254, loss G: -0.17729723453521729\n",
      "Epoch [6/10] Batch [90/469] Loss D: -0.4316951036453247, loss G: -0.2914271950721741\n",
      "Epoch [6/10] Batch [91/469] Loss D: -0.5212445855140686, loss G: -0.11900359392166138\n",
      "Epoch [6/10] Batch [92/469] Loss D: -0.48412570357322693, loss G: -0.3878946006298065\n",
      "Epoch [6/10] Batch [93/469] Loss D: -0.36942338943481445, loss G: -0.21136358380317688\n",
      "Epoch [6/10] Batch [94/469] Loss D: -0.49015915393829346, loss G: -0.10953398048877716\n",
      "Epoch [6/10] Batch [95/469] Loss D: -0.3423934578895569, loss G: -0.4271972179412842\n",
      "Epoch [6/10] Batch [96/469] Loss D: -0.3809475004673004, loss G: -0.19758886098861694\n",
      "Epoch [6/10] Batch [97/469] Loss D: -0.5133142471313477, loss G: -0.12520088255405426\n",
      "Epoch [6/10] Batch [98/469] Loss D: -0.4102976322174072, loss G: -0.34316006302833557\n",
      "Epoch [6/10] Batch [99/469] Loss D: -0.47903311252593994, loss G: -0.17123979330062866\n",
      "Epoch [6/10] Batch [100/469] Loss D: -0.4733881652355194, loss G: -0.10775807499885559\n",
      "Epoch [6/10] Batch [101/469] Loss D: -0.30942419171333313, loss G: -0.40454018115997314\n",
      "Epoch [6/10] Batch [102/469] Loss D: -0.4174436330795288, loss G: -0.18164905905723572\n",
      "Epoch [6/10] Batch [103/469] Loss D: -0.45633912086486816, loss G: -0.19998157024383545\n",
      "Epoch [6/10] Batch [104/469] Loss D: -0.5297505855560303, loss G: -0.18446855247020721\n",
      "Epoch [6/10] Batch [105/469] Loss D: -0.4518235921859741, loss G: -0.18398675322532654\n",
      "Epoch [6/10] Batch [106/469] Loss D: -0.4486396312713623, loss G: -0.2852576673030853\n",
      "Epoch [6/10] Batch [107/469] Loss D: -0.40621674060821533, loss G: -0.12769173085689545\n",
      "Epoch [6/10] Batch [108/469] Loss D: -0.5060850381851196, loss G: -0.3224247395992279\n",
      "Epoch [6/10] Batch [109/469] Loss D: -0.43786516785621643, loss G: -0.08756482601165771\n",
      "Epoch [6/10] Batch [110/469] Loss D: -0.41420915722846985, loss G: -0.3466164171695709\n",
      "Epoch [6/10] Batch [111/469] Loss D: -0.40340888500213623, loss G: -0.21945571899414062\n",
      "Epoch [6/10] Batch [112/469] Loss D: -0.5279170870780945, loss G: -0.22384999692440033\n",
      "Epoch [6/10] Batch [113/469] Loss D: -0.5383399724960327, loss G: -0.18963804841041565\n",
      "Epoch [6/10] Batch [114/469] Loss D: -0.5556073784828186, loss G: -0.14483849704265594\n",
      "Epoch [6/10] Batch [115/469] Loss D: -0.4515296518802643, loss G: -0.2796376645565033\n",
      "Epoch [6/10] Batch [116/469] Loss D: -0.4884440302848816, loss G: -0.1499795913696289\n",
      "Epoch [6/10] Batch [117/469] Loss D: -0.5090826749801636, loss G: -0.33868950605392456\n",
      "Epoch [6/10] Batch [118/469] Loss D: -0.4304629862308502, loss G: -0.1436920017004013\n",
      "Epoch [6/10] Batch [119/469] Loss D: -0.4045640528202057, loss G: -0.272136390209198\n",
      "Epoch [6/10] Batch [120/469] Loss D: -0.4629843533039093, loss G: -0.2532730996608734\n",
      "Epoch [6/10] Batch [121/469] Loss D: -0.49059104919433594, loss G: -0.09564648568630219\n",
      "Epoch [6/10] Batch [122/469] Loss D: -0.38484033942222595, loss G: -0.39011484384536743\n",
      "Epoch [6/10] Batch [123/469] Loss D: -0.47820159792900085, loss G: -0.11360535770654678\n",
      "Epoch [6/10] Batch [124/469] Loss D: -0.5078243017196655, loss G: -0.32840365171432495\n",
      "Epoch [6/10] Batch [125/469] Loss D: -0.3943617343902588, loss G: -0.10944283753633499\n",
      "Epoch [6/10] Batch [126/469] Loss D: -0.4171842932701111, loss G: -0.4713805913925171\n",
      "Epoch [6/10] Batch [127/469] Loss D: -0.3861541152000427, loss G: -0.10172280669212341\n",
      "Epoch [6/10] Batch [128/469] Loss D: -0.37699955701828003, loss G: -0.22979772090911865\n",
      "Epoch [6/10] Batch [129/469] Loss D: -0.4299260377883911, loss G: -0.40061694383621216\n",
      "Epoch [6/10] Batch [130/469] Loss D: -0.3920394778251648, loss G: -0.13243785500526428\n",
      "Epoch [6/10] Batch [131/469] Loss D: -0.4028698801994324, loss G: -0.2336912453174591\n",
      "Epoch [6/10] Batch [132/469] Loss D: -0.46251723170280457, loss G: -0.2613186836242676\n",
      "Epoch [6/10] Batch [133/469] Loss D: -0.46313077211380005, loss G: -0.1552932858467102\n",
      "Epoch [6/10] Batch [134/469] Loss D: -0.48798882961273193, loss G: -0.23067952692508698\n",
      "Epoch [6/10] Batch [135/469] Loss D: -0.5261570811271667, loss G: -0.2163858860731125\n",
      "Epoch [6/10] Batch [136/469] Loss D: -0.4446479082107544, loss G: -0.21340636909008026\n",
      "Epoch [6/10] Batch [137/469] Loss D: -0.4528496265411377, loss G: -0.14305593073368073\n",
      "Epoch [6/10] Batch [138/469] Loss D: -0.43265360593795776, loss G: -0.34822410345077515\n",
      "Epoch [6/10] Batch [139/469] Loss D: -0.46272099018096924, loss G: -0.14006486535072327\n",
      "Epoch [6/10] Batch [140/469] Loss D: -0.4982883930206299, loss G: -0.26392197608947754\n",
      "Epoch [6/10] Batch [141/469] Loss D: -0.5113843679428101, loss G: -0.1820848286151886\n",
      "Epoch [6/10] Batch [142/469] Loss D: -0.5487421154975891, loss G: -0.18570251762866974\n",
      "Epoch [6/10] Batch [143/469] Loss D: -0.4333234429359436, loss G: -0.20352989435195923\n",
      "Epoch [6/10] Batch [144/469] Loss D: -0.39123398065567017, loss G: -0.289887934923172\n",
      "Epoch [6/10] Batch [145/469] Loss D: -0.5316148996353149, loss G: -0.09963010251522064\n",
      "Epoch [6/10] Batch [146/469] Loss D: -0.382667601108551, loss G: -0.40854084491729736\n",
      "Epoch [6/10] Batch [147/469] Loss D: -0.4096699059009552, loss G: -0.18024897575378418\n",
      "Epoch [6/10] Batch [148/469] Loss D: -0.4818086624145508, loss G: -0.22727185487747192\n",
      "Epoch [6/10] Batch [149/469] Loss D: -0.37451446056365967, loss G: -0.28160354495048523\n",
      "Epoch [6/10] Batch [150/469] Loss D: -0.46568164229393005, loss G: -0.12734544277191162\n",
      "Epoch [6/10] Batch [151/469] Loss D: -0.3978273570537567, loss G: -0.351762056350708\n",
      "Epoch [6/10] Batch [152/469] Loss D: -0.36808866262435913, loss G: -0.27832332253456116\n",
      "Epoch [6/10] Batch [153/469] Loss D: -0.4189283847808838, loss G: -0.12054646015167236\n",
      "Epoch [6/10] Batch [154/469] Loss D: -0.4069264531135559, loss G: -0.3851715326309204\n",
      "Epoch [6/10] Batch [155/469] Loss D: -0.3999248743057251, loss G: -0.2596449553966522\n",
      "Epoch [6/10] Batch [156/469] Loss D: -0.5491665005683899, loss G: -0.06595070660114288\n",
      "Epoch [6/10] Batch [157/469] Loss D: -0.4074006676673889, loss G: -0.4564211070537567\n",
      "Epoch [6/10] Batch [158/469] Loss D: -0.4424683153629303, loss G: -0.17584912478923798\n",
      "Epoch [6/10] Batch [159/469] Loss D: -0.4970945119857788, loss G: -0.13701841235160828\n",
      "Epoch [6/10] Batch [160/469] Loss D: -0.40817058086395264, loss G: -0.3822438716888428\n",
      "Epoch [6/10] Batch [161/469] Loss D: -0.45379579067230225, loss G: -0.13240472972393036\n",
      "Epoch [6/10] Batch [162/469] Loss D: -0.42727383971214294, loss G: -0.35262811183929443\n",
      "Epoch [6/10] Batch [163/469] Loss D: -0.5637955665588379, loss G: -0.0759536474943161\n",
      "Epoch [6/10] Batch [164/469] Loss D: -0.37338727712631226, loss G: -0.34163570404052734\n",
      "Epoch [6/10] Batch [165/469] Loss D: -0.4532257914543152, loss G: -0.17641958594322205\n",
      "Epoch [6/10] Batch [166/469] Loss D: -0.49441125988960266, loss G: -0.2959398627281189\n",
      "Epoch [6/10] Batch [167/469] Loss D: -0.4447266459465027, loss G: -0.11774934083223343\n",
      "Epoch [6/10] Batch [168/469] Loss D: -0.5314427614212036, loss G: -0.24911543726921082\n",
      "Epoch [6/10] Batch [169/469] Loss D: -0.46215301752090454, loss G: -0.23102200031280518\n",
      "Epoch [6/10] Batch [170/469] Loss D: -0.48752033710479736, loss G: -0.17083820700645447\n",
      "Epoch [6/10] Batch [171/469] Loss D: -0.4671779274940491, loss G: -0.3553568720817566\n",
      "Epoch [6/10] Batch [172/469] Loss D: -0.4336952865123749, loss G: -0.08735127747058868\n",
      "Epoch [6/10] Batch [173/469] Loss D: -0.42834725975990295, loss G: -0.3027991056442261\n",
      "Epoch [6/10] Batch [174/469] Loss D: -0.4668869078159332, loss G: -0.14959755539894104\n",
      "Epoch [6/10] Batch [175/469] Loss D: -0.3553099036216736, loss G: -0.29019176959991455\n",
      "Epoch [6/10] Batch [176/469] Loss D: -0.5639948844909668, loss G: -0.19381439685821533\n",
      "Epoch [6/10] Batch [177/469] Loss D: -0.49669408798217773, loss G: -0.1450732797384262\n",
      "Epoch [6/10] Batch [178/469] Loss D: -0.4617197513580322, loss G: -0.2733687460422516\n",
      "Epoch [6/10] Batch [179/469] Loss D: -0.4731747508049011, loss G: -0.16704684495925903\n",
      "Epoch [6/10] Batch [180/469] Loss D: -0.474234014749527, loss G: -0.2616110146045685\n",
      "Epoch [6/10] Batch [181/469] Loss D: -0.4555192291736603, loss G: -0.2617027461528778\n",
      "Epoch [6/10] Batch [182/469] Loss D: -0.4333435893058777, loss G: -0.17052523791790009\n",
      "Epoch [6/10] Batch [183/469] Loss D: -0.4498673975467682, loss G: -0.21544475853443146\n",
      "Epoch [6/10] Batch [184/469] Loss D: -0.5203063488006592, loss G: -0.22205694019794464\n",
      "Epoch [6/10] Batch [185/469] Loss D: -0.598774790763855, loss G: -0.054920174181461334\n",
      "Epoch [6/10] Batch [186/469] Loss D: -0.4591633677482605, loss G: -0.427436500787735\n",
      "Epoch [6/10] Batch [187/469] Loss D: -0.43889155983924866, loss G: -0.13632823526859283\n",
      "Epoch [6/10] Batch [188/469] Loss D: -0.47404205799102783, loss G: -0.32407525181770325\n",
      "Epoch [6/10] Batch [189/469] Loss D: -0.4461615979671478, loss G: -0.18438534438610077\n",
      "Epoch [6/10] Batch [190/469] Loss D: -0.4056461751461029, loss G: -0.31679457426071167\n",
      "Epoch [6/10] Batch [191/469] Loss D: -0.44264140725135803, loss G: -0.13729918003082275\n",
      "Epoch [6/10] Batch [192/469] Loss D: -0.4712834358215332, loss G: -0.2684035897254944\n",
      "Epoch [6/10] Batch [193/469] Loss D: -0.5084197521209717, loss G: -0.15856817364692688\n",
      "Epoch [6/10] Batch [194/469] Loss D: -0.4596773087978363, loss G: -0.30252569913864136\n",
      "Epoch [6/10] Batch [195/469] Loss D: -0.49582669138908386, loss G: -0.09320226311683655\n",
      "Epoch [6/10] Batch [196/469] Loss D: -0.4393075704574585, loss G: -0.37830859422683716\n",
      "Epoch [6/10] Batch [197/469] Loss D: -0.41363608837127686, loss G: -0.14348599314689636\n",
      "Epoch [6/10] Batch [198/469] Loss D: -0.4900834858417511, loss G: -0.17471210658550262\n",
      "Epoch [6/10] Batch [199/469] Loss D: -0.5673537850379944, loss G: -0.38057392835617065\n",
      "Epoch [6/10] Batch [200/469] Loss D: -0.39833590388298035, loss G: -0.17341873049736023\n",
      "Epoch [6/10] Batch [201/469] Loss D: -0.4788883924484253, loss G: -0.21827241778373718\n",
      "Epoch [6/10] Batch [202/469] Loss D: -0.4688969850540161, loss G: -0.22227731347084045\n",
      "Epoch [6/10] Batch [203/469] Loss D: -0.5320764183998108, loss G: -0.22054478526115417\n",
      "Epoch [6/10] Batch [204/469] Loss D: -0.4612239897251129, loss G: -0.13782283663749695\n",
      "Epoch [6/10] Batch [205/469] Loss D: -0.4103572368621826, loss G: -0.2794836759567261\n",
      "Epoch [6/10] Batch [206/469] Loss D: -0.5562717914581299, loss G: -0.16737772524356842\n",
      "Epoch [6/10] Batch [207/469] Loss D: -0.5287681818008423, loss G: -0.2051086574792862\n",
      "Epoch [6/10] Batch [208/469] Loss D: -0.5623831748962402, loss G: -0.11057812720537186\n",
      "Epoch [6/10] Batch [209/469] Loss D: -0.4619796872138977, loss G: -0.3671659231185913\n",
      "Epoch [6/10] Batch [210/469] Loss D: -0.4129307270050049, loss G: -0.09301988780498505\n",
      "Epoch [6/10] Batch [211/469] Loss D: -0.3469817042350769, loss G: -0.3440357446670532\n",
      "Epoch [6/10] Batch [212/469] Loss D: -0.44829195737838745, loss G: -0.13701261579990387\n",
      "Epoch [6/10] Batch [213/469] Loss D: -0.5105240345001221, loss G: -0.2013389766216278\n",
      "Epoch [6/10] Batch [214/469] Loss D: -0.4146043360233307, loss G: -0.2618889808654785\n",
      "Epoch [6/10] Batch [215/469] Loss D: -0.42194145917892456, loss G: -0.2463402897119522\n",
      "Epoch [6/10] Batch [216/469] Loss D: -0.409856915473938, loss G: -0.10630759596824646\n",
      "Epoch [6/10] Batch [217/469] Loss D: -0.45189177989959717, loss G: -0.31861770153045654\n",
      "Epoch [6/10] Batch [218/469] Loss D: -0.43686148524284363, loss G: -0.23819434642791748\n",
      "Epoch [6/10] Batch [219/469] Loss D: -0.475989431142807, loss G: -0.12368135154247284\n",
      "Epoch [6/10] Batch [220/469] Loss D: -0.5039197206497192, loss G: -0.34570273756980896\n",
      "Epoch [6/10] Batch [221/469] Loss D: -0.41273820400238037, loss G: -0.14459019899368286\n",
      "Epoch [6/10] Batch [222/469] Loss D: -0.5206542015075684, loss G: -0.20542050898075104\n",
      "Epoch [6/10] Batch [223/469] Loss D: -0.4919114112854004, loss G: -0.16679605841636658\n",
      "Epoch [6/10] Batch [224/469] Loss D: -0.3883068561553955, loss G: -0.25904929637908936\n",
      "Epoch [6/10] Batch [225/469] Loss D: -0.48260051012039185, loss G: -0.19556933641433716\n",
      "Epoch [6/10] Batch [226/469] Loss D: -0.4729841947555542, loss G: -0.2200104296207428\n",
      "Epoch [6/10] Batch [227/469] Loss D: -0.4803369641304016, loss G: -0.19914375245571136\n",
      "Epoch [6/10] Batch [228/469] Loss D: -0.5532160401344299, loss G: -0.11069972813129425\n",
      "Epoch [6/10] Batch [229/469] Loss D: -0.5089840292930603, loss G: -0.3577960729598999\n",
      "Epoch [6/10] Batch [230/469] Loss D: -0.3993641138076782, loss G: -0.24631425738334656\n",
      "Epoch [6/10] Batch [231/469] Loss D: -0.5230971574783325, loss G: -0.1444219946861267\n",
      "Epoch [6/10] Batch [232/469] Loss D: -0.59062260389328, loss G: -0.18979111313819885\n",
      "Epoch [6/10] Batch [233/469] Loss D: -0.38430050015449524, loss G: -0.25021401047706604\n",
      "Epoch [6/10] Batch [234/469] Loss D: -0.48199909925460815, loss G: -0.24479778110980988\n",
      "Epoch [6/10] Batch [235/469] Loss D: -0.4323972761631012, loss G: -0.1997910737991333\n",
      "Epoch [6/10] Batch [236/469] Loss D: -0.4962138831615448, loss G: -0.1475304663181305\n",
      "Epoch [6/10] Batch [237/469] Loss D: -0.32278409600257874, loss G: -0.37990298867225647\n",
      "Epoch [6/10] Batch [238/469] Loss D: -0.4040523171424866, loss G: -0.15632736682891846\n",
      "Epoch [6/10] Batch [239/469] Loss D: -0.4873602092266083, loss G: -0.24092461168766022\n",
      "Epoch [6/10] Batch [240/469] Loss D: -0.49628499150276184, loss G: -0.1585366427898407\n",
      "Epoch [6/10] Batch [241/469] Loss D: -0.46437859535217285, loss G: -0.3275231719017029\n",
      "Epoch [6/10] Batch [242/469] Loss D: -0.40028116106987, loss G: -0.14354346692562103\n",
      "Epoch [6/10] Batch [243/469] Loss D: -0.414284884929657, loss G: -0.3045922517776489\n",
      "Epoch [6/10] Batch [244/469] Loss D: -0.4523748755455017, loss G: -0.2869062125682831\n",
      "Epoch [6/10] Batch [245/469] Loss D: -0.45352181792259216, loss G: -0.19709280133247375\n",
      "Epoch [6/10] Batch [246/469] Loss D: -0.5540395975112915, loss G: -0.09382494539022446\n",
      "Epoch [6/10] Batch [247/469] Loss D: -0.502536952495575, loss G: -0.25735217332839966\n",
      "Epoch [6/10] Batch [248/469] Loss D: -0.455929696559906, loss G: -0.31559547781944275\n",
      "Epoch [6/10] Batch [249/469] Loss D: -0.3509160876274109, loss G: -0.21240603923797607\n",
      "Epoch [6/10] Batch [250/469] Loss D: -0.5470331311225891, loss G: -0.20262272655963898\n",
      "Epoch [6/10] Batch [251/469] Loss D: -0.49131929874420166, loss G: -0.22862422466278076\n",
      "Epoch [6/10] Batch [252/469] Loss D: -0.4612008333206177, loss G: -0.17224743962287903\n",
      "Epoch [6/10] Batch [253/469] Loss D: -0.4318464398384094, loss G: -0.2744002938270569\n",
      "Epoch [6/10] Batch [254/469] Loss D: -0.4899093508720398, loss G: -0.2046707570552826\n",
      "Epoch [6/10] Batch [255/469] Loss D: -0.5153934955596924, loss G: -0.06849659979343414\n",
      "Epoch [6/10] Batch [256/469] Loss D: -0.4074670672416687, loss G: -0.43941742181777954\n",
      "Epoch [6/10] Batch [257/469] Loss D: -0.4494670033454895, loss G: -0.08384256809949875\n",
      "Epoch [6/10] Batch [258/469] Loss D: -0.4643482267856598, loss G: -0.29550644755363464\n",
      "Epoch [6/10] Batch [259/469] Loss D: -0.4101000130176544, loss G: -0.23431633412837982\n",
      "Epoch [6/10] Batch [260/469] Loss D: -0.5116403698921204, loss G: -0.1450921893119812\n",
      "Epoch [6/10] Batch [261/469] Loss D: -0.4102541208267212, loss G: -0.35051554441452026\n",
      "Epoch [6/10] Batch [262/469] Loss D: -0.37178027629852295, loss G: -0.14495408535003662\n",
      "Epoch [6/10] Batch [263/469] Loss D: -0.43256908655166626, loss G: -0.29182952642440796\n",
      "Epoch [6/10] Batch [264/469] Loss D: -0.3963312804698944, loss G: -0.2417527139186859\n",
      "Epoch [6/10] Batch [265/469] Loss D: -0.5133388042449951, loss G: -0.17334340512752533\n",
      "Epoch [6/10] Batch [266/469] Loss D: -0.5552375912666321, loss G: -0.14975635707378387\n",
      "Epoch [6/10] Batch [267/469] Loss D: -0.4569976329803467, loss G: -0.3625825047492981\n",
      "Epoch [6/10] Batch [268/469] Loss D: -0.44193166494369507, loss G: -0.13362006843090057\n",
      "Epoch [6/10] Batch [269/469] Loss D: -0.432902455329895, loss G: -0.2155478298664093\n",
      "Epoch [6/10] Batch [270/469] Loss D: -0.4301057755947113, loss G: -0.386512815952301\n",
      "Epoch [6/10] Batch [271/469] Loss D: -0.4195423722267151, loss G: -0.15959075093269348\n",
      "Epoch [6/10] Batch [272/469] Loss D: -0.5293673276901245, loss G: -0.1449912041425705\n",
      "Epoch [6/10] Batch [273/469] Loss D: -0.4759640693664551, loss G: -0.2937588095664978\n",
      "Epoch [6/10] Batch [274/469] Loss D: -0.4853525459766388, loss G: -0.16908827424049377\n",
      "Epoch [6/10] Batch [275/469] Loss D: -0.5127740502357483, loss G: -0.2221108078956604\n",
      "Epoch [6/10] Batch [276/469] Loss D: -0.5106903910636902, loss G: -0.23364043235778809\n",
      "Epoch [6/10] Batch [277/469] Loss D: -0.5210347175598145, loss G: -0.0692928358912468\n",
      "Epoch [6/10] Batch [278/469] Loss D: -0.3841705024242401, loss G: -0.33917996287345886\n",
      "Epoch [6/10] Batch [279/469] Loss D: -0.4229075610637665, loss G: -0.19054178893566132\n",
      "Epoch [6/10] Batch [280/469] Loss D: -0.5110935568809509, loss G: -0.1789880245923996\n",
      "Epoch [6/10] Batch [281/469] Loss D: -0.4457956552505493, loss G: -0.2763011157512665\n",
      "Epoch [6/10] Batch [282/469] Loss D: -0.4537891149520874, loss G: -0.19248974323272705\n",
      "Epoch [6/10] Batch [283/469] Loss D: -0.4937025308609009, loss G: -0.22154510021209717\n",
      "Epoch [6/10] Batch [284/469] Loss D: -0.5017917156219482, loss G: -0.12415273487567902\n",
      "Epoch [6/10] Batch [285/469] Loss D: -0.49349352717399597, loss G: -0.2683632969856262\n",
      "Epoch [6/10] Batch [286/469] Loss D: -0.5536569356918335, loss G: -0.1964430958032608\n",
      "Epoch [6/10] Batch [287/469] Loss D: -0.5511223077774048, loss G: -0.14342063665390015\n",
      "Epoch [6/10] Batch [288/469] Loss D: -0.5198174715042114, loss G: -0.20416241884231567\n",
      "Epoch [6/10] Batch [289/469] Loss D: -0.4907694458961487, loss G: -0.16041868925094604\n",
      "Epoch [6/10] Batch [290/469] Loss D: -0.527845025062561, loss G: -0.2520392835140228\n",
      "Epoch [6/10] Batch [291/469] Loss D: -0.5639724135398865, loss G: -0.14508776366710663\n",
      "Epoch [6/10] Batch [292/469] Loss D: -0.5789914727210999, loss G: -0.27196842432022095\n",
      "Epoch [6/10] Batch [293/469] Loss D: -0.4384213089942932, loss G: -0.18480738997459412\n",
      "Epoch [6/10] Batch [294/469] Loss D: -0.45052221417427063, loss G: -0.1624816507101059\n",
      "Epoch [6/10] Batch [295/469] Loss D: -0.44654467701911926, loss G: -0.3893738090991974\n",
      "Epoch [6/10] Batch [296/469] Loss D: -0.4155404567718506, loss G: -0.10663016885519028\n",
      "Epoch [6/10] Batch [297/469] Loss D: -0.47033512592315674, loss G: -0.2836921811103821\n",
      "Epoch [6/10] Batch [298/469] Loss D: -0.44833457469940186, loss G: -0.24778218567371368\n",
      "Epoch [6/10] Batch [299/469] Loss D: -0.5297638773918152, loss G: -0.1317148506641388\n",
      "Epoch [6/10] Batch [300/469] Loss D: -0.49727216362953186, loss G: -0.193691685795784\n",
      "Epoch [6/10] Batch [301/469] Loss D: -0.5146880149841309, loss G: -0.2956653833389282\n",
      "Epoch [6/10] Batch [302/469] Loss D: -0.4788401424884796, loss G: -0.07644703984260559\n",
      "Epoch [6/10] Batch [303/469] Loss D: -0.43510109186172485, loss G: -0.3498784005641937\n",
      "Epoch [6/10] Batch [304/469] Loss D: -0.39432868361473083, loss G: -0.18623356521129608\n",
      "Epoch [6/10] Batch [305/469] Loss D: -0.5108527541160583, loss G: -0.1266925036907196\n",
      "Epoch [6/10] Batch [306/469] Loss D: -0.4046417474746704, loss G: -0.47728651762008667\n",
      "Epoch [6/10] Batch [307/469] Loss D: -0.3613637685775757, loss G: -0.15065932273864746\n",
      "Epoch [6/10] Batch [308/469] Loss D: -0.4702013432979584, loss G: -0.19374199211597443\n",
      "Epoch [6/10] Batch [309/469] Loss D: -0.4789157807826996, loss G: -0.23411330580711365\n",
      "Epoch [6/10] Batch [310/469] Loss D: -0.570478081703186, loss G: -0.07078786939382553\n",
      "Epoch [6/10] Batch [311/469] Loss D: -0.4378982186317444, loss G: -0.33494436740875244\n",
      "Epoch [6/10] Batch [312/469] Loss D: -0.4454042911529541, loss G: -0.1760408878326416\n",
      "Epoch [6/10] Batch [313/469] Loss D: -0.5153834819793701, loss G: -0.20466719567775726\n",
      "Epoch [6/10] Batch [314/469] Loss D: -0.5084688067436218, loss G: -0.22550585865974426\n",
      "Epoch [6/10] Batch [315/469] Loss D: -0.4646940529346466, loss G: -0.17744311690330505\n",
      "Epoch [6/10] Batch [316/469] Loss D: -0.44491806626319885, loss G: -0.24099810421466827\n",
      "Epoch [6/10] Batch [317/469] Loss D: -0.47746187448501587, loss G: -0.25412461161613464\n",
      "Epoch [6/10] Batch [318/469] Loss D: -0.4021139144897461, loss G: -0.1607753038406372\n",
      "Epoch [6/10] Batch [319/469] Loss D: -0.45940637588500977, loss G: -0.3475087881088257\n",
      "Epoch [6/10] Batch [320/469] Loss D: -0.4187687635421753, loss G: -0.20509585738182068\n",
      "Epoch [6/10] Batch [321/469] Loss D: -0.46852946281433105, loss G: -0.10756484419107437\n",
      "Epoch [6/10] Batch [322/469] Loss D: -0.45952969789505005, loss G: -0.3254354000091553\n",
      "Epoch [6/10] Batch [323/469] Loss D: -0.415282666683197, loss G: -0.228785902261734\n",
      "Epoch [6/10] Batch [324/469] Loss D: -0.5582869648933411, loss G: -0.15758106112480164\n",
      "Epoch [6/10] Batch [325/469] Loss D: -0.412656307220459, loss G: -0.3211822509765625\n",
      "Epoch [6/10] Batch [326/469] Loss D: -0.42782413959503174, loss G: -0.2419578731060028\n",
      "Epoch [6/10] Batch [327/469] Loss D: -0.472708523273468, loss G: -0.2042020857334137\n",
      "Epoch [6/10] Batch [328/469] Loss D: -0.40862205624580383, loss G: -0.2500396966934204\n",
      "Epoch [6/10] Batch [329/469] Loss D: -0.4303232431411743, loss G: -0.2906935513019562\n",
      "Epoch [6/10] Batch [330/469] Loss D: -0.4906872510910034, loss G: -0.1399979293346405\n",
      "Epoch [6/10] Batch [331/469] Loss D: -0.47056785225868225, loss G: -0.3472415804862976\n",
      "Epoch [6/10] Batch [332/469] Loss D: -0.3738461136817932, loss G: -0.1542443484067917\n",
      "Epoch [6/10] Batch [333/469] Loss D: -0.5015252828598022, loss G: -0.29231852293014526\n",
      "Epoch [6/10] Batch [334/469] Loss D: -0.47243532538414, loss G: -0.07768344134092331\n",
      "Epoch [6/10] Batch [335/469] Loss D: -0.375821053981781, loss G: -0.34143584966659546\n",
      "Epoch [6/10] Batch [336/469] Loss D: -0.40436261892318726, loss G: -0.210762619972229\n",
      "Epoch [6/10] Batch [337/469] Loss D: -0.5119438767433167, loss G: -0.09795645624399185\n",
      "Epoch [6/10] Batch [338/469] Loss D: -0.4365616738796234, loss G: -0.36381280422210693\n",
      "Epoch [6/10] Batch [339/469] Loss D: -0.44873425364494324, loss G: -0.10277876257896423\n",
      "Epoch [6/10] Batch [340/469] Loss D: -0.4504534900188446, loss G: -0.22355782985687256\n",
      "Epoch [6/10] Batch [341/469] Loss D: -0.4666716456413269, loss G: -0.30370262265205383\n",
      "Epoch [6/10] Batch [342/469] Loss D: -0.4623112082481384, loss G: -0.10711827129125595\n",
      "Epoch [6/10] Batch [343/469] Loss D: -0.4584752917289734, loss G: -0.29366403818130493\n",
      "Epoch [6/10] Batch [344/469] Loss D: -0.4304162561893463, loss G: -0.21759861707687378\n",
      "Epoch [6/10] Batch [345/469] Loss D: -0.4388464689254761, loss G: -0.24114863574504852\n",
      "Epoch [6/10] Batch [346/469] Loss D: -0.5012299418449402, loss G: -0.1261289417743683\n",
      "Epoch [6/10] Batch [347/469] Loss D: -0.5586670637130737, loss G: -0.20867544412612915\n",
      "Epoch [6/10] Batch [348/469] Loss D: -0.4788004755973816, loss G: -0.2504504323005676\n",
      "Epoch [6/10] Batch [349/469] Loss D: -0.44780513644218445, loss G: -0.13022299110889435\n",
      "Epoch [6/10] Batch [350/469] Loss D: -0.5263683795928955, loss G: -0.2307557910680771\n",
      "Epoch [6/10] Batch [351/469] Loss D: -0.4163692593574524, loss G: -0.26561787724494934\n",
      "Epoch [6/10] Batch [352/469] Loss D: -0.44879767298698425, loss G: -0.12843956053256989\n",
      "Epoch [6/10] Batch [353/469] Loss D: -0.3676048517227173, loss G: -0.28880569338798523\n",
      "Epoch [6/10] Batch [354/469] Loss D: -0.46872174739837646, loss G: -0.20902711153030396\n",
      "Epoch [6/10] Batch [355/469] Loss D: -0.5098457932472229, loss G: -0.20851096510887146\n",
      "Epoch [6/10] Batch [356/469] Loss D: -0.45521092414855957, loss G: -0.16412191092967987\n",
      "Epoch [6/10] Batch [357/469] Loss D: -0.4894774854183197, loss G: -0.1820666491985321\n",
      "Epoch [6/10] Batch [358/469] Loss D: -0.5407447814941406, loss G: -0.23885568976402283\n",
      "Epoch [6/10] Batch [359/469] Loss D: -0.5630033612251282, loss G: -0.14164075255393982\n",
      "Epoch [6/10] Batch [360/469] Loss D: -0.49464547634124756, loss G: -0.26238250732421875\n",
      "Epoch [6/10] Batch [361/469] Loss D: -0.45293235778808594, loss G: -0.1755335032939911\n",
      "Epoch [6/10] Batch [362/469] Loss D: -0.46291396021842957, loss G: -0.32913777232170105\n",
      "Epoch [6/10] Batch [363/469] Loss D: -0.4362545311450958, loss G: -0.1150682270526886\n",
      "Epoch [6/10] Batch [364/469] Loss D: -0.3675750195980072, loss G: -0.3617619276046753\n",
      "Epoch [6/10] Batch [365/469] Loss D: -0.4737386405467987, loss G: -0.1436176300048828\n",
      "Epoch [6/10] Batch [366/469] Loss D: -0.40962180495262146, loss G: -0.18868499994277954\n",
      "Epoch [6/10] Batch [367/469] Loss D: -0.6183376908302307, loss G: -0.1694658100605011\n",
      "Epoch [6/10] Batch [368/469] Loss D: -0.5570337772369385, loss G: -0.25322431325912476\n",
      "Epoch [6/10] Batch [369/469] Loss D: -0.5074132680892944, loss G: -0.09230281412601471\n",
      "Epoch [6/10] Batch [370/469] Loss D: -0.5699124932289124, loss G: -0.270163357257843\n",
      "Epoch [6/10] Batch [371/469] Loss D: -0.494126558303833, loss G: -0.16400150954723358\n",
      "Epoch [6/10] Batch [372/469] Loss D: -0.42656654119491577, loss G: -0.27934300899505615\n",
      "Epoch [6/10] Batch [373/469] Loss D: -0.3757358193397522, loss G: -0.2574920356273651\n",
      "Epoch [6/10] Batch [374/469] Loss D: -0.4357106685638428, loss G: -0.08705804497003555\n",
      "Epoch [6/10] Batch [375/469] Loss D: -0.4074050188064575, loss G: -0.3113902807235718\n",
      "Epoch [6/10] Batch [376/469] Loss D: -0.5208277702331543, loss G: -0.21229961514472961\n",
      "Epoch [6/10] Batch [377/469] Loss D: -0.4502623677253723, loss G: -0.1695646345615387\n",
      "Epoch [6/10] Batch [378/469] Loss D: -0.5355914831161499, loss G: -0.23899081349372864\n",
      "Epoch [6/10] Batch [379/469] Loss D: -0.47043702006340027, loss G: -0.1676509529352188\n",
      "Epoch [6/10] Batch [380/469] Loss D: -0.42732375860214233, loss G: -0.23908737301826477\n",
      "Epoch [6/10] Batch [381/469] Loss D: -0.4687263071537018, loss G: -0.23532161116600037\n",
      "Epoch [6/10] Batch [382/469] Loss D: -0.4729706645011902, loss G: -0.22710657119750977\n",
      "Epoch [6/10] Batch [383/469] Loss D: -0.4223847985267639, loss G: -0.2476825714111328\n",
      "Epoch [6/10] Batch [384/469] Loss D: -0.4820821285247803, loss G: -0.15697550773620605\n",
      "Epoch [6/10] Batch [385/469] Loss D: -0.41804036498069763, loss G: -0.3148422837257385\n",
      "Epoch [6/10] Batch [386/469] Loss D: -0.4281858205795288, loss G: -0.1755005121231079\n",
      "Epoch [6/10] Batch [387/469] Loss D: -0.4387468099594116, loss G: -0.24149130284786224\n",
      "Epoch [6/10] Batch [388/469] Loss D: -0.4530041217803955, loss G: -0.2128150761127472\n",
      "Epoch [6/10] Batch [389/469] Loss D: -0.5727391242980957, loss G: -0.16589541733264923\n",
      "Epoch [6/10] Batch [390/469] Loss D: -0.5119107365608215, loss G: -0.209082692861557\n",
      "Epoch [6/10] Batch [391/469] Loss D: -0.4561834931373596, loss G: -0.18200989067554474\n",
      "Epoch [6/10] Batch [392/469] Loss D: -0.48642659187316895, loss G: -0.2214171588420868\n",
      "Epoch [6/10] Batch [393/469] Loss D: -0.4214446544647217, loss G: -0.25989216566085815\n",
      "Epoch [6/10] Batch [394/469] Loss D: -0.4853508472442627, loss G: -0.19505532085895538\n",
      "Epoch [6/10] Batch [395/469] Loss D: -0.5475869178771973, loss G: -0.26293739676475525\n",
      "Epoch [6/10] Batch [396/469] Loss D: -0.40334081649780273, loss G: -0.1606874167919159\n",
      "Epoch [6/10] Batch [397/469] Loss D: -0.5001536011695862, loss G: -0.232878640294075\n",
      "Epoch [6/10] Batch [398/469] Loss D: -0.5231549739837646, loss G: -0.213189035654068\n",
      "Epoch [6/10] Batch [399/469] Loss D: -0.44970178604125977, loss G: -0.29140347242355347\n",
      "Epoch [6/10] Batch [400/469] Loss D: -0.4826757609844208, loss G: -0.10775741934776306\n",
      "Epoch [6/10] Batch [401/469] Loss D: -0.49839287996292114, loss G: -0.285591185092926\n",
      "Epoch [6/10] Batch [402/469] Loss D: -0.4486885666847229, loss G: -0.14066559076309204\n",
      "Epoch [6/10] Batch [403/469] Loss D: -0.38229209184646606, loss G: -0.3592124879360199\n",
      "Epoch [6/10] Batch [404/469] Loss D: -0.4742940366268158, loss G: -0.15585121512413025\n",
      "Epoch [6/10] Batch [405/469] Loss D: -0.5527724027633667, loss G: -0.15844348073005676\n",
      "Epoch [6/10] Batch [406/469] Loss D: -0.5364872813224792, loss G: -0.22070160508155823\n",
      "Epoch [6/10] Batch [407/469] Loss D: -0.44828271865844727, loss G: -0.13194051384925842\n",
      "Epoch [6/10] Batch [408/469] Loss D: -0.43766123056411743, loss G: -0.3038000464439392\n",
      "Epoch [6/10] Batch [409/469] Loss D: -0.5001338720321655, loss G: -0.17825466394424438\n",
      "Epoch [6/10] Batch [410/469] Loss D: -0.4538705050945282, loss G: -0.20191293954849243\n",
      "Epoch [6/10] Batch [411/469] Loss D: -0.4849889874458313, loss G: -0.18275870382785797\n",
      "Epoch [6/10] Batch [412/469] Loss D: -0.4935964345932007, loss G: -0.27202993631362915\n",
      "Epoch [6/10] Batch [413/469] Loss D: -0.420221209526062, loss G: -0.25246578454971313\n",
      "Epoch [6/10] Batch [414/469] Loss D: -0.5107470750808716, loss G: -0.1171284168958664\n",
      "Epoch [6/10] Batch [415/469] Loss D: -0.4095406234264374, loss G: -0.27155405282974243\n",
      "Epoch [6/10] Batch [416/469] Loss D: -0.5045348405838013, loss G: -0.2117045372724533\n",
      "Epoch [6/10] Batch [417/469] Loss D: -0.47113800048828125, loss G: -0.23732933402061462\n",
      "Epoch [6/10] Batch [418/469] Loss D: -0.49520984292030334, loss G: -0.12351186573505402\n",
      "Epoch [6/10] Batch [419/469] Loss D: -0.5968183875083923, loss G: -0.20023733377456665\n",
      "Epoch [6/10] Batch [420/469] Loss D: -0.519545316696167, loss G: -0.24179783463478088\n",
      "Epoch [6/10] Batch [421/469] Loss D: -0.5180955529212952, loss G: -0.05993414297699928\n",
      "Epoch [6/10] Batch [422/469] Loss D: -0.3408910036087036, loss G: -0.3112295866012573\n",
      "Epoch [6/10] Batch [423/469] Loss D: -0.4772806763648987, loss G: -0.21469798684120178\n",
      "Epoch [6/10] Batch [424/469] Loss D: -0.5064195394515991, loss G: -0.1071241945028305\n",
      "Epoch [6/10] Batch [425/469] Loss D: -0.3991668224334717, loss G: -0.3727998733520508\n",
      "Epoch [6/10] Batch [426/469] Loss D: -0.41232138872146606, loss G: -0.20620501041412354\n",
      "Epoch [6/10] Batch [427/469] Loss D: -0.4616047143936157, loss G: -0.1441519856452942\n",
      "Epoch [6/10] Batch [428/469] Loss D: -0.5077623128890991, loss G: -0.3526856303215027\n",
      "Epoch [6/10] Batch [429/469] Loss D: -0.429433673620224, loss G: -0.12650330364704132\n",
      "Epoch [6/10] Batch [430/469] Loss D: -0.42054763436317444, loss G: -0.26607200503349304\n",
      "Epoch [6/10] Batch [431/469] Loss D: -0.5377364158630371, loss G: -0.1666175127029419\n",
      "Epoch [6/10] Batch [432/469] Loss D: -0.43110108375549316, loss G: -0.25565260648727417\n",
      "Epoch [6/10] Batch [433/469] Loss D: -0.4535900354385376, loss G: -0.1671045422554016\n",
      "Epoch [6/10] Batch [434/469] Loss D: -0.5029150247573853, loss G: -0.15084029734134674\n",
      "Epoch [6/10] Batch [435/469] Loss D: -0.5505858659744263, loss G: -0.25895172357559204\n",
      "Epoch [6/10] Batch [436/469] Loss D: -0.5391401648521423, loss G: -0.13152466714382172\n",
      "Epoch [6/10] Batch [437/469] Loss D: -0.4949527084827423, loss G: -0.24499481916427612\n",
      "Epoch [6/10] Batch [438/469] Loss D: -0.5643771290779114, loss G: -0.172915518283844\n",
      "Epoch [6/10] Batch [439/469] Loss D: -0.5526955723762512, loss G: -0.1391475647687912\n",
      "Epoch [6/10] Batch [440/469] Loss D: -0.5153864622116089, loss G: -0.22776073217391968\n",
      "Epoch [6/10] Batch [441/469] Loss D: -0.4770684540271759, loss G: -0.18834221363067627\n",
      "Epoch [6/10] Batch [442/469] Loss D: -0.4924365282058716, loss G: -0.17225374281406403\n",
      "Epoch [6/10] Batch [443/469] Loss D: -0.5022767186164856, loss G: -0.16571840643882751\n",
      "Epoch [6/10] Batch [444/469] Loss D: -0.475791335105896, loss G: -0.28539320826530457\n",
      "Epoch [6/10] Batch [445/469] Loss D: -0.4051881432533264, loss G: -0.27044734358787537\n",
      "Epoch [6/10] Batch [446/469] Loss D: -0.4818473160266876, loss G: -0.10140460729598999\n",
      "Epoch [6/10] Batch [447/469] Loss D: -0.4517020285129547, loss G: -0.330890953540802\n",
      "Epoch [6/10] Batch [448/469] Loss D: -0.4651104211807251, loss G: -0.1754848062992096\n",
      "Epoch [6/10] Batch [449/469] Loss D: -0.47530481219291687, loss G: -0.22630718350410461\n",
      "Epoch [6/10] Batch [450/469] Loss D: -0.47438710927963257, loss G: -0.22482697665691376\n",
      "Epoch [6/10] Batch [451/469] Loss D: -0.4400782287120819, loss G: -0.25312262773513794\n",
      "Epoch [6/10] Batch [452/469] Loss D: -0.3948386609554291, loss G: -0.19750936329364777\n",
      "Epoch [6/10] Batch [453/469] Loss D: -0.47301438450813293, loss G: -0.24950510263442993\n",
      "Epoch [6/10] Batch [454/469] Loss D: -0.5082278251647949, loss G: -0.10142908245325089\n",
      "Epoch [6/10] Batch [455/469] Loss D: -0.42261457443237305, loss G: -0.302997887134552\n",
      "Epoch [6/10] Batch [456/469] Loss D: -0.4891999661922455, loss G: -0.08474646508693695\n",
      "Epoch [6/10] Batch [457/469] Loss D: -0.47725945711135864, loss G: -0.3436907231807709\n",
      "Epoch [6/10] Batch [458/469] Loss D: -0.3809241056442261, loss G: -0.15426553785800934\n",
      "Epoch [6/10] Batch [459/469] Loss D: -0.5256860256195068, loss G: -0.1388815939426422\n",
      "Epoch [6/10] Batch [460/469] Loss D: -0.4667956531047821, loss G: -0.366722971200943\n",
      "Epoch [6/10] Batch [461/469] Loss D: -0.42674291133880615, loss G: -0.05663756653666496\n",
      "Epoch [6/10] Batch [462/469] Loss D: -0.3942417502403259, loss G: -0.27436119318008423\n",
      "Epoch [6/10] Batch [463/469] Loss D: -0.408891886472702, loss G: -0.3188835382461548\n",
      "Epoch [6/10] Batch [464/469] Loss D: -0.5526502132415771, loss G: -0.09089089930057526\n",
      "Epoch [6/10] Batch [465/469] Loss D: -0.477027952671051, loss G: -0.286521315574646\n",
      "Epoch [6/10] Batch [466/469] Loss D: -0.507296085357666, loss G: -0.20915451645851135\n",
      "Epoch [6/10] Batch [467/469] Loss D: -0.5411771535873413, loss G: -0.10575145483016968\n",
      "Epoch [6/10] Batch [468/469] Loss D: -0.4692612886428833, loss G: -0.3399540185928345\n",
      "Epoch [6/10] Batch [469/469] Loss D: -0.47115251421928406, loss G: -0.0936925932765007\n",
      "Epoch [7/10] Batch [1/469] Loss D: -0.42238885164260864, loss G: -0.2547399401664734\n",
      "Epoch [7/10] Batch [2/469] Loss D: -0.4538176357746124, loss G: -0.239565908908844\n",
      "Epoch [7/10] Batch [3/469] Loss D: -0.502402126789093, loss G: -0.16876009106636047\n",
      "Epoch [7/10] Batch [4/469] Loss D: -0.5287833213806152, loss G: -0.18337109684944153\n",
      "Epoch [7/10] Batch [5/469] Loss D: -0.514032244682312, loss G: -0.2801004648208618\n",
      "Epoch [7/10] Batch [6/469] Loss D: -0.4904351830482483, loss G: -0.1338161826133728\n",
      "Epoch [7/10] Batch [7/469] Loss D: -0.45267948508262634, loss G: -0.4400475025177002\n",
      "Epoch [7/10] Batch [8/469] Loss D: -0.3087548017501831, loss G: -0.1545243263244629\n",
      "Epoch [7/10] Batch [9/469] Loss D: -0.3917897045612335, loss G: -0.2304290235042572\n",
      "Epoch [7/10] Batch [10/469] Loss D: -0.5359973311424255, loss G: -0.18837568163871765\n",
      "Epoch [7/10] Batch [11/469] Loss D: -0.487316370010376, loss G: -0.26055604219436646\n",
      "Epoch [7/10] Batch [12/469] Loss D: -0.48917457461357117, loss G: -0.14450082182884216\n",
      "Epoch [7/10] Batch [13/469] Loss D: -0.5238842368125916, loss G: -0.2300281822681427\n",
      "Epoch [7/10] Batch [14/469] Loss D: -0.595127284526825, loss G: -0.12644226849079132\n",
      "Epoch [7/10] Batch [15/469] Loss D: -0.5419049263000488, loss G: -0.2562928795814514\n",
      "Epoch [7/10] Batch [16/469] Loss D: -0.48937585949897766, loss G: -0.11848395317792892\n",
      "Epoch [7/10] Batch [17/469] Loss D: -0.44032126665115356, loss G: -0.3531603217124939\n",
      "Epoch [7/10] Batch [18/469] Loss D: -0.5120221376419067, loss G: -0.07914900779724121\n",
      "Epoch [7/10] Batch [19/469] Loss D: -0.5139087438583374, loss G: -0.2640259563922882\n",
      "Epoch [7/10] Batch [20/469] Loss D: -0.524635910987854, loss G: -0.17713041603565216\n",
      "Epoch [7/10] Batch [21/469] Loss D: -0.4490594267845154, loss G: -0.23483535647392273\n",
      "Epoch [7/10] Batch [22/469] Loss D: -0.5261225700378418, loss G: -0.1477806568145752\n",
      "Epoch [7/10] Batch [23/469] Loss D: -0.48600131273269653, loss G: -0.29078948497772217\n",
      "Epoch [7/10] Batch [24/469] Loss D: -0.563754677772522, loss G: -0.17956531047821045\n",
      "Epoch [7/10] Batch [25/469] Loss D: -0.4732052683830261, loss G: -0.16249388456344604\n",
      "Epoch [7/10] Batch [26/469] Loss D: -0.4737670421600342, loss G: -0.3825935423374176\n",
      "Epoch [7/10] Batch [27/469] Loss D: -0.42569777369499207, loss G: -0.1374393105506897\n",
      "Epoch [7/10] Batch [28/469] Loss D: -0.4729114770889282, loss G: -0.2199525535106659\n",
      "Epoch [7/10] Batch [29/469] Loss D: -0.42685890197753906, loss G: -0.3732653260231018\n",
      "Epoch [7/10] Batch [30/469] Loss D: -0.37997621297836304, loss G: -0.11873182654380798\n",
      "Epoch [7/10] Batch [31/469] Loss D: -0.41941210627555847, loss G: -0.28513526916503906\n",
      "Epoch [7/10] Batch [32/469] Loss D: -0.49568381905555725, loss G: -0.23340551555156708\n",
      "Epoch [7/10] Batch [33/469] Loss D: -0.5018215775489807, loss G: -0.11116946488618851\n",
      "Epoch [7/10] Batch [34/469] Loss D: -0.510650634765625, loss G: -0.2645566463470459\n",
      "Epoch [7/10] Batch [35/469] Loss D: -0.46070435643196106, loss G: -0.2240092009305954\n",
      "Epoch [7/10] Batch [36/469] Loss D: -0.5304365754127502, loss G: -0.1486615687608719\n",
      "Epoch [7/10] Batch [37/469] Loss D: -0.4241785705089569, loss G: -0.270599901676178\n",
      "Epoch [7/10] Batch [38/469] Loss D: -0.5305142402648926, loss G: -0.23184534907341003\n",
      "Epoch [7/10] Batch [39/469] Loss D: -0.495291531085968, loss G: -0.08444634079933167\n",
      "Epoch [7/10] Batch [40/469] Loss D: -0.44926387071609497, loss G: -0.3707345724105835\n",
      "Epoch [7/10] Batch [41/469] Loss D: -0.4410618543624878, loss G: -0.11590117961168289\n",
      "Epoch [7/10] Batch [42/469] Loss D: -0.5224040746688843, loss G: -0.2208336591720581\n",
      "Epoch [7/10] Batch [43/469] Loss D: -0.5426130294799805, loss G: -0.22722917795181274\n",
      "Epoch [7/10] Batch [44/469] Loss D: -0.5312256813049316, loss G: -0.10114094614982605\n",
      "Epoch [7/10] Batch [45/469] Loss D: -0.4235948622226715, loss G: -0.35190311074256897\n",
      "Epoch [7/10] Batch [46/469] Loss D: -0.4977702796459198, loss G: -0.07470082491636276\n",
      "Epoch [7/10] Batch [47/469] Loss D: -0.44353175163269043, loss G: -0.3352261185646057\n",
      "Epoch [7/10] Batch [48/469] Loss D: -0.5270549058914185, loss G: -0.10826011747121811\n",
      "Epoch [7/10] Batch [49/469] Loss D: -0.529911994934082, loss G: -0.33016496896743774\n",
      "Epoch [7/10] Batch [50/469] Loss D: -0.4488711655139923, loss G: -0.10328847914934158\n",
      "Epoch [7/10] Batch [51/469] Loss D: -0.4963163435459137, loss G: -0.26849499344825745\n",
      "Epoch [7/10] Batch [52/469] Loss D: -0.4726189970970154, loss G: -0.27645230293273926\n",
      "Epoch [7/10] Batch [53/469] Loss D: -0.5048140287399292, loss G: -0.07927051186561584\n",
      "Epoch [7/10] Batch [54/469] Loss D: -0.5089756846427917, loss G: -0.3685625195503235\n",
      "Epoch [7/10] Batch [55/469] Loss D: -0.45338159799575806, loss G: -0.11502562463283539\n",
      "Epoch [7/10] Batch [56/469] Loss D: -0.3685523569583893, loss G: -0.29365313053131104\n",
      "Epoch [7/10] Batch [57/469] Loss D: -0.377183735370636, loss G: -0.24945712089538574\n",
      "Epoch [7/10] Batch [58/469] Loss D: -0.5349432229995728, loss G: -0.10807903856039047\n",
      "Epoch [7/10] Batch [59/469] Loss D: -0.5340811014175415, loss G: -0.2611101269721985\n",
      "Epoch [7/10] Batch [60/469] Loss D: -0.4974193871021271, loss G: -0.21666446328163147\n",
      "Epoch [7/10] Batch [61/469] Loss D: -0.4641677141189575, loss G: -0.15361341834068298\n",
      "Epoch [7/10] Batch [62/469] Loss D: -0.5158936381340027, loss G: -0.3013904094696045\n",
      "Epoch [7/10] Batch [63/469] Loss D: -0.44528424739837646, loss G: -0.08902853727340698\n",
      "Epoch [7/10] Batch [64/469] Loss D: -0.5691565275192261, loss G: -0.22361648082733154\n",
      "Epoch [7/10] Batch [65/469] Loss D: -0.47745540738105774, loss G: -0.2199748456478119\n",
      "Epoch [7/10] Batch [66/469] Loss D: -0.4682130813598633, loss G: -0.32981160283088684\n",
      "Epoch [7/10] Batch [67/469] Loss D: -0.48854145407676697, loss G: -0.08246671408414841\n",
      "Epoch [7/10] Batch [68/469] Loss D: -0.47171545028686523, loss G: -0.282927542924881\n",
      "Epoch [7/10] Batch [69/469] Loss D: -0.43527859449386597, loss G: -0.18176358938217163\n",
      "Epoch [7/10] Batch [70/469] Loss D: -0.5581246614456177, loss G: -0.16141895949840546\n",
      "Epoch [7/10] Batch [71/469] Loss D: -0.5002990365028381, loss G: -0.2830086946487427\n",
      "Epoch [7/10] Batch [72/469] Loss D: -0.48599007725715637, loss G: -0.15638276934623718\n",
      "Epoch [7/10] Batch [73/469] Loss D: -0.5590474605560303, loss G: -0.22602829337120056\n",
      "Epoch [7/10] Batch [74/469] Loss D: -0.45379239320755005, loss G: -0.2369762361049652\n",
      "Epoch [7/10] Batch [75/469] Loss D: -0.5371724963188171, loss G: -0.15043872594833374\n",
      "Epoch [7/10] Batch [76/469] Loss D: -0.5995513200759888, loss G: -0.22590599954128265\n",
      "Epoch [7/10] Batch [77/469] Loss D: -0.5021342635154724, loss G: -0.06760472804307938\n",
      "Epoch [7/10] Batch [78/469] Loss D: -0.4760865569114685, loss G: -0.4386034607887268\n",
      "Epoch [7/10] Batch [79/469] Loss D: -0.3734855651855469, loss G: -0.1897950917482376\n",
      "Epoch [7/10] Batch [80/469] Loss D: -0.5221185684204102, loss G: -0.158506840467453\n",
      "Epoch [7/10] Batch [81/469] Loss D: -0.48592472076416016, loss G: -0.25455737113952637\n",
      "Epoch [7/10] Batch [82/469] Loss D: -0.48600977659225464, loss G: -0.10394951701164246\n",
      "Epoch [7/10] Batch [83/469] Loss D: -0.5313661694526672, loss G: -0.3057651221752167\n",
      "Epoch [7/10] Batch [84/469] Loss D: -0.5577836632728577, loss G: -0.10332430154085159\n",
      "Epoch [7/10] Batch [85/469] Loss D: -0.46158459782600403, loss G: -0.22147420048713684\n",
      "Epoch [7/10] Batch [86/469] Loss D: -0.5260035395622253, loss G: -0.144344300031662\n",
      "Epoch [7/10] Batch [87/469] Loss D: -0.44440537691116333, loss G: -0.3260571360588074\n",
      "Epoch [7/10] Batch [88/469] Loss D: -0.44821402430534363, loss G: -0.18969792127609253\n",
      "Epoch [7/10] Batch [89/469] Loss D: -0.47590938210487366, loss G: -0.20640987157821655\n",
      "Epoch [7/10] Batch [90/469] Loss D: -0.5258612632751465, loss G: -0.21289008855819702\n",
      "Epoch [7/10] Batch [91/469] Loss D: -0.5320053696632385, loss G: -0.17356760799884796\n",
      "Epoch [7/10] Batch [92/469] Loss D: -0.4737131595611572, loss G: -0.1788794845342636\n",
      "Epoch [7/10] Batch [93/469] Loss D: -0.566527783870697, loss G: -0.25615715980529785\n",
      "Epoch [7/10] Batch [94/469] Loss D: -0.5473310947418213, loss G: -0.09160538762807846\n",
      "Epoch [7/10] Batch [95/469] Loss D: -0.5181739330291748, loss G: -0.353996217250824\n",
      "Epoch [7/10] Batch [96/469] Loss D: -0.35066354274749756, loss G: -0.17266365885734558\n",
      "Epoch [7/10] Batch [97/469] Loss D: -0.5422471165657043, loss G: -0.1820409595966339\n",
      "Epoch [7/10] Batch [98/469] Loss D: -0.5118547677993774, loss G: -0.24408739805221558\n",
      "Epoch [7/10] Batch [99/469] Loss D: -0.4839797914028168, loss G: -0.20602452754974365\n",
      "Epoch [7/10] Batch [100/469] Loss D: -0.48096418380737305, loss G: -0.1717250794172287\n",
      "Epoch [7/10] Batch [101/469] Loss D: -0.5303090810775757, loss G: -0.2482377290725708\n",
      "Epoch [7/10] Batch [102/469] Loss D: -0.5590967535972595, loss G: -0.16727852821350098\n",
      "Epoch [7/10] Batch [103/469] Loss D: -0.5262877941131592, loss G: -0.09283838421106339\n",
      "Epoch [7/10] Batch [104/469] Loss D: -0.35806745290756226, loss G: -0.4127334654331207\n",
      "Epoch [7/10] Batch [105/469] Loss D: -0.38905075192451477, loss G: -0.20202895998954773\n",
      "Epoch [7/10] Batch [106/469] Loss D: -0.48125725984573364, loss G: -0.22574925422668457\n",
      "Epoch [7/10] Batch [107/469] Loss D: -0.5197581052780151, loss G: -0.16766630113124847\n",
      "Epoch [7/10] Batch [108/469] Loss D: -0.5995491743087769, loss G: -0.12801814079284668\n",
      "Epoch [7/10] Batch [109/469] Loss D: -0.562985897064209, loss G: -0.3318565785884857\n",
      "Epoch [7/10] Batch [110/469] Loss D: -0.5139088034629822, loss G: -0.08901622146368027\n",
      "Epoch [7/10] Batch [111/469] Loss D: -0.4480934739112854, loss G: -0.336911141872406\n",
      "Epoch [7/10] Batch [112/469] Loss D: -0.4543154835700989, loss G: -0.13379329442977905\n",
      "Epoch [7/10] Batch [113/469] Loss D: -0.5061610341072083, loss G: -0.25711965560913086\n",
      "Epoch [7/10] Batch [114/469] Loss D: -0.6171859502792358, loss G: -0.09047815948724747\n",
      "Epoch [7/10] Batch [115/469] Loss D: -0.5258834362030029, loss G: -0.17204147577285767\n",
      "Epoch [7/10] Batch [116/469] Loss D: -0.5256215333938599, loss G: -0.49210870265960693\n",
      "Epoch [7/10] Batch [117/469] Loss D: -0.338706374168396, loss G: -0.1177571713924408\n",
      "Epoch [7/10] Batch [118/469] Loss D: -0.5480881929397583, loss G: -0.18161167204380035\n",
      "Epoch [7/10] Batch [119/469] Loss D: -0.48880404233932495, loss G: -0.1822543740272522\n",
      "Epoch [7/10] Batch [120/469] Loss D: -0.48048722743988037, loss G: -0.300296425819397\n",
      "Epoch [7/10] Batch [121/469] Loss D: -0.4918110966682434, loss G: -0.13231849670410156\n",
      "Epoch [7/10] Batch [122/469] Loss D: -0.5036898255348206, loss G: -0.22187542915344238\n",
      "Epoch [7/10] Batch [123/469] Loss D: -0.5564197301864624, loss G: -0.2359657883644104\n",
      "Epoch [7/10] Batch [124/469] Loss D: -0.4825701117515564, loss G: -0.07891924679279327\n",
      "Epoch [7/10] Batch [125/469] Loss D: -0.5722803473472595, loss G: -0.2799195647239685\n",
      "Epoch [7/10] Batch [126/469] Loss D: -0.48962706327438354, loss G: -0.10920505970716476\n",
      "Epoch [7/10] Batch [127/469] Loss D: -0.5205228924751282, loss G: -0.25842568278312683\n",
      "Epoch [7/10] Batch [128/469] Loss D: -0.41530150175094604, loss G: -0.16992494463920593\n",
      "Epoch [7/10] Batch [129/469] Loss D: -0.49885231256484985, loss G: -0.2338864803314209\n",
      "Epoch [7/10] Batch [130/469] Loss D: -0.37403416633605957, loss G: -0.26113900542259216\n",
      "Epoch [7/10] Batch [131/469] Loss D: -0.5179626941680908, loss G: -0.15478840470314026\n",
      "Epoch [7/10] Batch [132/469] Loss D: -0.47248244285583496, loss G: -0.2554773688316345\n",
      "Epoch [7/10] Batch [133/469] Loss D: -0.505908191204071, loss G: -0.16577470302581787\n",
      "Epoch [7/10] Batch [134/469] Loss D: -0.49227410554885864, loss G: -0.28815221786499023\n",
      "Epoch [7/10] Batch [135/469] Loss D: -0.4811232388019562, loss G: -0.11456282436847687\n",
      "Epoch [7/10] Batch [136/469] Loss D: -0.4643007218837738, loss G: -0.2929520010948181\n",
      "Epoch [7/10] Batch [137/469] Loss D: -0.4503774344921112, loss G: -0.1322045624256134\n",
      "Epoch [7/10] Batch [138/469] Loss D: -0.4409865438938141, loss G: -0.35493019223213196\n",
      "Epoch [7/10] Batch [139/469] Loss D: -0.49710842967033386, loss G: -0.145173579454422\n",
      "Epoch [7/10] Batch [140/469] Loss D: -0.4710511565208435, loss G: -0.23093467950820923\n",
      "Epoch [7/10] Batch [141/469] Loss D: -0.5415359735488892, loss G: -0.16997525095939636\n",
      "Epoch [7/10] Batch [142/469] Loss D: -0.5239206552505493, loss G: -0.25946056842803955\n",
      "Epoch [7/10] Batch [143/469] Loss D: -0.4909403920173645, loss G: -0.11222338676452637\n",
      "Epoch [7/10] Batch [144/469] Loss D: -0.46407055854797363, loss G: -0.40824997425079346\n",
      "Epoch [7/10] Batch [145/469] Loss D: -0.42962878942489624, loss G: -0.1750430017709732\n",
      "Epoch [7/10] Batch [146/469] Loss D: -0.47454914450645447, loss G: -0.2251778542995453\n",
      "Epoch [7/10] Batch [147/469] Loss D: -0.539453387260437, loss G: -0.23987135291099548\n",
      "Epoch [7/10] Batch [148/469] Loss D: -0.5296441316604614, loss G: -0.1403554528951645\n",
      "Epoch [7/10] Batch [149/469] Loss D: -0.5324909090995789, loss G: -0.34124335646629333\n",
      "Epoch [7/10] Batch [150/469] Loss D: -0.4018781781196594, loss G: -0.14020970463752747\n",
      "Epoch [7/10] Batch [151/469] Loss D: -0.47751814126968384, loss G: -0.1954757273197174\n",
      "Epoch [7/10] Batch [152/469] Loss D: -0.5285881757736206, loss G: -0.2432364523410797\n",
      "Epoch [7/10] Batch [153/469] Loss D: -0.4855732023715973, loss G: -0.1273622214794159\n",
      "Epoch [7/10] Batch [154/469] Loss D: -0.4124005436897278, loss G: -0.3109159767627716\n",
      "Epoch [7/10] Batch [155/469] Loss D: -0.4584220051765442, loss G: -0.17124135792255402\n",
      "Epoch [7/10] Batch [156/469] Loss D: -0.4908873736858368, loss G: -0.2703387439250946\n",
      "Epoch [7/10] Batch [157/469] Loss D: -0.4774320125579834, loss G: -0.09723043441772461\n",
      "Epoch [7/10] Batch [158/469] Loss D: -0.5440793037414551, loss G: -0.30051106214523315\n",
      "Epoch [7/10] Batch [159/469] Loss D: -0.47262102365493774, loss G: -0.1331442892551422\n",
      "Epoch [7/10] Batch [160/469] Loss D: -0.5026473999023438, loss G: -0.3557364046573639\n",
      "Epoch [7/10] Batch [161/469] Loss D: -0.5013920068740845, loss G: -0.06509445607662201\n",
      "Epoch [7/10] Batch [162/469] Loss D: -0.47199171781539917, loss G: -0.3294958174228668\n",
      "Epoch [7/10] Batch [163/469] Loss D: -0.4824117124080658, loss G: -0.11626044660806656\n",
      "Epoch [7/10] Batch [164/469] Loss D: -0.47463110089302063, loss G: -0.3011325001716614\n",
      "Epoch [7/10] Batch [165/469] Loss D: -0.462118536233902, loss G: -0.14259976148605347\n",
      "Epoch [7/10] Batch [166/469] Loss D: -0.4436039328575134, loss G: -0.29976046085357666\n",
      "Epoch [7/10] Batch [167/469] Loss D: -0.49307262897491455, loss G: -0.07417693734169006\n",
      "Epoch [7/10] Batch [168/469] Loss D: -0.3735484778881073, loss G: -0.29806581139564514\n",
      "Epoch [7/10] Batch [169/469] Loss D: -0.4602106809616089, loss G: -0.17698191106319427\n",
      "Epoch [7/10] Batch [170/469] Loss D: -0.4582308828830719, loss G: -0.22230735421180725\n",
      "Epoch [7/10] Batch [171/469] Loss D: -0.49386829137802124, loss G: -0.22821329534053802\n",
      "Epoch [7/10] Batch [172/469] Loss D: -0.5819153785705566, loss G: -0.07640348374843597\n",
      "Epoch [7/10] Batch [173/469] Loss D: -0.49558374285697937, loss G: -0.39927181601524353\n",
      "Epoch [7/10] Batch [174/469] Loss D: -0.43342530727386475, loss G: -0.08394388109445572\n",
      "Epoch [7/10] Batch [175/469] Loss D: -0.434889554977417, loss G: -0.26978790760040283\n",
      "Epoch [7/10] Batch [176/469] Loss D: -0.5728668570518494, loss G: -0.13515618443489075\n",
      "Epoch [7/10] Batch [177/469] Loss D: -0.5782822966575623, loss G: -0.10366461426019669\n",
      "Epoch [7/10] Batch [178/469] Loss D: -0.48281797766685486, loss G: -0.37953078746795654\n",
      "Epoch [7/10] Batch [179/469] Loss D: -0.44421303272247314, loss G: -0.07041998952627182\n",
      "Epoch [7/10] Batch [180/469] Loss D: -0.44717392325401306, loss G: -0.2668246328830719\n",
      "Epoch [7/10] Batch [181/469] Loss D: -0.5132323503494263, loss G: -0.23012933135032654\n",
      "Epoch [7/10] Batch [182/469] Loss D: -0.5794565677642822, loss G: -0.03776185214519501\n",
      "Epoch [7/10] Batch [183/469] Loss D: -0.5272495746612549, loss G: -0.32429975271224976\n",
      "Epoch [7/10] Batch [184/469] Loss D: -0.5142761468887329, loss G: -0.17472997307777405\n",
      "Epoch [7/10] Batch [185/469] Loss D: -0.48925912380218506, loss G: -0.10438021272420883\n",
      "Epoch [7/10] Batch [186/469] Loss D: -0.5279250144958496, loss G: -0.3575235605239868\n",
      "Epoch [7/10] Batch [187/469] Loss D: -0.49785417318344116, loss G: -0.1952238380908966\n",
      "Epoch [7/10] Batch [188/469] Loss D: -0.5534448623657227, loss G: -0.13945084810256958\n",
      "Epoch [7/10] Batch [189/469] Loss D: -0.4934791624546051, loss G: -0.2744472026824951\n",
      "Epoch [7/10] Batch [190/469] Loss D: -0.4597609341144562, loss G: -0.21709267795085907\n",
      "Epoch [7/10] Batch [191/469] Loss D: -0.3970758318901062, loss G: -0.24094611406326294\n",
      "Epoch [7/10] Batch [192/469] Loss D: -0.4564219117164612, loss G: -0.2517220973968506\n",
      "Epoch [7/10] Batch [193/469] Loss D: -0.44794708490371704, loss G: -0.16209843754768372\n",
      "Epoch [7/10] Batch [194/469] Loss D: -0.413096159696579, loss G: -0.277727335691452\n",
      "Epoch [7/10] Batch [195/469] Loss D: -0.47104692459106445, loss G: -0.19336438179016113\n",
      "Epoch [7/10] Batch [196/469] Loss D: -0.5526734590530396, loss G: -0.09531466662883759\n",
      "Epoch [7/10] Batch [197/469] Loss D: -0.5636316537857056, loss G: -0.43230682611465454\n",
      "Epoch [7/10] Batch [198/469] Loss D: -0.39302247762680054, loss G: -0.15254424512386322\n",
      "Epoch [7/10] Batch [199/469] Loss D: -0.5202288031578064, loss G: -0.09169263392686844\n",
      "Epoch [7/10] Batch [200/469] Loss D: -0.47198933362960815, loss G: -0.35699766874313354\n",
      "Epoch [7/10] Batch [201/469] Loss D: -0.356649249792099, loss G: -0.24261854588985443\n",
      "Epoch [7/10] Batch [202/469] Loss D: -0.5302075147628784, loss G: -0.13313540816307068\n",
      "Epoch [7/10] Batch [203/469] Loss D: -0.5606071949005127, loss G: -0.16069380939006805\n",
      "Epoch [7/10] Batch [204/469] Loss D: -0.5418440103530884, loss G: -0.2549595832824707\n",
      "Epoch [7/10] Batch [205/469] Loss D: -0.4928571581840515, loss G: -0.1461019217967987\n",
      "Epoch [7/10] Batch [206/469] Loss D: -0.5492232441902161, loss G: -0.32598263025283813\n",
      "Epoch [7/10] Batch [207/469] Loss D: -0.4608134329319, loss G: -0.04585482180118561\n",
      "Epoch [7/10] Batch [208/469] Loss D: -0.446506530046463, loss G: -0.18657433986663818\n",
      "Epoch [7/10] Batch [209/469] Loss D: -0.47832590341567993, loss G: -0.36789610981941223\n",
      "Epoch [7/10] Batch [210/469] Loss D: -0.3830025792121887, loss G: -0.1747046709060669\n",
      "Epoch [7/10] Batch [211/469] Loss D: -0.5309286117553711, loss G: -0.2228955626487732\n",
      "Epoch [7/10] Batch [212/469] Loss D: -0.5555211305618286, loss G: -0.1720319539308548\n",
      "Epoch [7/10] Batch [213/469] Loss D: -0.5600953698158264, loss G: -0.07911580801010132\n",
      "Epoch [7/10] Batch [214/469] Loss D: -0.3242366313934326, loss G: -0.3808463215827942\n",
      "Epoch [7/10] Batch [215/469] Loss D: -0.48290085792541504, loss G: -0.1596982181072235\n",
      "Epoch [7/10] Batch [216/469] Loss D: -0.46762847900390625, loss G: -0.1684006154537201\n",
      "Epoch [7/10] Batch [217/469] Loss D: -0.5183797478675842, loss G: -0.33858606219291687\n",
      "Epoch [7/10] Batch [218/469] Loss D: -0.47211843729019165, loss G: -0.11147060990333557\n",
      "Epoch [7/10] Batch [219/469] Loss D: -0.43715670704841614, loss G: -0.2870924770832062\n",
      "Epoch [7/10] Batch [220/469] Loss D: -0.5253944396972656, loss G: -0.16268551349639893\n",
      "Epoch [7/10] Batch [221/469] Loss D: -0.49750712513923645, loss G: -0.22368009388446808\n",
      "Epoch [7/10] Batch [222/469] Loss D: -0.511277973651886, loss G: -0.14439448714256287\n",
      "Epoch [7/10] Batch [223/469] Loss D: -0.4054504930973053, loss G: -0.2665015757083893\n",
      "Epoch [7/10] Batch [224/469] Loss D: -0.541168749332428, loss G: -0.1286005824804306\n",
      "Epoch [7/10] Batch [225/469] Loss D: -0.4668624699115753, loss G: -0.2995953857898712\n",
      "Epoch [7/10] Batch [226/469] Loss D: -0.4741995334625244, loss G: -0.16096585988998413\n",
      "Epoch [7/10] Batch [227/469] Loss D: -0.5433428287506104, loss G: -0.19306139647960663\n",
      "Epoch [7/10] Batch [228/469] Loss D: -0.4934208393096924, loss G: -0.23260733485221863\n",
      "Epoch [7/10] Batch [229/469] Loss D: -0.4252713918685913, loss G: -0.17827653884887695\n",
      "Epoch [7/10] Batch [230/469] Loss D: -0.4183271527290344, loss G: -0.3617735505104065\n",
      "Epoch [7/10] Batch [231/469] Loss D: -0.4394899606704712, loss G: -0.11603213846683502\n",
      "Epoch [7/10] Batch [232/469] Loss D: -0.4500170350074768, loss G: -0.3384149670600891\n",
      "Epoch [7/10] Batch [233/469] Loss D: -0.49265673756599426, loss G: -0.17240431904792786\n",
      "Epoch [7/10] Batch [234/469] Loss D: -0.4744836688041687, loss G: -0.10438147187232971\n",
      "Epoch [7/10] Batch [235/469] Loss D: -0.4422694742679596, loss G: -0.3191717267036438\n",
      "Epoch [7/10] Batch [236/469] Loss D: -0.44973307847976685, loss G: -0.20799899101257324\n",
      "Epoch [7/10] Batch [237/469] Loss D: -0.5427652597427368, loss G: -0.14753806591033936\n",
      "Epoch [7/10] Batch [238/469] Loss D: -0.5727524161338806, loss G: -0.3465161919593811\n",
      "Epoch [7/10] Batch [239/469] Loss D: -0.4226682186126709, loss G: -0.13910150527954102\n",
      "Epoch [7/10] Batch [240/469] Loss D: -0.5065267086029053, loss G: -0.2124079167842865\n",
      "Epoch [7/10] Batch [241/469] Loss D: -0.517601490020752, loss G: -0.18708054721355438\n",
      "Epoch [7/10] Batch [242/469] Loss D: -0.42183130979537964, loss G: -0.18069547414779663\n",
      "Epoch [7/10] Batch [243/469] Loss D: -0.5574103593826294, loss G: -0.17897450923919678\n",
      "Epoch [7/10] Batch [244/469] Loss D: -0.46616077423095703, loss G: -0.3048359751701355\n",
      "Epoch [7/10] Batch [245/469] Loss D: -0.5645599961280823, loss G: -0.08218556642532349\n",
      "Epoch [7/10] Batch [246/469] Loss D: -0.4669276475906372, loss G: -0.3462824821472168\n",
      "Epoch [7/10] Batch [247/469] Loss D: -0.4547485411167145, loss G: -0.09646263718605042\n",
      "Epoch [7/10] Batch [248/469] Loss D: -0.3786751925945282, loss G: -0.2260068655014038\n",
      "Epoch [7/10] Batch [249/469] Loss D: -0.46860551834106445, loss G: -0.25579845905303955\n",
      "Epoch [7/10] Batch [250/469] Loss D: -0.5038838386535645, loss G: -0.1789718121290207\n",
      "Epoch [7/10] Batch [251/469] Loss D: -0.5108799338340759, loss G: -0.23075322806835175\n",
      "Epoch [7/10] Batch [252/469] Loss D: -0.5269598364830017, loss G: -0.1217871606349945\n",
      "Epoch [7/10] Batch [253/469] Loss D: -0.4231509864330292, loss G: -0.3068540692329407\n",
      "Epoch [7/10] Batch [254/469] Loss D: -0.42969024181365967, loss G: -0.14053350687026978\n",
      "Epoch [7/10] Batch [255/469] Loss D: -0.5121562480926514, loss G: -0.18230146169662476\n",
      "Epoch [7/10] Batch [256/469] Loss D: -0.5326169729232788, loss G: -0.24026337265968323\n",
      "Epoch [7/10] Batch [257/469] Loss D: -0.5365654826164246, loss G: -0.201646089553833\n",
      "Epoch [7/10] Batch [258/469] Loss D: -0.6424817442893982, loss G: -0.08035403490066528\n",
      "Epoch [7/10] Batch [259/469] Loss D: -0.4500533640384674, loss G: -0.40684401988983154\n",
      "Epoch [7/10] Batch [260/469] Loss D: -0.5242272019386292, loss G: -0.07562261819839478\n",
      "Epoch [7/10] Batch [261/469] Loss D: -0.42432039976119995, loss G: -0.34133148193359375\n",
      "Epoch [7/10] Batch [262/469] Loss D: -0.4257238507270813, loss G: -0.17897644639015198\n",
      "Epoch [7/10] Batch [263/469] Loss D: -0.4997478723526001, loss G: -0.2780945301055908\n",
      "Epoch [7/10] Batch [264/469] Loss D: -0.44040006399154663, loss G: -0.13606345653533936\n",
      "Epoch [7/10] Batch [265/469] Loss D: -0.5522323250770569, loss G: -0.25885266065597534\n",
      "Epoch [7/10] Batch [266/469] Loss D: -0.5496443510055542, loss G: -0.12732279300689697\n",
      "Epoch [7/10] Batch [267/469] Loss D: -0.4922674894332886, loss G: -0.25939300656318665\n",
      "Epoch [7/10] Batch [268/469] Loss D: -0.4621216654777527, loss G: -0.13505080342292786\n",
      "Epoch [7/10] Batch [269/469] Loss D: -0.49236226081848145, loss G: -0.343156099319458\n",
      "Epoch [7/10] Batch [270/469] Loss D: -0.35879141092300415, loss G: -0.30386286973953247\n",
      "Epoch [7/10] Batch [271/469] Loss D: -0.49313220381736755, loss G: -0.07208309322595596\n",
      "Epoch [7/10] Batch [272/469] Loss D: -0.38139012455940247, loss G: -0.4033057987689972\n",
      "Epoch [7/10] Batch [273/469] Loss D: -0.4554527997970581, loss G: -0.15015527606010437\n",
      "Epoch [7/10] Batch [274/469] Loss D: -0.4890173673629761, loss G: -0.20509466528892517\n",
      "Epoch [7/10] Batch [275/469] Loss D: -0.5476462244987488, loss G: -0.290063738822937\n",
      "Epoch [7/10] Batch [276/469] Loss D: -0.44644153118133545, loss G: -0.11161214113235474\n",
      "Epoch [7/10] Batch [277/469] Loss D: -0.490852952003479, loss G: -0.3374711871147156\n",
      "Epoch [7/10] Batch [278/469] Loss D: -0.422255277633667, loss G: -0.18254142999649048\n",
      "Epoch [7/10] Batch [279/469] Loss D: -0.46751219034194946, loss G: -0.20529958605766296\n",
      "Epoch [7/10] Batch [280/469] Loss D: -0.4723823368549347, loss G: -0.20825015008449554\n",
      "Epoch [7/10] Batch [281/469] Loss D: -0.44801706075668335, loss G: -0.22638751566410065\n",
      "Epoch [7/10] Batch [282/469] Loss D: -0.5368912220001221, loss G: -0.16358360648155212\n",
      "Epoch [7/10] Batch [283/469] Loss D: -0.467907190322876, loss G: -0.27197784185409546\n",
      "Epoch [7/10] Batch [284/469] Loss D: -0.4961259365081787, loss G: -0.18260672688484192\n",
      "Epoch [7/10] Batch [285/469] Loss D: -0.4749000072479248, loss G: -0.1678524613380432\n",
      "Epoch [7/10] Batch [286/469] Loss D: -0.4757092595100403, loss G: -0.39379268884658813\n",
      "Epoch [7/10] Batch [287/469] Loss D: -0.40861713886260986, loss G: -0.17257148027420044\n",
      "Epoch [7/10] Batch [288/469] Loss D: -0.5065383315086365, loss G: -0.14067038893699646\n",
      "Epoch [7/10] Batch [289/469] Loss D: -0.5393775105476379, loss G: -0.32351893186569214\n",
      "Epoch [7/10] Batch [290/469] Loss D: -0.49068617820739746, loss G: -0.16191667318344116\n",
      "Epoch [7/10] Batch [291/469] Loss D: -0.5316811800003052, loss G: -0.11774908006191254\n",
      "Epoch [7/10] Batch [292/469] Loss D: -0.401591420173645, loss G: -0.4971734881401062\n",
      "Epoch [7/10] Batch [293/469] Loss D: -0.35131120681762695, loss G: -0.27354180812835693\n",
      "Epoch [7/10] Batch [294/469] Loss D: -0.5305258631706238, loss G: -0.03676951676607132\n",
      "Epoch [7/10] Batch [295/469] Loss D: -0.3871620297431946, loss G: -0.31402307748794556\n",
      "Epoch [7/10] Batch [296/469] Loss D: -0.4278540015220642, loss G: -0.3255227208137512\n",
      "Epoch [7/10] Batch [297/469] Loss D: -0.5017387866973877, loss G: -0.08651840686798096\n",
      "Epoch [7/10] Batch [298/469] Loss D: -0.5453697443008423, loss G: -0.28675299882888794\n",
      "Epoch [7/10] Batch [299/469] Loss D: -0.41930967569351196, loss G: -0.21373358368873596\n",
      "Epoch [7/10] Batch [300/469] Loss D: -0.5038484334945679, loss G: -0.07566702365875244\n",
      "Epoch [7/10] Batch [301/469] Loss D: -0.32212942838668823, loss G: -0.26382845640182495\n",
      "Epoch [7/10] Batch [302/469] Loss D: -0.45934852957725525, loss G: -0.3238106966018677\n",
      "Epoch [7/10] Batch [303/469] Loss D: -0.4796290397644043, loss G: -0.15075068175792694\n",
      "Epoch [7/10] Batch [304/469] Loss D: -0.529356062412262, loss G: -0.1690434217453003\n",
      "Epoch [7/10] Batch [305/469] Loss D: -0.44972607493400574, loss G: -0.2561543881893158\n",
      "Epoch [7/10] Batch [306/469] Loss D: -0.5476301908493042, loss G: -0.16313979029655457\n",
      "Epoch [7/10] Batch [307/469] Loss D: -0.47426432371139526, loss G: -0.1849677711725235\n",
      "Epoch [7/10] Batch [308/469] Loss D: -0.5348179340362549, loss G: -0.23837700486183167\n",
      "Epoch [7/10] Batch [309/469] Loss D: -0.5062413215637207, loss G: -0.08821944892406464\n",
      "Epoch [7/10] Batch [310/469] Loss D: -0.4617164731025696, loss G: -0.3324534595012665\n",
      "Epoch [7/10] Batch [311/469] Loss D: -0.48433858156204224, loss G: -0.10063334554433823\n",
      "Epoch [7/10] Batch [312/469] Loss D: -0.3965211510658264, loss G: -0.30683600902557373\n",
      "Epoch [7/10] Batch [313/469] Loss D: -0.5065402984619141, loss G: -0.1705321967601776\n",
      "Epoch [7/10] Batch [314/469] Loss D: -0.45830512046813965, loss G: -0.16897869110107422\n",
      "Epoch [7/10] Batch [315/469] Loss D: -0.5338876247406006, loss G: -0.2565084397792816\n",
      "Epoch [7/10] Batch [316/469] Loss D: -0.4958708882331848, loss G: -0.1902860552072525\n",
      "Epoch [7/10] Batch [317/469] Loss D: -0.4486190378665924, loss G: -0.2504222095012665\n",
      "Epoch [7/10] Batch [318/469] Loss D: -0.5288779139518738, loss G: -0.09885069727897644\n",
      "Epoch [7/10] Batch [319/469] Loss D: -0.44884511828422546, loss G: -0.31712621450424194\n",
      "Epoch [7/10] Batch [320/469] Loss D: -0.5297514200210571, loss G: -0.12408816814422607\n",
      "Epoch [7/10] Batch [321/469] Loss D: -0.5461922883987427, loss G: -0.22844532132148743\n",
      "Epoch [7/10] Batch [322/469] Loss D: -0.5041848421096802, loss G: -0.11701713502407074\n",
      "Epoch [7/10] Batch [323/469] Loss D: -0.3901252746582031, loss G: -0.37530285120010376\n",
      "Epoch [7/10] Batch [324/469] Loss D: -0.4298630654811859, loss G: -0.15805800259113312\n",
      "Epoch [7/10] Batch [325/469] Loss D: -0.5535157918930054, loss G: -0.18257322907447815\n",
      "Epoch [7/10] Batch [326/469] Loss D: -0.586471438407898, loss G: -0.1453385055065155\n",
      "Epoch [7/10] Batch [327/469] Loss D: -0.5490665435791016, loss G: -0.27312204241752625\n",
      "Epoch [7/10] Batch [328/469] Loss D: -0.48173487186431885, loss G: -0.12866204977035522\n",
      "Epoch [7/10] Batch [329/469] Loss D: -0.5568280816078186, loss G: -0.22275975346565247\n",
      "Epoch [7/10] Batch [330/469] Loss D: -0.5272588133811951, loss G: -0.2560790479183197\n",
      "Epoch [7/10] Batch [331/469] Loss D: -0.49958691000938416, loss G: -0.1362404078245163\n",
      "Epoch [7/10] Batch [332/469] Loss D: -0.5415670871734619, loss G: -0.22317443788051605\n",
      "Epoch [7/10] Batch [333/469] Loss D: -0.5185794830322266, loss G: -0.16654467582702637\n",
      "Epoch [7/10] Batch [334/469] Loss D: -0.5154799818992615, loss G: -0.29565706849098206\n",
      "Epoch [7/10] Batch [335/469] Loss D: -0.46448835730552673, loss G: -0.17031916975975037\n",
      "Epoch [7/10] Batch [336/469] Loss D: -0.46149009466171265, loss G: -0.19532117247581482\n",
      "Epoch [7/10] Batch [337/469] Loss D: -0.4621899127960205, loss G: -0.3535565435886383\n",
      "Epoch [7/10] Batch [338/469] Loss D: -0.4473017752170563, loss G: -0.11452195048332214\n",
      "Epoch [7/10] Batch [339/469] Loss D: -0.4904802441596985, loss G: -0.23029634356498718\n",
      "Epoch [7/10] Batch [340/469] Loss D: -0.5174365043640137, loss G: -0.14353425800800323\n",
      "Epoch [7/10] Batch [341/469] Loss D: -0.47056713700294495, loss G: -0.24190759658813477\n",
      "Epoch [7/10] Batch [342/469] Loss D: -0.5433703064918518, loss G: -0.1379719078540802\n",
      "Epoch [7/10] Batch [343/469] Loss D: -0.4912935495376587, loss G: -0.3127630352973938\n",
      "Epoch [7/10] Batch [344/469] Loss D: -0.44172021746635437, loss G: -0.21283461153507233\n",
      "Epoch [7/10] Batch [345/469] Loss D: -0.5503189563751221, loss G: -0.1401578187942505\n",
      "Epoch [7/10] Batch [346/469] Loss D: -0.486925333738327, loss G: -0.2784069776535034\n",
      "Epoch [7/10] Batch [347/469] Loss D: -0.5269554853439331, loss G: -0.17193672060966492\n",
      "Epoch [7/10] Batch [348/469] Loss D: -0.5143966674804688, loss G: -0.18983222544193268\n",
      "Epoch [7/10] Batch [349/469] Loss D: -0.49776729941368103, loss G: -0.2593710422515869\n",
      "Epoch [7/10] Batch [350/469] Loss D: -0.48088109493255615, loss G: -0.11532621085643768\n",
      "Epoch [7/10] Batch [351/469] Loss D: -0.5463387370109558, loss G: -0.32713109254837036\n",
      "Epoch [7/10] Batch [352/469] Loss D: -0.480946809053421, loss G: -0.16818681359291077\n",
      "Epoch [7/10] Batch [353/469] Loss D: -0.45913124084472656, loss G: -0.15038767457008362\n",
      "Epoch [7/10] Batch [354/469] Loss D: -0.442804217338562, loss G: -0.3747445344924927\n",
      "Epoch [7/10] Batch [355/469] Loss D: -0.5100246667861938, loss G: -0.11959075927734375\n",
      "Epoch [7/10] Batch [356/469] Loss D: -0.49493592977523804, loss G: -0.16616284847259521\n",
      "Epoch [7/10] Batch [357/469] Loss D: -0.4772951602935791, loss G: -0.30337435007095337\n",
      "Epoch [7/10] Batch [358/469] Loss D: -0.46823742985725403, loss G: -0.14909617602825165\n",
      "Epoch [7/10] Batch [359/469] Loss D: -0.5480108261108398, loss G: -0.11019496619701385\n",
      "Epoch [7/10] Batch [360/469] Loss D: -0.43989595770835876, loss G: -0.3729434013366699\n",
      "Epoch [7/10] Batch [361/469] Loss D: -0.5020678043365479, loss G: -0.0613073855638504\n",
      "Epoch [7/10] Batch [362/469] Loss D: -0.3944227993488312, loss G: -0.27982234954833984\n",
      "Epoch [7/10] Batch [363/469] Loss D: -0.47390902042388916, loss G: -0.34081846475601196\n",
      "Epoch [7/10] Batch [364/469] Loss D: -0.47647565603256226, loss G: -0.135595440864563\n",
      "Epoch [7/10] Batch [365/469] Loss D: -0.4257464110851288, loss G: -0.2296692430973053\n",
      "Epoch [7/10] Batch [366/469] Loss D: -0.5488792061805725, loss G: -0.12476938962936401\n",
      "Epoch [7/10] Batch [367/469] Loss D: -0.48530495166778564, loss G: -0.38012826442718506\n",
      "Epoch [7/10] Batch [368/469] Loss D: -0.42863741517066956, loss G: -0.11485366523265839\n",
      "Epoch [7/10] Batch [369/469] Loss D: -0.5097472071647644, loss G: -0.3639306426048279\n",
      "Epoch [7/10] Batch [370/469] Loss D: -0.39927011728286743, loss G: -0.18342572450637817\n",
      "Epoch [7/10] Batch [371/469] Loss D: -0.5353792905807495, loss G: -0.13322696089744568\n",
      "Epoch [7/10] Batch [372/469] Loss D: -0.515153706073761, loss G: -0.40213680267333984\n",
      "Epoch [7/10] Batch [373/469] Loss D: -0.4567866325378418, loss G: -0.1288226842880249\n",
      "Epoch [7/10] Batch [374/469] Loss D: -0.5324952006340027, loss G: -0.18801459670066833\n",
      "Epoch [7/10] Batch [375/469] Loss D: -0.5690233707427979, loss G: -0.17599019408226013\n",
      "Epoch [7/10] Batch [376/469] Loss D: -0.48030683398246765, loss G: -0.2764393091201782\n",
      "Epoch [7/10] Batch [377/469] Loss D: -0.4691654145717621, loss G: -0.10951055586338043\n",
      "Epoch [7/10] Batch [378/469] Loss D: -0.437102347612381, loss G: -0.3386717140674591\n",
      "Epoch [7/10] Batch [379/469] Loss D: -0.4617905914783478, loss G: -0.18431653082370758\n",
      "Epoch [7/10] Batch [380/469] Loss D: -0.5293278694152832, loss G: -0.11362309753894806\n",
      "Epoch [7/10] Batch [381/469] Loss D: -0.4815046787261963, loss G: -0.42038142681121826\n",
      "Epoch [7/10] Batch [382/469] Loss D: -0.4780583381652832, loss G: -0.14820997416973114\n",
      "Epoch [7/10] Batch [383/469] Loss D: -0.5669208765029907, loss G: -0.09888903796672821\n",
      "Epoch [7/10] Batch [384/469] Loss D: -0.5140554904937744, loss G: -0.34645092487335205\n",
      "Epoch [7/10] Batch [385/469] Loss D: -0.46614596247673035, loss G: -0.1517057716846466\n",
      "Epoch [7/10] Batch [386/469] Loss D: -0.5317160487174988, loss G: -0.16825726628303528\n",
      "Epoch [7/10] Batch [387/469] Loss D: -0.5368109941482544, loss G: -0.2511579394340515\n",
      "Epoch [7/10] Batch [388/469] Loss D: -0.5688040852546692, loss G: -0.12138336151838303\n",
      "Epoch [7/10] Batch [389/469] Loss D: -0.49802401661872864, loss G: -0.25964459776878357\n",
      "Epoch [7/10] Batch [390/469] Loss D: -0.5031956434249878, loss G: -0.12783870100975037\n",
      "Epoch [7/10] Batch [391/469] Loss D: -0.5055450201034546, loss G: -0.2903873026371002\n",
      "Epoch [7/10] Batch [392/469] Loss D: -0.4941384196281433, loss G: -0.13135360181331635\n",
      "Epoch [7/10] Batch [393/469] Loss D: -0.4909532964229584, loss G: -0.29841095209121704\n",
      "Epoch [7/10] Batch [394/469] Loss D: -0.4916728138923645, loss G: -0.17693427205085754\n",
      "Epoch [7/10] Batch [395/469] Loss D: -0.5194998979568481, loss G: -0.17291051149368286\n",
      "Epoch [7/10] Batch [396/469] Loss D: -0.601564884185791, loss G: -0.26487916707992554\n",
      "Epoch [7/10] Batch [397/469] Loss D: -0.3994540572166443, loss G: -0.17467939853668213\n",
      "Epoch [7/10] Batch [398/469] Loss D: -0.5650188326835632, loss G: -0.14644521474838257\n",
      "Epoch [7/10] Batch [399/469] Loss D: -0.52275151014328, loss G: -0.25825372338294983\n",
      "Epoch [7/10] Batch [400/469] Loss D: -0.5187333822250366, loss G: -0.13863928616046906\n",
      "Epoch [7/10] Batch [401/469] Loss D: -0.4730060398578644, loss G: -0.2060873657464981\n",
      "Epoch [7/10] Batch [402/469] Loss D: -0.46186161041259766, loss G: -0.21071645617485046\n",
      "Epoch [7/10] Batch [403/469] Loss D: -0.43796807527542114, loss G: -0.24099309742450714\n",
      "Epoch [7/10] Batch [404/469] Loss D: -0.5845121741294861, loss G: -0.10360550880432129\n",
      "Epoch [7/10] Batch [405/469] Loss D: -0.4516527056694031, loss G: -0.3878139853477478\n",
      "Epoch [7/10] Batch [406/469] Loss D: -0.4879201352596283, loss G: -0.14083951711654663\n",
      "Epoch [7/10] Batch [407/469] Loss D: -0.5221623778343201, loss G: -0.15611043572425842\n",
      "Epoch [7/10] Batch [408/469] Loss D: -0.5576357245445251, loss G: -0.3052864670753479\n",
      "Epoch [7/10] Batch [409/469] Loss D: -0.4992902874946594, loss G: -0.10652266442775726\n",
      "Epoch [7/10] Batch [410/469] Loss D: -0.588242769241333, loss G: -0.17430630326271057\n",
      "Epoch [7/10] Batch [411/469] Loss D: -0.5059033632278442, loss G: -0.1907481849193573\n",
      "Epoch [7/10] Batch [412/469] Loss D: -0.5053020715713501, loss G: -0.31876659393310547\n",
      "Epoch [7/10] Batch [413/469] Loss D: -0.5595275163650513, loss G: -0.10173530876636505\n",
      "Epoch [7/10] Batch [414/469] Loss D: -0.5265425443649292, loss G: -0.3069261312484741\n",
      "Epoch [7/10] Batch [415/469] Loss D: -0.4291972517967224, loss G: -0.20219546556472778\n",
      "Epoch [7/10] Batch [416/469] Loss D: -0.5467538833618164, loss G: -0.11130097508430481\n",
      "Epoch [7/10] Batch [417/469] Loss D: -0.4024578630924225, loss G: -0.3390747010707855\n",
      "Epoch [7/10] Batch [418/469] Loss D: -0.5189517140388489, loss G: -0.10362190008163452\n",
      "Epoch [7/10] Batch [419/469] Loss D: -0.5015546083450317, loss G: -0.3447849750518799\n",
      "Epoch [7/10] Batch [420/469] Loss D: -0.47050830721855164, loss G: -0.09354419261217117\n",
      "Epoch [7/10] Batch [421/469] Loss D: -0.5038342475891113, loss G: -0.3059549927711487\n",
      "Epoch [7/10] Batch [422/469] Loss D: -0.448363721370697, loss G: -0.2719065546989441\n",
      "Epoch [7/10] Batch [423/469] Loss D: -0.46226394176483154, loss G: -0.11811274290084839\n",
      "Epoch [7/10] Batch [424/469] Loss D: -0.47550132870674133, loss G: -0.3038911819458008\n",
      "Epoch [7/10] Batch [425/469] Loss D: -0.5082481503486633, loss G: -0.1220163106918335\n",
      "Epoch [7/10] Batch [426/469] Loss D: -0.492153137922287, loss G: -0.31792277097702026\n",
      "Epoch [7/10] Batch [427/469] Loss D: -0.4351930320262909, loss G: -0.2116272747516632\n",
      "Epoch [7/10] Batch [428/469] Loss D: -0.4621141254901886, loss G: -0.23988977074623108\n",
      "Epoch [7/10] Batch [429/469] Loss D: -0.5140957832336426, loss G: -0.12059493362903595\n",
      "Epoch [7/10] Batch [430/469] Loss D: -0.4979745149612427, loss G: -0.2726094722747803\n",
      "Epoch [7/10] Batch [431/469] Loss D: -0.46643590927124023, loss G: -0.13984176516532898\n",
      "Epoch [7/10] Batch [432/469] Loss D: -0.46363773941993713, loss G: -0.32866013050079346\n",
      "Epoch [7/10] Batch [433/469] Loss D: -0.49827852845191956, loss G: -0.174773707985878\n",
      "Epoch [7/10] Batch [434/469] Loss D: -0.48820099234580994, loss G: -0.16029080748558044\n",
      "Epoch [7/10] Batch [435/469] Loss D: -0.5910579562187195, loss G: -0.19302943348884583\n",
      "Epoch [7/10] Batch [436/469] Loss D: -0.4810633361339569, loss G: -0.24524912238121033\n",
      "Epoch [7/10] Batch [437/469] Loss D: -0.4505596160888672, loss G: -0.15417639911174774\n",
      "Epoch [7/10] Batch [438/469] Loss D: -0.569072425365448, loss G: -0.22422809898853302\n",
      "Epoch [7/10] Batch [439/469] Loss D: -0.4884057343006134, loss G: -0.2473803609609604\n",
      "Epoch [7/10] Batch [440/469] Loss D: -0.4933425784111023, loss G: -0.19871170818805695\n",
      "Epoch [7/10] Batch [441/469] Loss D: -0.47257813811302185, loss G: -0.12723371386528015\n",
      "Epoch [7/10] Batch [442/469] Loss D: -0.6294656991958618, loss G: -0.09087271243333817\n",
      "Epoch [7/10] Batch [443/469] Loss D: -0.5127121210098267, loss G: -0.414346307516098\n",
      "Epoch [7/10] Batch [444/469] Loss D: -0.4715682864189148, loss G: -0.12131613492965698\n",
      "Epoch [7/10] Batch [445/469] Loss D: -0.5664651989936829, loss G: -0.13095876574516296\n",
      "Epoch [7/10] Batch [446/469] Loss D: -0.6090492606163025, loss G: -0.24884362518787384\n",
      "Epoch [7/10] Batch [447/469] Loss D: -0.49653542041778564, loss G: -0.13557013869285583\n",
      "Epoch [7/10] Batch [448/469] Loss D: -0.4834291934967041, loss G: -0.28920483589172363\n",
      "Epoch [7/10] Batch [449/469] Loss D: -0.37615254521369934, loss G: -0.18811088800430298\n",
      "Epoch [7/10] Batch [450/469] Loss D: -0.49301469326019287, loss G: -0.26126813888549805\n",
      "Epoch [7/10] Batch [451/469] Loss D: -0.4677252769470215, loss G: -0.15685002505779266\n",
      "Epoch [7/10] Batch [452/469] Loss D: -0.5451114177703857, loss G: -0.29165202379226685\n",
      "Epoch [7/10] Batch [453/469] Loss D: -0.5044064521789551, loss G: -0.06991411000490189\n",
      "Epoch [7/10] Batch [454/469] Loss D: -0.4760099947452545, loss G: -0.35161808133125305\n",
      "Epoch [7/10] Batch [455/469] Loss D: -0.4859048128128052, loss G: -0.09277357161045074\n",
      "Epoch [7/10] Batch [456/469] Loss D: -0.4625574052333832, loss G: -0.2560983896255493\n",
      "Epoch [7/10] Batch [457/469] Loss D: -0.5613955855369568, loss G: -0.27487486600875854\n",
      "Epoch [7/10] Batch [458/469] Loss D: -0.5356999039649963, loss G: -0.05414271354675293\n",
      "Epoch [7/10] Batch [459/469] Loss D: -0.3902052640914917, loss G: -0.2609793543815613\n",
      "Epoch [7/10] Batch [460/469] Loss D: -0.5314322710037231, loss G: -0.21466436982154846\n",
      "Epoch [7/10] Batch [461/469] Loss D: -0.5230909585952759, loss G: -0.05319806933403015\n",
      "Epoch [7/10] Batch [462/469] Loss D: -0.4083266258239746, loss G: -0.26211920380592346\n",
      "Epoch [7/10] Batch [463/469] Loss D: -0.45612502098083496, loss G: -0.2121478170156479\n",
      "Epoch [7/10] Batch [464/469] Loss D: -0.5659493803977966, loss G: -0.06818318367004395\n",
      "Epoch [7/10] Batch [465/469] Loss D: -0.40196168422698975, loss G: -0.3154100179672241\n",
      "Epoch [7/10] Batch [466/469] Loss D: -0.4981159567832947, loss G: -0.11693007498979568\n",
      "Epoch [7/10] Batch [467/469] Loss D: -0.5241348147392273, loss G: -0.3080829977989197\n",
      "Epoch [7/10] Batch [468/469] Loss D: -0.4783490300178528, loss G: -0.16666527092456818\n",
      "Epoch [7/10] Batch [469/469] Loss D: -0.5460806488990784, loss G: -0.15906578302383423\n",
      "Epoch [8/10] Batch [1/469] Loss D: -0.5524340271949768, loss G: -0.2102394700050354\n",
      "Epoch [8/10] Batch [2/469] Loss D: -0.4442099928855896, loss G: -0.1754971593618393\n",
      "Epoch [8/10] Batch [3/469] Loss D: -0.5227845311164856, loss G: -0.2762136459350586\n",
      "Epoch [8/10] Batch [4/469] Loss D: -0.519878625869751, loss G: -0.1821363866329193\n",
      "Epoch [8/10] Batch [5/469] Loss D: -0.4117395877838135, loss G: -0.19184795022010803\n",
      "Epoch [8/10] Batch [6/469] Loss D: -0.44555866718292236, loss G: -0.28152403235435486\n",
      "Epoch [8/10] Batch [7/469] Loss D: -0.5117590427398682, loss G: -0.16511550545692444\n",
      "Epoch [8/10] Batch [8/469] Loss D: -0.5502948760986328, loss G: -0.16647064685821533\n",
      "Epoch [8/10] Batch [9/469] Loss D: -0.5171982049942017, loss G: -0.24421446025371552\n",
      "Epoch [8/10] Batch [10/469] Loss D: -0.48644182085990906, loss G: -0.13270995020866394\n",
      "Epoch [8/10] Batch [11/469] Loss D: -0.4067153334617615, loss G: -0.3799857497215271\n",
      "Epoch [8/10] Batch [12/469] Loss D: -0.44770336151123047, loss G: -0.17759168148040771\n",
      "Epoch [8/10] Batch [13/469] Loss D: -0.5241716504096985, loss G: -0.2190798819065094\n",
      "Epoch [8/10] Batch [14/469] Loss D: -0.441203773021698, loss G: -0.24056877195835114\n",
      "Epoch [8/10] Batch [15/469] Loss D: -0.5365468859672546, loss G: -0.08438242226839066\n",
      "Epoch [8/10] Batch [16/469] Loss D: -0.4544227719306946, loss G: -0.35743188858032227\n",
      "Epoch [8/10] Batch [17/469] Loss D: -0.47118833661079407, loss G: -0.1248399019241333\n",
      "Epoch [8/10] Batch [18/469] Loss D: -0.4271682798862457, loss G: -0.2976497411727905\n",
      "Epoch [8/10] Batch [19/469] Loss D: -0.5015228986740112, loss G: -0.16572587192058563\n",
      "Epoch [8/10] Batch [20/469] Loss D: -0.43746817111968994, loss G: -0.25007641315460205\n",
      "Epoch [8/10] Batch [21/469] Loss D: -0.529867947101593, loss G: -0.18139736354351044\n",
      "Epoch [8/10] Batch [22/469] Loss D: -0.5172411799430847, loss G: -0.21041756868362427\n",
      "Epoch [8/10] Batch [23/469] Loss D: -0.5274745225906372, loss G: -0.20110198855400085\n",
      "Epoch [8/10] Batch [24/469] Loss D: -0.5253003239631653, loss G: -0.17895087599754333\n",
      "Epoch [8/10] Batch [25/469] Loss D: -0.5729058980941772, loss G: -0.11866006255149841\n",
      "Epoch [8/10] Batch [26/469] Loss D: -0.5697882175445557, loss G: -0.17106422781944275\n",
      "Epoch [8/10] Batch [27/469] Loss D: -0.5760859251022339, loss G: -0.18741999566555023\n",
      "Epoch [8/10] Batch [28/469] Loss D: -0.600014865398407, loss G: -0.1398683786392212\n",
      "Epoch [8/10] Batch [29/469] Loss D: -0.5177739858627319, loss G: -0.13290782272815704\n",
      "Epoch [8/10] Batch [30/469] Loss D: -0.4161957800388336, loss G: -0.2704778015613556\n",
      "Epoch [8/10] Batch [31/469] Loss D: -0.4668859839439392, loss G: -0.2250608205795288\n",
      "Epoch [8/10] Batch [32/469] Loss D: -0.4306281805038452, loss G: -0.17191708087921143\n",
      "Epoch [8/10] Batch [33/469] Loss D: -0.4757336676120758, loss G: -0.2617899179458618\n",
      "Epoch [8/10] Batch [34/469] Loss D: -0.4989527463912964, loss G: -0.1410197764635086\n",
      "Epoch [8/10] Batch [35/469] Loss D: -0.5468037724494934, loss G: -0.26878535747528076\n",
      "Epoch [8/10] Batch [36/469] Loss D: -0.48358994722366333, loss G: -0.12245262414216995\n",
      "Epoch [8/10] Batch [37/469] Loss D: -0.5105960369110107, loss G: -0.24741485714912415\n",
      "Epoch [8/10] Batch [38/469] Loss D: -0.5502898693084717, loss G: -0.14244510233402252\n",
      "Epoch [8/10] Batch [39/469] Loss D: -0.5158390998840332, loss G: -0.2581135630607605\n",
      "Epoch [8/10] Batch [40/469] Loss D: -0.5308119058609009, loss G: -0.12145357578992844\n",
      "Epoch [8/10] Batch [41/469] Loss D: -0.541646420955658, loss G: -0.22784046828746796\n",
      "Epoch [8/10] Batch [42/469] Loss D: -0.4484105706214905, loss G: -0.2718640863895416\n",
      "Epoch [8/10] Batch [43/469] Loss D: -0.5098607540130615, loss G: -0.0685657262802124\n",
      "Epoch [8/10] Batch [44/469] Loss D: -0.4468200206756592, loss G: -0.3547315001487732\n",
      "Epoch [8/10] Batch [45/469] Loss D: -0.536264181137085, loss G: -0.12143684923648834\n",
      "Epoch [8/10] Batch [46/469] Loss D: -0.5197272300720215, loss G: -0.17058280110359192\n",
      "Epoch [8/10] Batch [47/469] Loss D: -0.5841187238693237, loss G: -0.20248593389987946\n",
      "Epoch [8/10] Batch [48/469] Loss D: -0.47965335845947266, loss G: -0.16340702772140503\n",
      "Epoch [8/10] Batch [49/469] Loss D: -0.4432753920555115, loss G: -0.2703489065170288\n",
      "Epoch [8/10] Batch [50/469] Loss D: -0.4536111354827881, loss G: -0.2367417812347412\n",
      "Epoch [8/10] Batch [51/469] Loss D: -0.5297686457633972, loss G: -0.13823643326759338\n",
      "Epoch [8/10] Batch [52/469] Loss D: -0.5069981813430786, loss G: -0.3530694246292114\n",
      "Epoch [8/10] Batch [53/469] Loss D: -0.4424009919166565, loss G: -0.12189068645238876\n",
      "Epoch [8/10] Batch [54/469] Loss D: -0.5801202058792114, loss G: -0.18072132766246796\n",
      "Epoch [8/10] Batch [55/469] Loss D: -0.48204851150512695, loss G: -0.3122119903564453\n",
      "Epoch [8/10] Batch [56/469] Loss D: -0.4788658320903778, loss G: -0.11334719508886337\n",
      "Epoch [8/10] Batch [57/469] Loss D: -0.5347640514373779, loss G: -0.22797219455242157\n",
      "Epoch [8/10] Batch [58/469] Loss D: -0.501862645149231, loss G: -0.19516250491142273\n",
      "Epoch [8/10] Batch [59/469] Loss D: -0.5603653192520142, loss G: -0.1277645379304886\n",
      "Epoch [8/10] Batch [60/469] Loss D: -0.49209272861480713, loss G: -0.2317880541086197\n",
      "Epoch [8/10] Batch [61/469] Loss D: -0.5405609607696533, loss G: -0.11167359352111816\n",
      "Epoch [8/10] Batch [62/469] Loss D: -0.5676980018615723, loss G: -0.2761172354221344\n",
      "Epoch [8/10] Batch [63/469] Loss D: -0.4744340777397156, loss G: -0.18039722740650177\n",
      "Epoch [8/10] Batch [64/469] Loss D: -0.5342666506767273, loss G: -0.23013484477996826\n",
      "Epoch [8/10] Batch [65/469] Loss D: -0.48580479621887207, loss G: -0.20171359181404114\n",
      "Epoch [8/10] Batch [66/469] Loss D: -0.5964930057525635, loss G: -0.15565070509910583\n",
      "Epoch [8/10] Batch [67/469] Loss D: -0.5235253572463989, loss G: -0.2039453685283661\n",
      "Epoch [8/10] Batch [68/469] Loss D: -0.5277595520019531, loss G: -0.2325344681739807\n",
      "Epoch [8/10] Batch [69/469] Loss D: -0.5412917137145996, loss G: -0.13207730650901794\n",
      "Epoch [8/10] Batch [70/469] Loss D: -0.4813806116580963, loss G: -0.27566754817962646\n",
      "Epoch [8/10] Batch [71/469] Loss D: -0.5108533501625061, loss G: -0.15058079361915588\n",
      "Epoch [8/10] Batch [72/469] Loss D: -0.5198590755462646, loss G: -0.2572256028652191\n",
      "Epoch [8/10] Batch [73/469] Loss D: -0.526419997215271, loss G: -0.12375646084547043\n",
      "Epoch [8/10] Batch [74/469] Loss D: -0.44232410192489624, loss G: -0.26784074306488037\n",
      "Epoch [8/10] Batch [75/469] Loss D: -0.5416613817214966, loss G: -0.22158485651016235\n",
      "Epoch [8/10] Batch [76/469] Loss D: -0.5325263738632202, loss G: -0.13848496973514557\n",
      "Epoch [8/10] Batch [77/469] Loss D: -0.6149696111679077, loss G: -0.17173144221305847\n",
      "Epoch [8/10] Batch [78/469] Loss D: -0.4867978096008301, loss G: -0.34513676166534424\n",
      "Epoch [8/10] Batch [79/469] Loss D: -0.47154903411865234, loss G: -0.09566110372543335\n",
      "Epoch [8/10] Batch [80/469] Loss D: -0.5327585935592651, loss G: -0.18304724991321564\n",
      "Epoch [8/10] Batch [81/469] Loss D: -0.5416806936264038, loss G: -0.3264838755130768\n",
      "Epoch [8/10] Batch [82/469] Loss D: -0.5024546980857849, loss G: -0.08395986258983612\n",
      "Epoch [8/10] Batch [83/469] Loss D: -0.4306563138961792, loss G: -0.290897399187088\n",
      "Epoch [8/10] Batch [84/469] Loss D: -0.4963003993034363, loss G: -0.17034095525741577\n",
      "Epoch [8/10] Batch [85/469] Loss D: -0.4492700695991516, loss G: -0.24336981773376465\n",
      "Epoch [8/10] Batch [86/469] Loss D: -0.5705150961875916, loss G: -0.16438359022140503\n",
      "Epoch [8/10] Batch [87/469] Loss D: -0.5254775285720825, loss G: -0.17098861932754517\n",
      "Epoch [8/10] Batch [88/469] Loss D: -0.5670486688613892, loss G: -0.18727484345436096\n",
      "Epoch [8/10] Batch [89/469] Loss D: -0.6154173612594604, loss G: -0.134048193693161\n",
      "Epoch [8/10] Batch [90/469] Loss D: -0.5567867755889893, loss G: -0.2672373950481415\n",
      "Epoch [8/10] Batch [91/469] Loss D: -0.512543797492981, loss G: -0.0848182886838913\n",
      "Epoch [8/10] Batch [92/469] Loss D: -0.4780292809009552, loss G: -0.3059072494506836\n",
      "Epoch [8/10] Batch [93/469] Loss D: -0.4977138042449951, loss G: -0.15333515405654907\n",
      "Epoch [8/10] Batch [94/469] Loss D: -0.5931976437568665, loss G: -0.16423487663269043\n",
      "Epoch [8/10] Batch [95/469] Loss D: -0.5252903699874878, loss G: -0.20544256269931793\n",
      "Epoch [8/10] Batch [96/469] Loss D: -0.5473103523254395, loss G: -0.18128027021884918\n",
      "Epoch [8/10] Batch [97/469] Loss D: -0.5410622358322144, loss G: -0.1468014419078827\n",
      "Epoch [8/10] Batch [98/469] Loss D: -0.5196434259414673, loss G: -0.2636471390724182\n",
      "Epoch [8/10] Batch [99/469] Loss D: -0.5675421357154846, loss G: -0.07615430653095245\n",
      "Epoch [8/10] Batch [100/469] Loss D: -0.5263302326202393, loss G: -0.2781243324279785\n",
      "Epoch [8/10] Batch [101/469] Loss D: -0.5796025395393372, loss G: -0.09510685503482819\n",
      "Epoch [8/10] Batch [102/469] Loss D: -0.4939157962799072, loss G: -0.35971054434776306\n",
      "Epoch [8/10] Batch [103/469] Loss D: -0.46383458375930786, loss G: -0.04127912223339081\n",
      "Epoch [8/10] Batch [104/469] Loss D: -0.28613513708114624, loss G: -0.21339181065559387\n",
      "Epoch [8/10] Batch [105/469] Loss D: -0.5661621689796448, loss G: -0.21212245523929596\n",
      "Epoch [8/10] Batch [106/469] Loss D: -0.5316510200500488, loss G: -0.1316710114479065\n",
      "Epoch [8/10] Batch [107/469] Loss D: -0.5494024753570557, loss G: -0.24914336204528809\n",
      "Epoch [8/10] Batch [108/469] Loss D: -0.5016294717788696, loss G: -0.11195886135101318\n",
      "Epoch [8/10] Batch [109/469] Loss D: -0.5790055394172668, loss G: -0.1905931830406189\n",
      "Epoch [8/10] Batch [110/469] Loss D: -0.6036115884780884, loss G: -0.12979915738105774\n",
      "Epoch [8/10] Batch [111/469] Loss D: -0.5534385442733765, loss G: -0.2445862591266632\n",
      "Epoch [8/10] Batch [112/469] Loss D: -0.47119706869125366, loss G: -0.1283906102180481\n",
      "Epoch [8/10] Batch [113/469] Loss D: -0.4773578941822052, loss G: -0.23791715502738953\n",
      "Epoch [8/10] Batch [114/469] Loss D: -0.4739260971546173, loss G: -0.20952461659908295\n",
      "Epoch [8/10] Batch [115/469] Loss D: -0.5908499956130981, loss G: -0.045494195073843\n",
      "Epoch [8/10] Batch [116/469] Loss D: -0.43905237317085266, loss G: -0.42628002166748047\n",
      "Epoch [8/10] Batch [117/469] Loss D: -0.47839415073394775, loss G: -0.18506455421447754\n",
      "Epoch [8/10] Batch [118/469] Loss D: -0.5594087839126587, loss G: -0.08468308299779892\n",
      "Epoch [8/10] Batch [119/469] Loss D: -0.5132433772087097, loss G: -0.272592157125473\n",
      "Epoch [8/10] Batch [120/469] Loss D: -0.4878304600715637, loss G: -0.2354508340358734\n",
      "Epoch [8/10] Batch [121/469] Loss D: -0.567345917224884, loss G: -0.133668452501297\n",
      "Epoch [8/10] Batch [122/469] Loss D: -0.5054032802581787, loss G: -0.2578091025352478\n",
      "Epoch [8/10] Batch [123/469] Loss D: -0.5502248406410217, loss G: -0.15584294497966766\n",
      "Epoch [8/10] Batch [124/469] Loss D: -0.4720236659049988, loss G: -0.21434199810028076\n",
      "Epoch [8/10] Batch [125/469] Loss D: -0.5807621479034424, loss G: -0.1944166123867035\n",
      "Epoch [8/10] Batch [126/469] Loss D: -0.5435405373573303, loss G: -0.15921133756637573\n",
      "Epoch [8/10] Batch [127/469] Loss D: -0.5364893674850464, loss G: -0.2324446141719818\n",
      "Epoch [8/10] Batch [128/469] Loss D: -0.5430100560188293, loss G: -0.1877404749393463\n",
      "Epoch [8/10] Batch [129/469] Loss D: -0.592125654220581, loss G: -0.1257486641407013\n",
      "Epoch [8/10] Batch [130/469] Loss D: -0.6155177354812622, loss G: -0.15435177087783813\n",
      "Epoch [8/10] Batch [131/469] Loss D: -0.6213973760604858, loss G: -0.10812994837760925\n",
      "Epoch [8/10] Batch [132/469] Loss D: -0.5206049680709839, loss G: -0.42738449573516846\n",
      "Epoch [8/10] Batch [133/469] Loss D: -0.3759043216705322, loss G: -0.10561852157115936\n",
      "Epoch [8/10] Batch [134/469] Loss D: -0.4534366726875305, loss G: -0.19504864513874054\n",
      "Epoch [8/10] Batch [135/469] Loss D: -0.4902390241622925, loss G: -0.2938687801361084\n",
      "Epoch [8/10] Batch [136/469] Loss D: -0.4950507879257202, loss G: -0.10911351442337036\n",
      "Epoch [8/10] Batch [137/469] Loss D: -0.4508682191371918, loss G: -0.33896273374557495\n",
      "Epoch [8/10] Batch [138/469] Loss D: -0.518513560295105, loss G: -0.13696745038032532\n",
      "Epoch [8/10] Batch [139/469] Loss D: -0.4813287854194641, loss G: -0.1944696456193924\n",
      "Epoch [8/10] Batch [140/469] Loss D: -0.5332664251327515, loss G: -0.12828579545021057\n",
      "Epoch [8/10] Batch [141/469] Loss D: -0.5318602323532104, loss G: -0.2653023600578308\n",
      "Epoch [8/10] Batch [142/469] Loss D: -0.5294798612594604, loss G: -0.09861606359481812\n",
      "Epoch [8/10] Batch [143/469] Loss D: -0.5143694877624512, loss G: -0.2651504576206207\n",
      "Epoch [8/10] Batch [144/469] Loss D: -0.4495471119880676, loss G: -0.2550772428512573\n",
      "Epoch [8/10] Batch [145/469] Loss D: -0.585108757019043, loss G: -0.08326155692338943\n",
      "Epoch [8/10] Batch [146/469] Loss D: -0.5344476699829102, loss G: -0.25547581911087036\n",
      "Epoch [8/10] Batch [147/469] Loss D: -0.575486421585083, loss G: -0.13531376421451569\n",
      "Epoch [8/10] Batch [148/469] Loss D: -0.547573447227478, loss G: -0.20470647513866425\n",
      "Epoch [8/10] Batch [149/469] Loss D: -0.5746749043464661, loss G: -0.159300297498703\n",
      "Epoch [8/10] Batch [150/469] Loss D: -0.5231192111968994, loss G: -0.2531840205192566\n",
      "Epoch [8/10] Batch [151/469] Loss D: -0.47140783071517944, loss G: -0.12335449457168579\n",
      "Epoch [8/10] Batch [152/469] Loss D: -0.5251730680465698, loss G: -0.3374693989753723\n",
      "Epoch [8/10] Batch [153/469] Loss D: -0.45550838112831116, loss G: -0.1553545594215393\n",
      "Epoch [8/10] Batch [154/469] Loss D: -0.5083107948303223, loss G: -0.1833096593618393\n",
      "Epoch [8/10] Batch [155/469] Loss D: -0.5289015769958496, loss G: -0.36116155982017517\n",
      "Epoch [8/10] Batch [156/469] Loss D: -0.47552114725112915, loss G: -0.12462279945611954\n",
      "Epoch [8/10] Batch [157/469] Loss D: -0.5158677101135254, loss G: -0.19041180610656738\n",
      "Epoch [8/10] Batch [158/469] Loss D: -0.5233339667320251, loss G: -0.28891265392303467\n",
      "Epoch [8/10] Batch [159/469] Loss D: -0.499977707862854, loss G: -0.09686842560768127\n",
      "Epoch [8/10] Batch [160/469] Loss D: -0.5852215886116028, loss G: -0.211073100566864\n",
      "Epoch [8/10] Batch [161/469] Loss D: -0.5786621570587158, loss G: -0.276536226272583\n",
      "Epoch [8/10] Batch [162/469] Loss D: -0.4784972667694092, loss G: -0.1384148895740509\n",
      "Epoch [8/10] Batch [163/469] Loss D: -0.5440696477890015, loss G: -0.14393995702266693\n",
      "Epoch [8/10] Batch [164/469] Loss D: -0.4777984321117401, loss G: -0.3725297152996063\n",
      "Epoch [8/10] Batch [165/469] Loss D: -0.41472750902175903, loss G: -0.09526292979717255\n",
      "Epoch [8/10] Batch [166/469] Loss D: -0.47781994938850403, loss G: -0.3345942497253418\n",
      "Epoch [8/10] Batch [167/469] Loss D: -0.47502341866493225, loss G: -0.14559966325759888\n",
      "Epoch [8/10] Batch [168/469] Loss D: -0.5434963703155518, loss G: -0.24784967303276062\n",
      "Epoch [8/10] Batch [169/469] Loss D: -0.5090607404708862, loss G: -0.19644105434417725\n",
      "Epoch [8/10] Batch [170/469] Loss D: -0.5460207462310791, loss G: -0.08470280468463898\n",
      "Epoch [8/10] Batch [171/469] Loss D: -0.5626601576805115, loss G: -0.29697129130363464\n",
      "Epoch [8/10] Batch [172/469] Loss D: -0.520278811454773, loss G: -0.11180049926042557\n",
      "Epoch [8/10] Batch [173/469] Loss D: -0.5010601282119751, loss G: -0.2302241325378418\n",
      "Epoch [8/10] Batch [174/469] Loss D: -0.5880098342895508, loss G: -0.15651114284992218\n",
      "Epoch [8/10] Batch [175/469] Loss D: -0.5548287630081177, loss G: -0.15873566269874573\n",
      "Epoch [8/10] Batch [176/469] Loss D: -0.5583983659744263, loss G: -0.1748325526714325\n",
      "Epoch [8/10] Batch [177/469] Loss D: -0.5926741361618042, loss G: -0.14387018978595734\n",
      "Epoch [8/10] Batch [178/469] Loss D: -0.5403751134872437, loss G: -0.2774572968482971\n",
      "Epoch [8/10] Batch [179/469] Loss D: -0.5365595817565918, loss G: -0.09552057087421417\n",
      "Epoch [8/10] Batch [180/469] Loss D: -0.5082207918167114, loss G: -0.30985647439956665\n",
      "Epoch [8/10] Batch [181/469] Loss D: -0.5136651396751404, loss G: -0.12700778245925903\n",
      "Epoch [8/10] Batch [182/469] Loss D: -0.6101466417312622, loss G: -0.06926968693733215\n",
      "Epoch [8/10] Batch [183/469] Loss D: -0.4023113250732422, loss G: -0.5499218702316284\n",
      "Epoch [8/10] Batch [184/469] Loss D: -0.3473946452140808, loss G: -0.13175995647907257\n",
      "Epoch [8/10] Batch [185/469] Loss D: -0.5922857522964478, loss G: -0.16104871034622192\n",
      "Epoch [8/10] Batch [186/469] Loss D: -0.5413532257080078, loss G: -0.21829776465892792\n",
      "Epoch [8/10] Batch [187/469] Loss D: -0.5115289092063904, loss G: -0.14667142927646637\n",
      "Epoch [8/10] Batch [188/469] Loss D: -0.5302641987800598, loss G: -0.2012278139591217\n",
      "Epoch [8/10] Batch [189/469] Loss D: -0.5413028001785278, loss G: -0.26686030626296997\n",
      "Epoch [8/10] Batch [190/469] Loss D: -0.5966671705245972, loss G: -0.11018045246601105\n",
      "Epoch [8/10] Batch [191/469] Loss D: -0.46293526887893677, loss G: -0.3020156919956207\n",
      "Epoch [8/10] Batch [192/469] Loss D: -0.5333297848701477, loss G: -0.11235566437244415\n",
      "Epoch [8/10] Batch [193/469] Loss D: -0.49792933464050293, loss G: -0.3203519880771637\n",
      "Epoch [8/10] Batch [194/469] Loss D: -0.5555009245872498, loss G: -0.10654938966035843\n",
      "Epoch [8/10] Batch [195/469] Loss D: -0.49830788373947144, loss G: -0.3146899342536926\n",
      "Epoch [8/10] Batch [196/469] Loss D: -0.505306601524353, loss G: -0.15083928406238556\n",
      "Epoch [8/10] Batch [197/469] Loss D: -0.5125030279159546, loss G: -0.1480948030948639\n",
      "Epoch [8/10] Batch [198/469] Loss D: -0.5688928365707397, loss G: -0.1880471110343933\n",
      "Epoch [8/10] Batch [199/469] Loss D: -0.5617244243621826, loss G: -0.1987738162279129\n",
      "Epoch [8/10] Batch [200/469] Loss D: -0.4917125999927521, loss G: -0.14554931223392487\n",
      "Epoch [8/10] Batch [201/469] Loss D: -0.4379532039165497, loss G: -0.3770614266395569\n",
      "Epoch [8/10] Batch [202/469] Loss D: -0.4589043855667114, loss G: -0.23676587641239166\n",
      "Epoch [8/10] Batch [203/469] Loss D: -0.5514757633209229, loss G: -0.061595551669597626\n",
      "Epoch [8/10] Batch [204/469] Loss D: -0.3628999590873718, loss G: -0.27616435289382935\n",
      "Epoch [8/10] Batch [205/469] Loss D: -0.4837538003921509, loss G: -0.20512697100639343\n",
      "Epoch [8/10] Batch [206/469] Loss D: -0.5326203107833862, loss G: -0.1552191525697708\n",
      "Epoch [8/10] Batch [207/469] Loss D: -0.49488139152526855, loss G: -0.276420533657074\n",
      "Epoch [8/10] Batch [208/469] Loss D: -0.5016728639602661, loss G: -0.12180132418870926\n",
      "Epoch [8/10] Batch [209/469] Loss D: -0.5010753273963928, loss G: -0.20333677530288696\n",
      "Epoch [8/10] Batch [210/469] Loss D: -0.6324305534362793, loss G: -0.08509885519742966\n",
      "Epoch [8/10] Batch [211/469] Loss D: -0.5404212474822998, loss G: -0.2752060890197754\n",
      "Epoch [8/10] Batch [212/469] Loss D: -0.5430147647857666, loss G: -0.13029751181602478\n",
      "Epoch [8/10] Batch [213/469] Loss D: -0.515029788017273, loss G: -0.1894090622663498\n",
      "Epoch [8/10] Batch [214/469] Loss D: -0.6250932216644287, loss G: -0.1712312400341034\n",
      "Epoch [8/10] Batch [215/469] Loss D: -0.549068808555603, loss G: -0.2295084148645401\n",
      "Epoch [8/10] Batch [216/469] Loss D: -0.5417838096618652, loss G: -0.11460106074810028\n",
      "Epoch [8/10] Batch [217/469] Loss D: -0.48563623428344727, loss G: -0.3875264525413513\n",
      "Epoch [8/10] Batch [218/469] Loss D: -0.4514901638031006, loss G: -0.07846476882696152\n",
      "Epoch [8/10] Batch [219/469] Loss D: -0.36689019203186035, loss G: -0.2503066658973694\n",
      "Epoch [8/10] Batch [220/469] Loss D: -0.48511916399002075, loss G: -0.253520131111145\n",
      "Epoch [8/10] Batch [221/469] Loss D: -0.551524817943573, loss G: -0.12718766927719116\n",
      "Epoch [8/10] Batch [222/469] Loss D: -0.5385996103286743, loss G: -0.2386421263217926\n",
      "Epoch [8/10] Batch [223/469] Loss D: -0.5049635171890259, loss G: -0.19481834769248962\n",
      "Epoch [8/10] Batch [224/469] Loss D: -0.6048753261566162, loss G: -0.09509122371673584\n",
      "Epoch [8/10] Batch [225/469] Loss D: -0.5170985460281372, loss G: -0.30838334560394287\n",
      "Epoch [8/10] Batch [226/469] Loss D: -0.5239127278327942, loss G: -0.11186172813177109\n",
      "Epoch [8/10] Batch [227/469] Loss D: -0.5575302839279175, loss G: -0.12456989288330078\n",
      "Epoch [8/10] Batch [228/469] Loss D: -0.48461592197418213, loss G: -0.43268778920173645\n",
      "Epoch [8/10] Batch [229/469] Loss D: -0.36781519651412964, loss G: -0.18429172039031982\n",
      "Epoch [8/10] Batch [230/469] Loss D: -0.6099709272384644, loss G: -0.07788200676441193\n",
      "Epoch [8/10] Batch [231/469] Loss D: -0.5326322913169861, loss G: -0.3530075252056122\n",
      "Epoch [8/10] Batch [232/469] Loss D: -0.4755544066429138, loss G: -0.1502324640750885\n",
      "Epoch [8/10] Batch [233/469] Loss D: -0.5357117652893066, loss G: -0.2868116497993469\n",
      "Epoch [8/10] Batch [234/469] Loss D: -0.5084228515625, loss G: -0.08573751896619797\n",
      "Epoch [8/10] Batch [235/469] Loss D: -0.5126729011535645, loss G: -0.25382253527641296\n",
      "Epoch [8/10] Batch [236/469] Loss D: -0.5469824075698853, loss G: -0.1664648801088333\n",
      "Epoch [8/10] Batch [237/469] Loss D: -0.59070885181427, loss G: -0.1671554297208786\n",
      "Epoch [8/10] Batch [238/469] Loss D: -0.6396474838256836, loss G: -0.08965972810983658\n",
      "Epoch [8/10] Batch [239/469] Loss D: -0.5051729679107666, loss G: -0.3963277339935303\n",
      "Epoch [8/10] Batch [240/469] Loss D: -0.4390932321548462, loss G: -0.09934729337692261\n",
      "Epoch [8/10] Batch [241/469] Loss D: -0.5052125453948975, loss G: -0.24721771478652954\n",
      "Epoch [8/10] Batch [242/469] Loss D: -0.5162341594696045, loss G: -0.19953414797782898\n",
      "Epoch [8/10] Batch [243/469] Loss D: -0.5380656719207764, loss G: -0.09777940809726715\n",
      "Epoch [8/10] Batch [244/469] Loss D: -0.46918317675590515, loss G: -0.3762497901916504\n",
      "Epoch [8/10] Batch [245/469] Loss D: -0.43807217478752136, loss G: -0.1313071846961975\n",
      "Epoch [8/10] Batch [246/469] Loss D: -0.5999972820281982, loss G: -0.11116671562194824\n",
      "Epoch [8/10] Batch [247/469] Loss D: -0.5636825561523438, loss G: -0.3267090916633606\n",
      "Epoch [8/10] Batch [248/469] Loss D: -0.4919249415397644, loss G: -0.12972445785999298\n",
      "Epoch [8/10] Batch [249/469] Loss D: -0.5548217296600342, loss G: -0.16166892647743225\n",
      "Epoch [8/10] Batch [250/469] Loss D: -0.5526476502418518, loss G: -0.3177420496940613\n",
      "Epoch [8/10] Batch [251/469] Loss D: -0.3655175566673279, loss G: -0.17714211344718933\n",
      "Epoch [8/10] Batch [252/469] Loss D: -0.5102764368057251, loss G: -0.23713980615139008\n",
      "Epoch [8/10] Batch [253/469] Loss D: -0.5694378614425659, loss G: -0.23135609924793243\n",
      "Epoch [8/10] Batch [254/469] Loss D: -0.4789026975631714, loss G: -0.13992416858673096\n",
      "Epoch [8/10] Batch [255/469] Loss D: -0.600861668586731, loss G: -0.2333066761493683\n",
      "Epoch [8/10] Batch [256/469] Loss D: -0.47399669885635376, loss G: -0.19900019466876984\n",
      "Epoch [8/10] Batch [257/469] Loss D: -0.5690518617630005, loss G: -0.15557590126991272\n",
      "Epoch [8/10] Batch [258/469] Loss D: -0.6023942828178406, loss G: -0.33377763628959656\n",
      "Epoch [8/10] Batch [259/469] Loss D: -0.4733850359916687, loss G: -0.06315004080533981\n",
      "Epoch [8/10] Batch [260/469] Loss D: -0.3666195273399353, loss G: -0.22005707025527954\n",
      "Epoch [8/10] Batch [261/469] Loss D: -0.47709017992019653, loss G: -0.35098642110824585\n",
      "Epoch [8/10] Batch [262/469] Loss D: -0.48752695322036743, loss G: -0.07956917583942413\n",
      "Epoch [8/10] Batch [263/469] Loss D: -0.5119050145149231, loss G: -0.24959589540958405\n",
      "Epoch [8/10] Batch [264/469] Loss D: -0.5015776753425598, loss G: -0.27593356370925903\n",
      "Epoch [8/10] Batch [265/469] Loss D: -0.4930499792098999, loss G: -0.09886792302131653\n",
      "Epoch [8/10] Batch [266/469] Loss D: -0.46775633096694946, loss G: -0.30260902643203735\n",
      "Epoch [8/10] Batch [267/469] Loss D: -0.45427578687667847, loss G: -0.18631020188331604\n",
      "Epoch [8/10] Batch [268/469] Loss D: -0.5571798086166382, loss G: -0.15207460522651672\n",
      "Epoch [8/10] Batch [269/469] Loss D: -0.5455460548400879, loss G: -0.2663969397544861\n",
      "Epoch [8/10] Batch [270/469] Loss D: -0.4685739278793335, loss G: -0.08831579983234406\n",
      "Epoch [8/10] Batch [271/469] Loss D: -0.4407236576080322, loss G: -0.3137372136116028\n",
      "Epoch [8/10] Batch [272/469] Loss D: -0.514129638671875, loss G: -0.16413614153862\n",
      "Epoch [8/10] Batch [273/469] Loss D: -0.4452753961086273, loss G: -0.20654357969760895\n",
      "Epoch [8/10] Batch [274/469] Loss D: -0.5615438222885132, loss G: -0.1968555450439453\n",
      "Epoch [8/10] Batch [275/469] Loss D: -0.5683305263519287, loss G: -0.14195403456687927\n",
      "Epoch [8/10] Batch [276/469] Loss D: -0.5498937368392944, loss G: -0.224702388048172\n",
      "Epoch [8/10] Batch [277/469] Loss D: -0.5334115624427795, loss G: -0.1490572690963745\n",
      "Epoch [8/10] Batch [278/469] Loss D: -0.4931652545928955, loss G: -0.23238563537597656\n",
      "Epoch [8/10] Batch [279/469] Loss D: -0.5951374173164368, loss G: -0.14418132603168488\n",
      "Epoch [8/10] Batch [280/469] Loss D: -0.5988138914108276, loss G: -0.20846308767795563\n",
      "Epoch [8/10] Batch [281/469] Loss D: -0.5473661422729492, loss G: -0.1610339730978012\n",
      "Epoch [8/10] Batch [282/469] Loss D: -0.5329955816268921, loss G: -0.19130279123783112\n",
      "Epoch [8/10] Batch [283/469] Loss D: -0.5094001293182373, loss G: -0.2278788834810257\n",
      "Epoch [8/10] Batch [284/469] Loss D: -0.5894429683685303, loss G: -0.15829801559448242\n",
      "Epoch [8/10] Batch [285/469] Loss D: -0.5094934105873108, loss G: -0.30266955494880676\n",
      "Epoch [8/10] Batch [286/469] Loss D: -0.5964629650115967, loss G: -0.051396314054727554\n",
      "Epoch [8/10] Batch [287/469] Loss D: -0.49674224853515625, loss G: -0.38081789016723633\n",
      "Epoch [8/10] Batch [288/469] Loss D: -0.4275827407836914, loss G: -0.1569940447807312\n",
      "Epoch [8/10] Batch [289/469] Loss D: -0.4993845820426941, loss G: -0.23320356011390686\n",
      "Epoch [8/10] Batch [290/469] Loss D: -0.6077901124954224, loss G: -0.10904602706432343\n",
      "Epoch [8/10] Batch [291/469] Loss D: -0.5181872844696045, loss G: -0.2996239960193634\n",
      "Epoch [8/10] Batch [292/469] Loss D: -0.4471059739589691, loss G: -0.14702971279621124\n",
      "Epoch [8/10] Batch [293/469] Loss D: -0.5408872961997986, loss G: -0.19598309695720673\n",
      "Epoch [8/10] Batch [294/469] Loss D: -0.6106545329093933, loss G: -0.1815868467092514\n",
      "Epoch [8/10] Batch [295/469] Loss D: -0.5951564311981201, loss G: -0.20478704571723938\n",
      "Epoch [8/10] Batch [296/469] Loss D: -0.4932698607444763, loss G: -0.1742575615644455\n",
      "Epoch [8/10] Batch [297/469] Loss D: -0.5333187580108643, loss G: -0.15438878536224365\n",
      "Epoch [8/10] Batch [298/469] Loss D: -0.4894682466983795, loss G: -0.2325565218925476\n",
      "Epoch [8/10] Batch [299/469] Loss D: -0.5394542217254639, loss G: -0.14479082822799683\n",
      "Epoch [8/10] Batch [300/469] Loss D: -0.6118121147155762, loss G: -0.1659800410270691\n",
      "Epoch [8/10] Batch [301/469] Loss D: -0.5399529337882996, loss G: -0.2198568880558014\n",
      "Epoch [8/10] Batch [302/469] Loss D: -0.5822592973709106, loss G: -0.1654719114303589\n",
      "Epoch [8/10] Batch [303/469] Loss D: -0.5853785872459412, loss G: -0.12894165515899658\n",
      "Epoch [8/10] Batch [304/469] Loss D: -0.5495075583457947, loss G: -0.2635686993598938\n",
      "Epoch [8/10] Batch [305/469] Loss D: -0.5164227485656738, loss G: -0.10843582451343536\n",
      "Epoch [8/10] Batch [306/469] Loss D: -0.6022849082946777, loss G: -0.20154798030853271\n",
      "Epoch [8/10] Batch [307/469] Loss D: -0.5382505655288696, loss G: -0.21325992047786713\n",
      "Epoch [8/10] Batch [308/469] Loss D: -0.49186187982559204, loss G: -0.1705252081155777\n",
      "Epoch [8/10] Batch [309/469] Loss D: -0.620684027671814, loss G: -0.22158779203891754\n",
      "Epoch [8/10] Batch [310/469] Loss D: -0.5607640743255615, loss G: -0.05314768850803375\n",
      "Epoch [8/10] Batch [311/469] Loss D: -0.4092104136943817, loss G: -0.45809853076934814\n",
      "Epoch [8/10] Batch [312/469] Loss D: -0.3425792455673218, loss G: -0.32903456687927246\n",
      "Epoch [8/10] Batch [313/469] Loss D: -0.4701775908470154, loss G: -0.07651296257972717\n",
      "Epoch [8/10] Batch [314/469] Loss D: -0.4999208450317383, loss G: -0.32448357343673706\n",
      "Epoch [8/10] Batch [315/469] Loss D: -0.5177623629570007, loss G: -0.14609840512275696\n",
      "Epoch [8/10] Batch [316/469] Loss D: -0.5500010848045349, loss G: -0.13982728123664856\n",
      "Epoch [8/10] Batch [317/469] Loss D: -0.5761328935623169, loss G: -0.22391358017921448\n",
      "Epoch [8/10] Batch [318/469] Loss D: -0.4511668086051941, loss G: -0.17421527206897736\n",
      "Epoch [8/10] Batch [319/469] Loss D: -0.5866187810897827, loss G: -0.1835251748561859\n",
      "Epoch [8/10] Batch [320/469] Loss D: -0.5353341102600098, loss G: -0.30105262994766235\n",
      "Epoch [8/10] Batch [321/469] Loss D: -0.4680632948875427, loss G: -0.11801599711179733\n",
      "Epoch [8/10] Batch [322/469] Loss D: -0.5762016773223877, loss G: -0.222561776638031\n",
      "Epoch [8/10] Batch [323/469] Loss D: -0.6240390539169312, loss G: -0.13477447628974915\n",
      "Epoch [8/10] Batch [324/469] Loss D: -0.5409610867500305, loss G: -0.1054588109254837\n",
      "Epoch [8/10] Batch [325/469] Loss D: -0.4946444630622864, loss G: -0.3626699447631836\n",
      "Epoch [8/10] Batch [326/469] Loss D: -0.469568133354187, loss G: -0.1146264299750328\n",
      "Epoch [8/10] Batch [327/469] Loss D: -0.5477935075759888, loss G: -0.25982511043548584\n",
      "Epoch [8/10] Batch [328/469] Loss D: -0.48183226585388184, loss G: -0.14419890940189362\n",
      "Epoch [8/10] Batch [329/469] Loss D: -0.4993307590484619, loss G: -0.4214114546775818\n",
      "Epoch [8/10] Batch [330/469] Loss D: -0.4746967554092407, loss G: -0.12348555028438568\n",
      "Epoch [8/10] Batch [331/469] Loss D: -0.48005685210227966, loss G: -0.21110409498214722\n",
      "Epoch [8/10] Batch [332/469] Loss D: -0.6048890352249146, loss G: -0.17477460205554962\n",
      "Epoch [8/10] Batch [333/469] Loss D: -0.5094993114471436, loss G: -0.14686806499958038\n",
      "Epoch [8/10] Batch [334/469] Loss D: -0.5340214371681213, loss G: -0.15911614894866943\n",
      "Epoch [8/10] Batch [335/469] Loss D: -0.5401078462600708, loss G: -0.2579990029335022\n",
      "Epoch [8/10] Batch [336/469] Loss D: -0.49816739559173584, loss G: -0.1685938835144043\n",
      "Epoch [8/10] Batch [337/469] Loss D: -0.5207291841506958, loss G: -0.14239490032196045\n",
      "Epoch [8/10] Batch [338/469] Loss D: -0.5530483722686768, loss G: -0.21179836988449097\n",
      "Epoch [8/10] Batch [339/469] Loss D: -0.5458889007568359, loss G: -0.13320398330688477\n",
      "Epoch [8/10] Batch [340/469] Loss D: -0.5934596061706543, loss G: -0.22490303218364716\n",
      "Epoch [8/10] Batch [341/469] Loss D: -0.5778003931045532, loss G: -0.08647726476192474\n",
      "Epoch [8/10] Batch [342/469] Loss D: -0.5150743126869202, loss G: -0.3337900936603546\n",
      "Epoch [8/10] Batch [343/469] Loss D: -0.4995117783546448, loss G: -0.11219623684883118\n",
      "Epoch [8/10] Batch [344/469] Loss D: -0.49106651544570923, loss G: -0.19631072878837585\n",
      "Epoch [8/10] Batch [345/469] Loss D: -0.5146870613098145, loss G: -0.1952495276927948\n",
      "Epoch [8/10] Batch [346/469] Loss D: -0.589641273021698, loss G: -0.14447951316833496\n",
      "Epoch [8/10] Batch [347/469] Loss D: -0.5557858943939209, loss G: -0.22912518680095673\n",
      "Epoch [8/10] Batch [348/469] Loss D: -0.5503820776939392, loss G: -0.11607494950294495\n",
      "Epoch [8/10] Batch [349/469] Loss D: -0.5255619287490845, loss G: -0.20171350240707397\n",
      "Epoch [8/10] Batch [350/469] Loss D: -0.5861340761184692, loss G: -0.25946173071861267\n",
      "Epoch [8/10] Batch [351/469] Loss D: -0.5305770635604858, loss G: -0.10364910960197449\n",
      "Epoch [8/10] Batch [352/469] Loss D: -0.6200653314590454, loss G: -0.212971031665802\n",
      "Epoch [8/10] Batch [353/469] Loss D: -0.5915136337280273, loss G: -0.2853659689426422\n",
      "Epoch [8/10] Batch [354/469] Loss D: -0.54079669713974, loss G: -0.05124824494123459\n",
      "Epoch [8/10] Batch [355/469] Loss D: -0.44580864906311035, loss G: -0.28212085366249084\n",
      "Epoch [8/10] Batch [356/469] Loss D: -0.46949994564056396, loss G: -0.18598707020282745\n",
      "Epoch [8/10] Batch [357/469] Loss D: -0.47570228576660156, loss G: -0.2588796019554138\n",
      "Epoch [8/10] Batch [358/469] Loss D: -0.5008149147033691, loss G: -0.14567124843597412\n",
      "Epoch [8/10] Batch [359/469] Loss D: -0.5631417036056519, loss G: -0.24921399354934692\n",
      "Epoch [8/10] Batch [360/469] Loss D: -0.5893038511276245, loss G: -0.125389963388443\n",
      "Epoch [8/10] Batch [361/469] Loss D: -0.5063526034355164, loss G: -0.2568417191505432\n",
      "Epoch [8/10] Batch [362/469] Loss D: -0.5255417227745056, loss G: -0.2027667760848999\n",
      "Epoch [8/10] Batch [363/469] Loss D: -0.6063100099563599, loss G: -0.08135852217674255\n",
      "Epoch [8/10] Batch [364/469] Loss D: -0.529207706451416, loss G: -0.3315575122833252\n",
      "Epoch [8/10] Batch [365/469] Loss D: -0.5228092670440674, loss G: -0.10730601847171783\n",
      "Epoch [8/10] Batch [366/469] Loss D: -0.5551748871803284, loss G: -0.2173801064491272\n",
      "Epoch [8/10] Batch [367/469] Loss D: -0.48815590143203735, loss G: -0.20374558866024017\n",
      "Epoch [8/10] Batch [368/469] Loss D: -0.4397731423377991, loss G: -0.2876265347003937\n",
      "Epoch [8/10] Batch [369/469] Loss D: -0.5084007978439331, loss G: -0.11123041063547134\n",
      "Epoch [8/10] Batch [370/469] Loss D: -0.5660125017166138, loss G: -0.1910986602306366\n",
      "Epoch [8/10] Batch [371/469] Loss D: -0.542025089263916, loss G: -0.19970116019248962\n",
      "Epoch [8/10] Batch [372/469] Loss D: -0.566146731376648, loss G: -0.10876578092575073\n",
      "Epoch [8/10] Batch [373/469] Loss D: -0.5399259328842163, loss G: -0.21993231773376465\n",
      "Epoch [8/10] Batch [374/469] Loss D: -0.5754063725471497, loss G: -0.08865822106599808\n",
      "Epoch [8/10] Batch [375/469] Loss D: -0.5751549601554871, loss G: -0.3407297134399414\n",
      "Epoch [8/10] Batch [376/469] Loss D: -0.4781709909439087, loss G: -0.08011575043201447\n",
      "Epoch [8/10] Batch [377/469] Loss D: -0.4426802396774292, loss G: -0.21180470287799835\n",
      "Epoch [8/10] Batch [378/469] Loss D: -0.5369385480880737, loss G: -0.19528692960739136\n",
      "Epoch [8/10] Batch [379/469] Loss D: -0.5172209739685059, loss G: -0.0775008499622345\n",
      "Epoch [8/10] Batch [380/469] Loss D: -0.5563222169876099, loss G: -0.34227365255355835\n",
      "Epoch [8/10] Batch [381/469] Loss D: -0.444857656955719, loss G: -0.10762079805135727\n",
      "Epoch [8/10] Batch [382/469] Loss D: -0.5021210312843323, loss G: -0.2006298154592514\n",
      "Epoch [8/10] Batch [383/469] Loss D: -0.5701494812965393, loss G: -0.21827757358551025\n",
      "Epoch [8/10] Batch [384/469] Loss D: -0.5390426516532898, loss G: -0.15471282601356506\n",
      "Epoch [8/10] Batch [385/469] Loss D: -0.63974529504776, loss G: -0.09824765473604202\n",
      "Epoch [8/10] Batch [386/469] Loss D: -0.5520201921463013, loss G: -0.25879427790641785\n",
      "Epoch [8/10] Batch [387/469] Loss D: -0.5067110657691956, loss G: -0.17001932859420776\n",
      "Epoch [8/10] Batch [388/469] Loss D: -0.5801020264625549, loss G: -0.2559565305709839\n",
      "Epoch [8/10] Batch [389/469] Loss D: -0.42262929677963257, loss G: -0.13714057207107544\n",
      "Epoch [8/10] Batch [390/469] Loss D: -0.48404034972190857, loss G: -0.22616209089756012\n",
      "Epoch [8/10] Batch [391/469] Loss D: -0.6242610216140747, loss G: -0.12688320875167847\n",
      "Epoch [8/10] Batch [392/469] Loss D: -0.5178312659263611, loss G: -0.37938135862350464\n",
      "Epoch [8/10] Batch [393/469] Loss D: -0.4166743755340576, loss G: -0.1333431601524353\n",
      "Epoch [8/10] Batch [394/469] Loss D: -0.47219792008399963, loss G: -0.2444993257522583\n",
      "Epoch [8/10] Batch [395/469] Loss D: -0.5526445508003235, loss G: -0.13043758273124695\n",
      "Epoch [8/10] Batch [396/469] Loss D: -0.5017156600952148, loss G: -0.29884976148605347\n",
      "Epoch [8/10] Batch [397/469] Loss D: -0.5278087854385376, loss G: -0.08086202293634415\n",
      "Epoch [8/10] Batch [398/469] Loss D: -0.4057612419128418, loss G: -0.25834405422210693\n",
      "Epoch [8/10] Batch [399/469] Loss D: -0.5611633062362671, loss G: -0.1938389241695404\n",
      "Epoch [8/10] Batch [400/469] Loss D: -0.5052765607833862, loss G: -0.13548727333545685\n",
      "Epoch [8/10] Batch [401/469] Loss D: -0.5052657127380371, loss G: -0.3088214695453644\n",
      "Epoch [8/10] Batch [402/469] Loss D: -0.5309566855430603, loss G: -0.09211766719818115\n",
      "Epoch [8/10] Batch [403/469] Loss D: -0.5326584577560425, loss G: -0.23542527854442596\n",
      "Epoch [8/10] Batch [404/469] Loss D: -0.538813591003418, loss G: -0.1150122880935669\n",
      "Epoch [8/10] Batch [405/469] Loss D: -0.5070769190788269, loss G: -0.2836959958076477\n",
      "Epoch [8/10] Batch [406/469] Loss D: -0.5592848062515259, loss G: -0.12448596954345703\n",
      "Epoch [8/10] Batch [407/469] Loss D: -0.48684775829315186, loss G: -0.2322753369808197\n",
      "Epoch [8/10] Batch [408/469] Loss D: -0.5501976013183594, loss G: -0.11553574353456497\n",
      "Epoch [8/10] Batch [409/469] Loss D: -0.5069926977157593, loss G: -0.2130918800830841\n",
      "Epoch [8/10] Batch [410/469] Loss D: -0.5315679311752319, loss G: -0.20926713943481445\n",
      "Epoch [8/10] Batch [411/469] Loss D: -0.5504716634750366, loss G: -0.1356341391801834\n",
      "Epoch [8/10] Batch [412/469] Loss D: -0.5333284735679626, loss G: -0.3476027250289917\n",
      "Epoch [8/10] Batch [413/469] Loss D: -0.40729016065597534, loss G: -0.0936107262969017\n",
      "Epoch [8/10] Batch [414/469] Loss D: -0.5252166986465454, loss G: -0.2099100649356842\n",
      "Epoch [8/10] Batch [415/469] Loss D: -0.5264503359794617, loss G: -0.21853692829608917\n",
      "Epoch [8/10] Batch [416/469] Loss D: -0.4752102196216583, loss G: -0.13493402302265167\n",
      "Epoch [8/10] Batch [417/469] Loss D: -0.5074701309204102, loss G: -0.3579772710800171\n",
      "Epoch [8/10] Batch [418/469] Loss D: -0.4136325716972351, loss G: -0.09884190559387207\n",
      "Epoch [8/10] Batch [419/469] Loss D: -0.5546883940696716, loss G: -0.18679803609848022\n",
      "Epoch [8/10] Batch [420/469] Loss D: -0.5301259756088257, loss G: -0.2327515184879303\n",
      "Epoch [8/10] Batch [421/469] Loss D: -0.5763733983039856, loss G: -0.13218000531196594\n",
      "Epoch [8/10] Batch [422/469] Loss D: -0.5486688613891602, loss G: -0.26119816303253174\n",
      "Epoch [8/10] Batch [423/469] Loss D: -0.5128928422927856, loss G: -0.07280449569225311\n",
      "Epoch [8/10] Batch [424/469] Loss D: -0.4828324019908905, loss G: -0.3269205689430237\n",
      "Epoch [8/10] Batch [425/469] Loss D: -0.5657923221588135, loss G: -0.08982868492603302\n",
      "Epoch [8/10] Batch [426/469] Loss D: -0.5861671566963196, loss G: -0.16354204714298248\n",
      "Epoch [8/10] Batch [427/469] Loss D: -0.4793417155742645, loss G: -0.364923894405365\n",
      "Epoch [8/10] Batch [428/469] Loss D: -0.5545684695243835, loss G: -0.08340686559677124\n",
      "Epoch [8/10] Batch [429/469] Loss D: -0.5124446153640747, loss G: -0.23488956689834595\n",
      "Epoch [8/10] Batch [430/469] Loss D: -0.5418771505355835, loss G: -0.12582921981811523\n",
      "Epoch [8/10] Batch [431/469] Loss D: -0.53863924741745, loss G: -0.23626808822155\n",
      "Epoch [8/10] Batch [432/469] Loss D: -0.5041400194168091, loss G: -0.14759549498558044\n",
      "Epoch [8/10] Batch [433/469] Loss D: -0.5457520484924316, loss G: -0.19833633303642273\n",
      "Epoch [8/10] Batch [434/469] Loss D: -0.610403835773468, loss G: -0.09154649078845978\n",
      "Epoch [8/10] Batch [435/469] Loss D: -0.6187721490859985, loss G: -0.3094089925289154\n",
      "Epoch [8/10] Batch [436/469] Loss D: -0.5124576091766357, loss G: -0.10857701301574707\n",
      "Epoch [8/10] Batch [437/469] Loss D: -0.5317914485931396, loss G: -0.24183732271194458\n",
      "Epoch [8/10] Batch [438/469] Loss D: -0.566167414188385, loss G: -0.12415380030870438\n",
      "Epoch [8/10] Batch [439/469] Loss D: -0.5634023547172546, loss G: -0.38353270292282104\n",
      "Epoch [8/10] Batch [440/469] Loss D: -0.41857510805130005, loss G: -0.11069057881832123\n",
      "Epoch [8/10] Batch [441/469] Loss D: -0.5368263721466064, loss G: -0.15519267320632935\n",
      "Epoch [8/10] Batch [442/469] Loss D: -0.566047191619873, loss G: -0.2646353840827942\n",
      "Epoch [8/10] Batch [443/469] Loss D: -0.5018100738525391, loss G: -0.11475841701030731\n",
      "Epoch [8/10] Batch [444/469] Loss D: -0.5623121857643127, loss G: -0.2060849666595459\n",
      "Epoch [8/10] Batch [445/469] Loss D: -0.5701816082000732, loss G: -0.22295111417770386\n",
      "Epoch [8/10] Batch [446/469] Loss D: -0.5220311880111694, loss G: -0.227849543094635\n",
      "Epoch [8/10] Batch [447/469] Loss D: -0.6044632196426392, loss G: -0.06890855729579926\n",
      "Epoch [8/10] Batch [448/469] Loss D: -0.5076149702072144, loss G: -0.3520043194293976\n",
      "Epoch [8/10] Batch [449/469] Loss D: -0.4916709065437317, loss G: -0.13790711760520935\n",
      "Epoch [8/10] Batch [450/469] Loss D: -0.5880235433578491, loss G: -0.07330557703971863\n",
      "Epoch [8/10] Batch [451/469] Loss D: -0.5083487033843994, loss G: -0.3828842043876648\n",
      "Epoch [8/10] Batch [452/469] Loss D: -0.49770185351371765, loss G: -0.1277010142803192\n",
      "Epoch [8/10] Batch [453/469] Loss D: -0.5775412321090698, loss G: -0.11378240585327148\n",
      "Epoch [8/10] Batch [454/469] Loss D: -0.4927988052368164, loss G: -0.2932640612125397\n",
      "Epoch [8/10] Batch [455/469] Loss D: -0.5689622163772583, loss G: -0.1514420211315155\n",
      "Epoch [8/10] Batch [456/469] Loss D: -0.52177894115448, loss G: -0.1422860473394394\n",
      "Epoch [8/10] Batch [457/469] Loss D: -0.5750923156738281, loss G: -0.18082916736602783\n",
      "Epoch [8/10] Batch [458/469] Loss D: -0.4880838990211487, loss G: -0.37168994545936584\n",
      "Epoch [8/10] Batch [459/469] Loss D: -0.4598109722137451, loss G: -0.04464321583509445\n",
      "Epoch [8/10] Batch [460/469] Loss D: -0.34544801712036133, loss G: -0.24955791234970093\n",
      "Epoch [8/10] Batch [461/469] Loss D: -0.5420157313346863, loss G: -0.2694832682609558\n",
      "Epoch [8/10] Batch [462/469] Loss D: -0.5279097557067871, loss G: -0.08458718657493591\n",
      "Epoch [8/10] Batch [463/469] Loss D: -0.5001903772354126, loss G: -0.2284277379512787\n",
      "Epoch [8/10] Batch [464/469] Loss D: -0.6018909215927124, loss G: -0.20425185561180115\n",
      "Epoch [8/10] Batch [465/469] Loss D: -0.49073177576065063, loss G: -0.1672259122133255\n",
      "Epoch [8/10] Batch [466/469] Loss D: -0.5266522169113159, loss G: -0.17759950459003448\n",
      "Epoch [8/10] Batch [467/469] Loss D: -0.5562868118286133, loss G: -0.2254684418439865\n",
      "Epoch [8/10] Batch [468/469] Loss D: -0.5831062197685242, loss G: -0.12013968080282211\n",
      "Epoch [8/10] Batch [469/469] Loss D: -0.5125979781150818, loss G: -0.2222004383802414\n",
      "Epoch [9/10] Batch [1/469] Loss D: -0.4614180028438568, loss G: -0.1287297010421753\n",
      "Epoch [9/10] Batch [2/469] Loss D: -0.4775065779685974, loss G: -0.36772090196609497\n",
      "Epoch [9/10] Batch [3/469] Loss D: -0.52680903673172, loss G: -0.10144072771072388\n",
      "Epoch [9/10] Batch [4/469] Loss D: -0.4794544577598572, loss G: -0.25655218958854675\n",
      "Epoch [9/10] Batch [5/469] Loss D: -0.5646223425865173, loss G: -0.1840028464794159\n",
      "Epoch [9/10] Batch [6/469] Loss D: -0.5073428153991699, loss G: -0.18229520320892334\n",
      "Epoch [9/10] Batch [7/469] Loss D: -0.5657590627670288, loss G: -0.18161386251449585\n",
      "Epoch [9/10] Batch [8/469] Loss D: -0.5496901869773865, loss G: -0.245748832821846\n",
      "Epoch [9/10] Batch [9/469] Loss D: -0.5878617763519287, loss G: -0.04969247430562973\n",
      "Epoch [9/10] Batch [10/469] Loss D: -0.512546718120575, loss G: -0.3778042793273926\n",
      "Epoch [9/10] Batch [11/469] Loss D: -0.4740973114967346, loss G: -0.12547549605369568\n",
      "Epoch [9/10] Batch [12/469] Loss D: -0.6217259168624878, loss G: -0.1689014434814453\n",
      "Epoch [9/10] Batch [13/469] Loss D: -0.5599151253700256, loss G: -0.1310426890850067\n",
      "Epoch [9/10] Batch [14/469] Loss D: -0.6344609260559082, loss G: -0.14959043264389038\n",
      "Epoch [9/10] Batch [15/469] Loss D: -0.5722897052764893, loss G: -0.21481133997440338\n",
      "Epoch [9/10] Batch [16/469] Loss D: -0.5655025243759155, loss G: -0.1875823736190796\n",
      "Epoch [9/10] Batch [17/469] Loss D: -0.5463314652442932, loss G: -0.1130012720823288\n",
      "Epoch [9/10] Batch [18/469] Loss D: -0.5699464082717896, loss G: -0.24407412111759186\n",
      "Epoch [9/10] Batch [19/469] Loss D: -0.5519037246704102, loss G: -0.1094723716378212\n",
      "Epoch [9/10] Batch [20/469] Loss D: -0.603337287902832, loss G: -0.18282923102378845\n",
      "Epoch [9/10] Batch [21/469] Loss D: -0.5281169414520264, loss G: -0.22521008551120758\n",
      "Epoch [9/10] Batch [22/469] Loss D: -0.508114755153656, loss G: -0.10291337966918945\n",
      "Epoch [9/10] Batch [23/469] Loss D: -0.5196614265441895, loss G: -0.3362571895122528\n",
      "Epoch [9/10] Batch [24/469] Loss D: -0.5096995830535889, loss G: -0.08523255586624146\n",
      "Epoch [9/10] Batch [25/469] Loss D: -0.4868103861808777, loss G: -0.36549216508865356\n",
      "Epoch [9/10] Batch [26/469] Loss D: -0.5144762992858887, loss G: -0.1127854734659195\n",
      "Epoch [9/10] Batch [27/469] Loss D: -0.5463323593139648, loss G: -0.20503684878349304\n",
      "Epoch [9/10] Batch [28/469] Loss D: -0.5715292096138, loss G: -0.31933003664016724\n",
      "Epoch [9/10] Batch [29/469] Loss D: -0.4649953246116638, loss G: -0.10008560121059418\n",
      "Epoch [9/10] Batch [30/469] Loss D: -0.5037974119186401, loss G: -0.24736754596233368\n",
      "Epoch [9/10] Batch [31/469] Loss D: -0.5628805756568909, loss G: -0.14652866125106812\n",
      "Epoch [9/10] Batch [32/469] Loss D: -0.5728447437286377, loss G: -0.1636282503604889\n",
      "Epoch [9/10] Batch [33/469] Loss D: -0.541391134262085, loss G: -0.2954201102256775\n",
      "Epoch [9/10] Batch [34/469] Loss D: -0.45060995221138, loss G: -0.12040506303310394\n",
      "Epoch [9/10] Batch [35/469] Loss D: -0.4733576774597168, loss G: -0.27332139015197754\n",
      "Epoch [9/10] Batch [36/469] Loss D: -0.5590521693229675, loss G: -0.10614197701215744\n",
      "Epoch [9/10] Batch [37/469] Loss D: -0.5999572277069092, loss G: -0.2623720169067383\n",
      "Epoch [9/10] Batch [38/469] Loss D: -0.5843544006347656, loss G: -0.056546978652477264\n",
      "Epoch [9/10] Batch [39/469] Loss D: -0.47638869285583496, loss G: -0.40360158681869507\n",
      "Epoch [9/10] Batch [40/469] Loss D: -0.5639363527297974, loss G: -0.0883435383439064\n",
      "Epoch [9/10] Batch [41/469] Loss D: -0.4986768066883087, loss G: -0.18999969959259033\n",
      "Epoch [9/10] Batch [42/469] Loss D: -0.603683352470398, loss G: -0.17604802548885345\n",
      "Epoch [9/10] Batch [43/469] Loss D: -0.564100980758667, loss G: -0.19742463529109955\n",
      "Epoch [9/10] Batch [44/469] Loss D: -0.6522788405418396, loss G: -0.062100738286972046\n",
      "Epoch [9/10] Batch [45/469] Loss D: -0.5300017595291138, loss G: -0.32857394218444824\n",
      "Epoch [9/10] Batch [46/469] Loss D: -0.49939465522766113, loss G: -0.11759932339191437\n",
      "Epoch [9/10] Batch [47/469] Loss D: -0.5319998264312744, loss G: -0.23722636699676514\n",
      "Epoch [9/10] Batch [48/469] Loss D: -0.5261794328689575, loss G: -0.24359923601150513\n",
      "Epoch [9/10] Batch [49/469] Loss D: -0.5909709334373474, loss G: -0.06714622676372528\n",
      "Epoch [9/10] Batch [50/469] Loss D: -0.5441749095916748, loss G: -0.29312819242477417\n",
      "Epoch [9/10] Batch [51/469] Loss D: -0.6323229670524597, loss G: -0.07940196990966797\n",
      "Epoch [9/10] Batch [52/469] Loss D: -0.5373251438140869, loss G: -0.2965952754020691\n",
      "Epoch [9/10] Batch [53/469] Loss D: -0.4934055805206299, loss G: -0.12478712946176529\n",
      "Epoch [9/10] Batch [54/469] Loss D: -0.609488308429718, loss G: -0.16952922940254211\n",
      "Epoch [9/10] Batch [55/469] Loss D: -0.5945173501968384, loss G: -0.259338915348053\n",
      "Epoch [9/10] Batch [56/469] Loss D: -0.558635950088501, loss G: -0.0679260641336441\n",
      "Epoch [9/10] Batch [57/469] Loss D: -0.5525161623954773, loss G: -0.27390342950820923\n",
      "Epoch [9/10] Batch [58/469] Loss D: -0.5265072584152222, loss G: -0.1852794885635376\n",
      "Epoch [9/10] Batch [59/469] Loss D: -0.5848549008369446, loss G: -0.11834943294525146\n",
      "Epoch [9/10] Batch [60/469] Loss D: -0.5986891388893127, loss G: -0.21766912937164307\n",
      "Epoch [9/10] Batch [61/469] Loss D: -0.5860022902488708, loss G: -0.2213040590286255\n",
      "Epoch [9/10] Batch [62/469] Loss D: -0.5161272883415222, loss G: -0.11615047603845596\n",
      "Epoch [9/10] Batch [63/469] Loss D: -0.4038577973842621, loss G: -0.29597070813179016\n",
      "Epoch [9/10] Batch [64/469] Loss D: -0.5338777303695679, loss G: -0.2363664209842682\n",
      "Epoch [9/10] Batch [65/469] Loss D: -0.5336124897003174, loss G: -0.11182992160320282\n",
      "Epoch [9/10] Batch [66/469] Loss D: -0.5279695987701416, loss G: -0.22077146172523499\n",
      "Epoch [9/10] Batch [67/469] Loss D: -0.5717346668243408, loss G: -0.1049676239490509\n",
      "Epoch [9/10] Batch [68/469] Loss D: -0.5713167190551758, loss G: -0.2024829387664795\n",
      "Epoch [9/10] Batch [69/469] Loss D: -0.5806804299354553, loss G: -0.19512194395065308\n",
      "Epoch [9/10] Batch [70/469] Loss D: -0.6349936723709106, loss G: -0.06300726532936096\n",
      "Epoch [9/10] Batch [71/469] Loss D: -0.5140898823738098, loss G: -0.23525552451610565\n",
      "Epoch [9/10] Batch [72/469] Loss D: -0.5615764260292053, loss G: -0.13424614071846008\n",
      "Epoch [9/10] Batch [73/469] Loss D: -0.49862101674079895, loss G: -0.32789504528045654\n",
      "Epoch [9/10] Batch [74/469] Loss D: -0.5159269571304321, loss G: -0.07244396209716797\n",
      "Epoch [9/10] Batch [75/469] Loss D: -0.5905022025108337, loss G: -0.26408928632736206\n",
      "Epoch [9/10] Batch [76/469] Loss D: -0.5438628196716309, loss G: -0.10932036489248276\n",
      "Epoch [9/10] Batch [77/469] Loss D: -0.49402424693107605, loss G: -0.270982027053833\n",
      "Epoch [9/10] Batch [78/469] Loss D: -0.563359260559082, loss G: -0.15189756453037262\n",
      "Epoch [9/10] Batch [79/469] Loss D: -0.5517924427986145, loss G: -0.10374021530151367\n",
      "Epoch [9/10] Batch [80/469] Loss D: -0.5576680898666382, loss G: -0.28803521394729614\n",
      "Epoch [9/10] Batch [81/469] Loss D: -0.5402886867523193, loss G: -0.09688454866409302\n",
      "Epoch [9/10] Batch [82/469] Loss D: -0.5915446877479553, loss G: -0.23853430151939392\n",
      "Epoch [9/10] Batch [83/469] Loss D: -0.5659516453742981, loss G: -0.1971994787454605\n",
      "Epoch [9/10] Batch [84/469] Loss D: -0.5822625160217285, loss G: -0.08105379343032837\n",
      "Epoch [9/10] Batch [85/469] Loss D: -0.5273255109786987, loss G: -0.31192225217819214\n",
      "Epoch [9/10] Batch [86/469] Loss D: -0.5253133177757263, loss G: -0.17970241606235504\n",
      "Epoch [9/10] Batch [87/469] Loss D: -0.4804568290710449, loss G: -0.1260613203048706\n",
      "Epoch [9/10] Batch [88/469] Loss D: -0.5973167419433594, loss G: -0.29959115386009216\n",
      "Epoch [9/10] Batch [89/469] Loss D: -0.4875830113887787, loss G: -0.07345268875360489\n",
      "Epoch [9/10] Batch [90/469] Loss D: -0.49403470754623413, loss G: -0.3082123398780823\n",
      "Epoch [9/10] Batch [91/469] Loss D: -0.5315129160881042, loss G: -0.10471212863922119\n",
      "Epoch [9/10] Batch [92/469] Loss D: -0.5248730182647705, loss G: -0.25141698122024536\n",
      "Epoch [9/10] Batch [93/469] Loss D: -0.6125308871269226, loss G: -0.049967408180236816\n",
      "Epoch [9/10] Batch [94/469] Loss D: -0.5330633521080017, loss G: -0.2978084683418274\n",
      "Epoch [9/10] Batch [95/469] Loss D: -0.5315022468566895, loss G: -0.09741534292697906\n",
      "Epoch [9/10] Batch [96/469] Loss D: -0.47519612312316895, loss G: -0.2365981489419937\n",
      "Epoch [9/10] Batch [97/469] Loss D: -0.5588376522064209, loss G: -0.15814533829689026\n",
      "Epoch [9/10] Batch [98/469] Loss D: -0.5321975946426392, loss G: -0.1892320215702057\n",
      "Epoch [9/10] Batch [99/469] Loss D: -0.5056328177452087, loss G: -0.21905414760112762\n",
      "Epoch [9/10] Batch [100/469] Loss D: -0.509326696395874, loss G: -0.10147635638713837\n",
      "Epoch [9/10] Batch [101/469] Loss D: -0.4867281913757324, loss G: -0.27076148986816406\n",
      "Epoch [9/10] Batch [102/469] Loss D: -0.4888407289981842, loss G: -0.23312968015670776\n",
      "Epoch [9/10] Batch [103/469] Loss D: -0.5708277225494385, loss G: -0.09940966218709946\n",
      "Epoch [9/10] Batch [104/469] Loss D: -0.5185308456420898, loss G: -0.30756324529647827\n",
      "Epoch [9/10] Batch [105/469] Loss D: -0.47069162130355835, loss G: -0.1273210346698761\n",
      "Epoch [9/10] Batch [106/469] Loss D: -0.5545973777770996, loss G: -0.2683589458465576\n",
      "Epoch [9/10] Batch [107/469] Loss D: -0.5322079658508301, loss G: -0.15293952822685242\n",
      "Epoch [9/10] Batch [108/469] Loss D: -0.5666196942329407, loss G: -0.2765393853187561\n",
      "Epoch [9/10] Batch [109/469] Loss D: -0.5466676354408264, loss G: -0.08000985532999039\n",
      "Epoch [9/10] Batch [110/469] Loss D: -0.4976968765258789, loss G: -0.3689129650592804\n",
      "Epoch [9/10] Batch [111/469] Loss D: -0.4281370937824249, loss G: -0.19684451818466187\n",
      "Epoch [9/10] Batch [112/469] Loss D: -0.538265585899353, loss G: -0.1059734970331192\n",
      "Epoch [9/10] Batch [113/469] Loss D: -0.5235490798950195, loss G: -0.3482413589954376\n",
      "Epoch [9/10] Batch [114/469] Loss D: -0.5316681861877441, loss G: -0.09288185089826584\n",
      "Epoch [9/10] Batch [115/469] Loss D: -0.577256441116333, loss G: -0.09859064966440201\n",
      "Epoch [9/10] Batch [116/469] Loss D: -0.41471439599990845, loss G: -0.4416239857673645\n",
      "Epoch [9/10] Batch [117/469] Loss D: -0.48494550585746765, loss G: -0.15405158698558807\n",
      "Epoch [9/10] Batch [118/469] Loss D: -0.5739421844482422, loss G: -0.12197130173444748\n",
      "Epoch [9/10] Batch [119/469] Loss D: -0.5191784501075745, loss G: -0.2980796694755554\n",
      "Epoch [9/10] Batch [120/469] Loss D: -0.529699444770813, loss G: -0.12608513236045837\n",
      "Epoch [9/10] Batch [121/469] Loss D: -0.6017813682556152, loss G: -0.12504471838474274\n",
      "Epoch [9/10] Batch [122/469] Loss D: -0.48428741097450256, loss G: -0.35140448808670044\n",
      "Epoch [9/10] Batch [123/469] Loss D: -0.48970407247543335, loss G: -0.09104950726032257\n",
      "Epoch [9/10] Batch [124/469] Loss D: -0.40164199471473694, loss G: -0.3206554353237152\n",
      "Epoch [9/10] Batch [125/469] Loss D: -0.554746687412262, loss G: -0.11687871813774109\n",
      "Epoch [9/10] Batch [126/469] Loss D: -0.5573387145996094, loss G: -0.2079516053199768\n",
      "Epoch [9/10] Batch [127/469] Loss D: -0.6158931851387024, loss G: -0.056500401347875595\n",
      "Epoch [9/10] Batch [128/469] Loss D: -0.5288669466972351, loss G: -0.3673466444015503\n",
      "Epoch [9/10] Batch [129/469] Loss D: -0.45072197914123535, loss G: -0.17547984421253204\n",
      "Epoch [9/10] Batch [130/469] Loss D: -0.5425123572349548, loss G: -0.2108616828918457\n",
      "Epoch [9/10] Batch [131/469] Loss D: -0.6416871547698975, loss G: -0.13665682077407837\n",
      "Epoch [9/10] Batch [132/469] Loss D: -0.6138073205947876, loss G: -0.08653607964515686\n",
      "Epoch [9/10] Batch [133/469] Loss D: -0.5509406924247742, loss G: -0.28113704919815063\n",
      "Epoch [9/10] Batch [134/469] Loss D: -0.5562812685966492, loss G: -0.059464383870363235\n",
      "Epoch [9/10] Batch [135/469] Loss D: -0.4027869403362274, loss G: -0.2869868874549866\n",
      "Epoch [9/10] Batch [136/469] Loss D: -0.4442580044269562, loss G: -0.30243808031082153\n",
      "Epoch [9/10] Batch [137/469] Loss D: -0.5341822504997253, loss G: -0.09626631438732147\n",
      "Epoch [9/10] Batch [138/469] Loss D: -0.3799396753311157, loss G: -0.34687376022338867\n",
      "Epoch [9/10] Batch [139/469] Loss D: -0.4587033987045288, loss G: -0.18185585737228394\n",
      "Epoch [9/10] Batch [140/469] Loss D: -0.4690709114074707, loss G: -0.1712801307439804\n",
      "Epoch [9/10] Batch [141/469] Loss D: -0.4588998854160309, loss G: -0.2957041263580322\n",
      "Epoch [9/10] Batch [142/469] Loss D: -0.556792140007019, loss G: -0.1323118358850479\n",
      "Epoch [9/10] Batch [143/469] Loss D: -0.5027281045913696, loss G: -0.2666465640068054\n",
      "Epoch [9/10] Batch [144/469] Loss D: -0.5481523275375366, loss G: -0.11502940952777863\n",
      "Epoch [9/10] Batch [145/469] Loss D: -0.5300683379173279, loss G: -0.2756383419036865\n",
      "Epoch [9/10] Batch [146/469] Loss D: -0.5249027013778687, loss G: -0.1116928979754448\n",
      "Epoch [9/10] Batch [147/469] Loss D: -0.49464714527130127, loss G: -0.29884040355682373\n",
      "Epoch [9/10] Batch [148/469] Loss D: -0.5524148941040039, loss G: -0.13898290693759918\n",
      "Epoch [9/10] Batch [149/469] Loss D: -0.5385088920593262, loss G: -0.13472190499305725\n",
      "Epoch [9/10] Batch [150/469] Loss D: -0.5386377573013306, loss G: -0.36653345823287964\n",
      "Epoch [9/10] Batch [151/469] Loss D: -0.42747071385383606, loss G: -0.14595305919647217\n",
      "Epoch [9/10] Batch [152/469] Loss D: -0.47366636991500854, loss G: -0.2827317714691162\n",
      "Epoch [9/10] Batch [153/469] Loss D: -0.540026843547821, loss G: -0.0967419221997261\n",
      "Epoch [9/10] Batch [154/469] Loss D: -0.4361431896686554, loss G: -0.37659379839897156\n",
      "Epoch [9/10] Batch [155/469] Loss D: -0.4109804034233093, loss G: -0.17335748672485352\n",
      "Epoch [9/10] Batch [156/469] Loss D: -0.4508551061153412, loss G: -0.2559138536453247\n",
      "Epoch [9/10] Batch [157/469] Loss D: -0.49528592824935913, loss G: -0.17770133912563324\n",
      "Epoch [9/10] Batch [158/469] Loss D: -0.5905623435974121, loss G: -0.1430160403251648\n",
      "Epoch [9/10] Batch [159/469] Loss D: -0.5588578581809998, loss G: -0.2656460404396057\n",
      "Epoch [9/10] Batch [160/469] Loss D: -0.5881040096282959, loss G: -0.08794718980789185\n",
      "Epoch [9/10] Batch [161/469] Loss D: -0.5462871789932251, loss G: -0.2871145009994507\n",
      "Epoch [9/10] Batch [162/469] Loss D: -0.5314038395881653, loss G: -0.1985865831375122\n",
      "Epoch [9/10] Batch [163/469] Loss D: -0.6368950605392456, loss G: -0.10241136699914932\n",
      "Epoch [9/10] Batch [164/469] Loss D: -0.5656405687332153, loss G: -0.1734521985054016\n",
      "Epoch [9/10] Batch [165/469] Loss D: -0.6091691851615906, loss G: -0.2826731204986572\n",
      "Epoch [9/10] Batch [166/469] Loss D: -0.5421963930130005, loss G: -0.12664836645126343\n",
      "Epoch [9/10] Batch [167/469] Loss D: -0.566568911075592, loss G: -0.1289505809545517\n",
      "Epoch [9/10] Batch [168/469] Loss D: -0.4331902861595154, loss G: -0.37389498949050903\n",
      "Epoch [9/10] Batch [169/469] Loss D: -0.48177972435951233, loss G: -0.06952424347400665\n",
      "Epoch [9/10] Batch [170/469] Loss D: -0.47523319721221924, loss G: -0.3559632897377014\n",
      "Epoch [9/10] Batch [171/469] Loss D: -0.46435415744781494, loss G: -0.11149103939533234\n",
      "Epoch [9/10] Batch [172/469] Loss D: -0.552876889705658, loss G: -0.18844741582870483\n",
      "Epoch [9/10] Batch [173/469] Loss D: -0.5885137319564819, loss G: -0.170356884598732\n",
      "Epoch [9/10] Batch [174/469] Loss D: -0.5615905523300171, loss G: -0.17395099997520447\n",
      "Epoch [9/10] Batch [175/469] Loss D: -0.4682220220565796, loss G: -0.32147863507270813\n",
      "Epoch [9/10] Batch [176/469] Loss D: -0.5239463448524475, loss G: -0.052837155759334564\n",
      "Epoch [9/10] Batch [177/469] Loss D: -0.4700944423675537, loss G: -0.3257982134819031\n",
      "Epoch [9/10] Batch [178/469] Loss D: -0.45933395624160767, loss G: -0.178110271692276\n",
      "Epoch [9/10] Batch [179/469] Loss D: -0.602430522441864, loss G: -0.04825698584318161\n",
      "Epoch [9/10] Batch [180/469] Loss D: -0.3777958154678345, loss G: -0.32645106315612793\n",
      "Epoch [9/10] Batch [181/469] Loss D: -0.5357986688613892, loss G: -0.1594412922859192\n",
      "Epoch [9/10] Batch [182/469] Loss D: -0.541332483291626, loss G: -0.15602357685565948\n",
      "Epoch [9/10] Batch [183/469] Loss D: -0.5674890875816345, loss G: -0.20065709948539734\n",
      "Epoch [9/10] Batch [184/469] Loss D: -0.5180569887161255, loss G: -0.219815194606781\n",
      "Epoch [9/10] Batch [185/469] Loss D: -0.5726544260978699, loss G: -0.12261997163295746\n",
      "Epoch [9/10] Batch [186/469] Loss D: -0.5451015830039978, loss G: -0.28170832991600037\n",
      "Epoch [9/10] Batch [187/469] Loss D: -0.49069496989250183, loss G: -0.12801194190979004\n",
      "Epoch [9/10] Batch [188/469] Loss D: -0.6260995268821716, loss G: -0.0809689536690712\n",
      "Epoch [9/10] Batch [189/469] Loss D: -0.6004974842071533, loss G: -0.3490127921104431\n",
      "Epoch [9/10] Batch [190/469] Loss D: -0.437732070684433, loss G: -0.12093433737754822\n",
      "Epoch [9/10] Batch [191/469] Loss D: -0.5813940763473511, loss G: -0.19323667883872986\n",
      "Epoch [9/10] Batch [192/469] Loss D: -0.6163529753684998, loss G: -0.1196826845407486\n",
      "Epoch [9/10] Batch [193/469] Loss D: -0.5390125513076782, loss G: -0.35339462757110596\n",
      "Epoch [9/10] Batch [194/469] Loss D: -0.40388721227645874, loss G: -0.050525031983852386\n",
      "Epoch [9/10] Batch [195/469] Loss D: -0.43950772285461426, loss G: -0.2794341742992401\n",
      "Epoch [9/10] Batch [196/469] Loss D: -0.5106587409973145, loss G: -0.2858469486236572\n",
      "Epoch [9/10] Batch [197/469] Loss D: -0.41395485401153564, loss G: -0.11428822576999664\n",
      "Epoch [9/10] Batch [198/469] Loss D: -0.5089707374572754, loss G: -0.2298087179660797\n",
      "Epoch [9/10] Batch [199/469] Loss D: -0.5333832502365112, loss G: -0.1718529611825943\n",
      "Epoch [9/10] Batch [200/469] Loss D: -0.5811949968338013, loss G: -0.2056872546672821\n",
      "Epoch [9/10] Batch [201/469] Loss D: -0.509249746799469, loss G: -0.1302921324968338\n",
      "Epoch [9/10] Batch [202/469] Loss D: -0.5089144706726074, loss G: -0.2099071592092514\n",
      "Epoch [9/10] Batch [203/469] Loss D: -0.551131546497345, loss G: -0.18730264902114868\n",
      "Epoch [9/10] Batch [204/469] Loss D: -0.5920037627220154, loss G: -0.1845092624425888\n",
      "Epoch [9/10] Batch [205/469] Loss D: -0.6031429767608643, loss G: -0.14069077372550964\n",
      "Epoch [9/10] Batch [206/469] Loss D: -0.5752578973770142, loss G: -0.1783267855644226\n",
      "Epoch [9/10] Batch [207/469] Loss D: -0.5443204641342163, loss G: -0.17095360159873962\n",
      "Epoch [9/10] Batch [208/469] Loss D: -0.5861579179763794, loss G: -0.19214387238025665\n",
      "Epoch [9/10] Batch [209/469] Loss D: -0.6073580980300903, loss G: -0.1284433901309967\n",
      "Epoch [9/10] Batch [210/469] Loss D: -0.5522305965423584, loss G: -0.2286141961812973\n",
      "Epoch [9/10] Batch [211/469] Loss D: -0.5156677961349487, loss G: -0.15555138885974884\n",
      "Epoch [9/10] Batch [212/469] Loss D: -0.6153616905212402, loss G: -0.18819601833820343\n",
      "Epoch [9/10] Batch [213/469] Loss D: -0.5892927646636963, loss G: -0.10806503146886826\n",
      "Epoch [9/10] Batch [214/469] Loss D: -0.5540661215782166, loss G: -0.27759885787963867\n",
      "Epoch [9/10] Batch [215/469] Loss D: -0.5265836715698242, loss G: -0.08964118361473083\n",
      "Epoch [9/10] Batch [216/469] Loss D: -0.5818130970001221, loss G: -0.28660309314727783\n",
      "Epoch [9/10] Batch [217/469] Loss D: -0.4449719786643982, loss G: -0.1515790820121765\n",
      "Epoch [9/10] Batch [218/469] Loss D: -0.5123964548110962, loss G: -0.27585309743881226\n",
      "Epoch [9/10] Batch [219/469] Loss D: -0.5377410054206848, loss G: -0.12852934002876282\n",
      "Epoch [9/10] Batch [220/469] Loss D: -0.539176881313324, loss G: -0.12122884392738342\n",
      "Epoch [9/10] Batch [221/469] Loss D: -0.5276134610176086, loss G: -0.3413431942462921\n",
      "Epoch [9/10] Batch [222/469] Loss D: -0.4301261603832245, loss G: -0.09296927601099014\n",
      "Epoch [9/10] Batch [223/469] Loss D: -0.5317360162734985, loss G: -0.171050027012825\n",
      "Epoch [9/10] Batch [224/469] Loss D: -0.6010042428970337, loss G: -0.2150183916091919\n",
      "Epoch [9/10] Batch [225/469] Loss D: -0.5386819839477539, loss G: -0.08924087136983871\n",
      "Epoch [9/10] Batch [226/469] Loss D: -0.6312272548675537, loss G: -0.12783819437026978\n",
      "Epoch [9/10] Batch [227/469] Loss D: -0.5204454064369202, loss G: -0.30009889602661133\n",
      "Epoch [9/10] Batch [228/469] Loss D: -0.5489346385002136, loss G: -0.06302135437726974\n",
      "Epoch [9/10] Batch [229/469] Loss D: -0.35744258761405945, loss G: -0.3094315528869629\n",
      "Epoch [9/10] Batch [230/469] Loss D: -0.45535820722579956, loss G: -0.2513752579689026\n",
      "Epoch [9/10] Batch [231/469] Loss D: -0.5418359041213989, loss G: -0.11376415938138962\n",
      "Epoch [9/10] Batch [232/469] Loss D: -0.6348713636398315, loss G: -0.28329479694366455\n",
      "Epoch [9/10] Batch [233/469] Loss D: -0.5335481762886047, loss G: -0.050310660153627396\n",
      "Epoch [9/10] Batch [234/469] Loss D: -0.48327887058258057, loss G: -0.3094866871833801\n",
      "Epoch [9/10] Batch [235/469] Loss D: -0.5202164053916931, loss G: -0.11640763282775879\n",
      "Epoch [9/10] Batch [236/469] Loss D: -0.5559296011924744, loss G: -0.13328835368156433\n",
      "Epoch [9/10] Batch [237/469] Loss D: -0.574274480342865, loss G: -0.3087352514266968\n",
      "Epoch [9/10] Batch [238/469] Loss D: -0.48347291350364685, loss G: -0.1476188600063324\n",
      "Epoch [9/10] Batch [239/469] Loss D: -0.48361629247665405, loss G: -0.26217538118362427\n",
      "Epoch [9/10] Batch [240/469] Loss D: -0.5101283192634583, loss G: -0.1205182671546936\n",
      "Epoch [9/10] Batch [241/469] Loss D: -0.5116590261459351, loss G: -0.2183445692062378\n",
      "Epoch [9/10] Batch [242/469] Loss D: -0.5107696652412415, loss G: -0.20826128125190735\n",
      "Epoch [9/10] Batch [243/469] Loss D: -0.561182975769043, loss G: -0.102521613240242\n",
      "Epoch [9/10] Batch [244/469] Loss D: -0.5468907356262207, loss G: -0.2262667715549469\n",
      "Epoch [9/10] Batch [245/469] Loss D: -0.5990570783615112, loss G: -0.2980882525444031\n",
      "Epoch [9/10] Batch [246/469] Loss D: -0.5556573867797852, loss G: -0.05324286222457886\n",
      "Epoch [9/10] Batch [247/469] Loss D: -0.5366868376731873, loss G: -0.2532005310058594\n",
      "Epoch [9/10] Batch [248/469] Loss D: -0.5839924812316895, loss G: -0.13590511679649353\n",
      "Epoch [9/10] Batch [249/469] Loss D: -0.5980620980262756, loss G: -0.15627440810203552\n",
      "Epoch [9/10] Batch [250/469] Loss D: -0.6125494241714478, loss G: -0.1512632966041565\n",
      "Epoch [9/10] Batch [251/469] Loss D: -0.6207954287528992, loss G: -0.20232412219047546\n",
      "Epoch [9/10] Batch [252/469] Loss D: -0.5584793090820312, loss G: -0.08420620858669281\n",
      "Epoch [9/10] Batch [253/469] Loss D: -0.5339404940605164, loss G: -0.3090707063674927\n",
      "Epoch [9/10] Batch [254/469] Loss D: -0.6642654538154602, loss G: -0.07616060972213745\n",
      "Epoch [9/10] Batch [255/469] Loss D: -0.6532557010650635, loss G: -0.15065248310565948\n",
      "Epoch [9/10] Batch [256/469] Loss D: -0.5891692638397217, loss G: -0.17010188102722168\n",
      "Epoch [9/10] Batch [257/469] Loss D: -0.5582250952720642, loss G: -0.21712155640125275\n",
      "Epoch [9/10] Batch [258/469] Loss D: -0.574251651763916, loss G: -0.0957876443862915\n",
      "Epoch [9/10] Batch [259/469] Loss D: -0.5669753551483154, loss G: -0.27405303716659546\n",
      "Epoch [9/10] Batch [260/469] Loss D: -0.5476993918418884, loss G: -0.11346791684627533\n",
      "Epoch [9/10] Batch [261/469] Loss D: -0.5136840343475342, loss G: -0.18521398305892944\n",
      "Epoch [9/10] Batch [262/469] Loss D: -0.5528709888458252, loss G: -0.20331111550331116\n",
      "Epoch [9/10] Batch [263/469] Loss D: -0.6544435024261475, loss G: -0.08524422347545624\n",
      "Epoch [9/10] Batch [264/469] Loss D: -0.6374017596244812, loss G: -0.2881464660167694\n",
      "Epoch [9/10] Batch [265/469] Loss D: -0.4967382550239563, loss G: -0.05925844609737396\n",
      "Epoch [9/10] Batch [266/469] Loss D: -0.4486258327960968, loss G: -0.28583449125289917\n",
      "Epoch [9/10] Batch [267/469] Loss D: -0.5476238131523132, loss G: -0.1127403974533081\n",
      "Epoch [9/10] Batch [268/469] Loss D: -0.5264042615890503, loss G: -0.2920414209365845\n",
      "Epoch [9/10] Batch [269/469] Loss D: -0.506067156791687, loss G: -0.09483906626701355\n",
      "Epoch [9/10] Batch [270/469] Loss D: -0.4632459878921509, loss G: -0.3274391293525696\n",
      "Epoch [9/10] Batch [271/469] Loss D: -0.5599822998046875, loss G: -0.05714855343103409\n",
      "Epoch [9/10] Batch [272/469] Loss D: -0.5284159779548645, loss G: -0.26747140288352966\n",
      "Epoch [9/10] Batch [273/469] Loss D: -0.6195887923240662, loss G: -0.12516339123249054\n",
      "Epoch [9/10] Batch [274/469] Loss D: -0.5785150527954102, loss G: -0.17061862349510193\n",
      "Epoch [9/10] Batch [275/469] Loss D: -0.5049908757209778, loss G: -0.25643590092658997\n",
      "Epoch [9/10] Batch [276/469] Loss D: -0.5417219400405884, loss G: -0.09253105521202087\n",
      "Epoch [9/10] Batch [277/469] Loss D: -0.4563184976577759, loss G: -0.2747619152069092\n",
      "Epoch [9/10] Batch [278/469] Loss D: -0.4928327202796936, loss G: -0.16483750939369202\n",
      "Epoch [9/10] Batch [279/469] Loss D: -0.6982403993606567, loss G: -0.09836028516292572\n",
      "Epoch [9/10] Batch [280/469] Loss D: -0.5393244028091431, loss G: -0.256119966506958\n",
      "Epoch [9/10] Batch [281/469] Loss D: -0.5408551692962646, loss G: -0.10384465008974075\n",
      "Epoch [9/10] Batch [282/469] Loss D: -0.5510622262954712, loss G: -0.16496826708316803\n",
      "Epoch [9/10] Batch [283/469] Loss D: -0.44582265615463257, loss G: -0.3704271912574768\n",
      "Epoch [9/10] Batch [284/469] Loss D: -0.4903845191001892, loss G: -0.10067221522331238\n",
      "Epoch [9/10] Batch [285/469] Loss D: -0.5391607284545898, loss G: -0.21376347541809082\n",
      "Epoch [9/10] Batch [286/469] Loss D: -0.5699154138565063, loss G: -0.21131235361099243\n",
      "Epoch [9/10] Batch [287/469] Loss D: -0.5283399820327759, loss G: -0.11606257408857346\n",
      "Epoch [9/10] Batch [288/469] Loss D: -0.5571866631507874, loss G: -0.2909873127937317\n",
      "Epoch [9/10] Batch [289/469] Loss D: -0.5285497903823853, loss G: -0.139609694480896\n",
      "Epoch [9/10] Batch [290/469] Loss D: -0.5495259165763855, loss G: -0.1578332781791687\n",
      "Epoch [9/10] Batch [291/469] Loss D: -0.5772484540939331, loss G: -0.1631140559911728\n",
      "Epoch [9/10] Batch [292/469] Loss D: -0.5616950988769531, loss G: -0.20956963300704956\n",
      "Epoch [9/10] Batch [293/469] Loss D: -0.5867111682891846, loss G: -0.16776128113269806\n",
      "Epoch [9/10] Batch [294/469] Loss D: -0.5442582368850708, loss G: -0.25847679376602173\n",
      "Epoch [9/10] Batch [295/469] Loss D: -0.5851042866706848, loss G: -0.0780603438615799\n",
      "Epoch [9/10] Batch [296/469] Loss D: -0.5098521709442139, loss G: -0.20702102780342102\n",
      "Epoch [9/10] Batch [297/469] Loss D: -0.544364869594574, loss G: -0.24718192219734192\n",
      "Epoch [9/10] Batch [298/469] Loss D: -0.5466536283493042, loss G: -0.16096839308738708\n",
      "Epoch [9/10] Batch [299/469] Loss D: -0.48902517557144165, loss G: -0.22398020327091217\n",
      "Epoch [9/10] Batch [300/469] Loss D: -0.6156784296035767, loss G: -0.10711350291967392\n",
      "Epoch [9/10] Batch [301/469] Loss D: -0.5604400038719177, loss G: -0.318080872297287\n",
      "Epoch [9/10] Batch [302/469] Loss D: -0.5262112617492676, loss G: -0.036042340099811554\n",
      "Epoch [9/10] Batch [303/469] Loss D: -0.4435465633869171, loss G: -0.3127071261405945\n",
      "Epoch [9/10] Batch [304/469] Loss D: -0.5188665390014648, loss G: -0.19499443471431732\n",
      "Epoch [9/10] Batch [305/469] Loss D: -0.5478760600090027, loss G: -0.15933337807655334\n",
      "Epoch [9/10] Batch [306/469] Loss D: -0.5292129516601562, loss G: -0.28484106063842773\n",
      "Epoch [9/10] Batch [307/469] Loss D: -0.5241191387176514, loss G: -0.10819527506828308\n",
      "Epoch [9/10] Batch [308/469] Loss D: -0.44183453917503357, loss G: -0.31908175349235535\n",
      "Epoch [9/10] Batch [309/469] Loss D: -0.4029451608657837, loss G: -0.140459343791008\n",
      "Epoch [9/10] Batch [310/469] Loss D: -0.5505160689353943, loss G: -0.15780729055404663\n",
      "Epoch [9/10] Batch [311/469] Loss D: -0.5350083112716675, loss G: -0.3076956868171692\n",
      "Epoch [9/10] Batch [312/469] Loss D: -0.5196609497070312, loss G: -0.15273159742355347\n",
      "Epoch [9/10] Batch [313/469] Loss D: -0.5799537897109985, loss G: -0.11923104524612427\n",
      "Epoch [9/10] Batch [314/469] Loss D: -0.5988130569458008, loss G: -0.36859628558158875\n",
      "Epoch [9/10] Batch [315/469] Loss D: -0.5026902556419373, loss G: -0.08213783800601959\n",
      "Epoch [9/10] Batch [316/469] Loss D: -0.663303017616272, loss G: -0.14338389039039612\n",
      "Epoch [9/10] Batch [317/469] Loss D: -0.5391235947608948, loss G: -0.20152872800827026\n",
      "Epoch [9/10] Batch [318/469] Loss D: -0.6179586052894592, loss G: -0.0856759175658226\n",
      "Epoch [9/10] Batch [319/469] Loss D: -0.4808489680290222, loss G: -0.31563273072242737\n",
      "Epoch [9/10] Batch [320/469] Loss D: -0.49491825699806213, loss G: -0.17871716618537903\n",
      "Epoch [9/10] Batch [321/469] Loss D: -0.5769458413124084, loss G: -0.108350470662117\n",
      "Epoch [9/10] Batch [322/469] Loss D: -0.5117157101631165, loss G: -0.33702337741851807\n",
      "Epoch [9/10] Batch [323/469] Loss D: -0.5685452818870544, loss G: -0.08717907965183258\n",
      "Epoch [9/10] Batch [324/469] Loss D: -0.4663969576358795, loss G: -0.26852351427078247\n",
      "Epoch [9/10] Batch [325/469] Loss D: -0.6117802262306213, loss G: -0.09493614733219147\n",
      "Epoch [9/10] Batch [326/469] Loss D: -0.6570268273353577, loss G: -0.15090665221214294\n",
      "Epoch [9/10] Batch [327/469] Loss D: -0.5695552229881287, loss G: -0.32363393902778625\n",
      "Epoch [9/10] Batch [328/469] Loss D: -0.43670377135276794, loss G: -0.13710559904575348\n",
      "Epoch [9/10] Batch [329/469] Loss D: -0.4287331700325012, loss G: -0.30646640062332153\n",
      "Epoch [9/10] Batch [330/469] Loss D: -0.5374016761779785, loss G: -0.10038246959447861\n",
      "Epoch [9/10] Batch [331/469] Loss D: -0.4825637936592102, loss G: -0.2914700508117676\n",
      "Epoch [9/10] Batch [332/469] Loss D: -0.5476059317588806, loss G: -0.16466084122657776\n",
      "Epoch [9/10] Batch [333/469] Loss D: -0.5835208296775818, loss G: -0.14053556323051453\n",
      "Epoch [9/10] Batch [334/469] Loss D: -0.5726974010467529, loss G: -0.22487668693065643\n",
      "Epoch [9/10] Batch [335/469] Loss D: -0.5916705131530762, loss G: -0.11941017955541611\n",
      "Epoch [9/10] Batch [336/469] Loss D: -0.4936791956424713, loss G: -0.2639608383178711\n",
      "Epoch [9/10] Batch [337/469] Loss D: -0.6270982623100281, loss G: -0.13651874661445618\n",
      "Epoch [9/10] Batch [338/469] Loss D: -0.6126170754432678, loss G: -0.11280034482479095\n",
      "Epoch [9/10] Batch [339/469] Loss D: -0.5120634436607361, loss G: -0.32803624868392944\n",
      "Epoch [9/10] Batch [340/469] Loss D: -0.5324703454971313, loss G: -0.06381791830062866\n",
      "Epoch [9/10] Batch [341/469] Loss D: -0.4285784363746643, loss G: -0.28434473276138306\n",
      "Epoch [9/10] Batch [342/469] Loss D: -0.4718092083930969, loss G: -0.1841748058795929\n",
      "Epoch [9/10] Batch [343/469] Loss D: -0.6051995754241943, loss G: -0.1774395853281021\n",
      "Epoch [9/10] Batch [344/469] Loss D: -0.5225450992584229, loss G: -0.18269629776477814\n",
      "Epoch [9/10] Batch [345/469] Loss D: -0.5373751521110535, loss G: -0.22975826263427734\n",
      "Epoch [9/10] Batch [346/469] Loss D: -0.5369031429290771, loss G: -0.05108685791492462\n",
      "Epoch [9/10] Batch [347/469] Loss D: -0.45885032415390015, loss G: -0.2682647705078125\n",
      "Epoch [9/10] Batch [348/469] Loss D: -0.560752272605896, loss G: -0.1428995430469513\n",
      "Epoch [9/10] Batch [349/469] Loss D: -0.5751711130142212, loss G: -0.11248348653316498\n",
      "Epoch [9/10] Batch [350/469] Loss D: -0.619117259979248, loss G: -0.29542356729507446\n",
      "Epoch [9/10] Batch [351/469] Loss D: -0.545053243637085, loss G: -0.10187268257141113\n",
      "Epoch [9/10] Batch [352/469] Loss D: -0.5086559057235718, loss G: -0.371764600276947\n",
      "Epoch [9/10] Batch [353/469] Loss D: -0.4378901720046997, loss G: -0.10134842991828918\n",
      "Epoch [9/10] Batch [354/469] Loss D: -0.45141860842704773, loss G: -0.235517218708992\n",
      "Epoch [9/10] Batch [355/469] Loss D: -0.5634284019470215, loss G: -0.37168800830841064\n",
      "Epoch [9/10] Batch [356/469] Loss D: -0.43266546726226807, loss G: -0.0841381698846817\n",
      "Epoch [9/10] Batch [357/469] Loss D: -0.49660754203796387, loss G: -0.2303062230348587\n",
      "Epoch [9/10] Batch [358/469] Loss D: -0.5932040214538574, loss G: -0.13804969191551208\n",
      "Epoch [9/10] Batch [359/469] Loss D: -0.4567199945449829, loss G: -0.34340161085128784\n",
      "Epoch [9/10] Batch [360/469] Loss D: -0.5526991486549377, loss G: -0.11085505783557892\n",
      "Epoch [9/10] Batch [361/469] Loss D: -0.5560525059700012, loss G: -0.13965514302253723\n",
      "Epoch [9/10] Batch [362/469] Loss D: -0.5222057700157166, loss G: -0.28890353441238403\n",
      "Epoch [9/10] Batch [363/469] Loss D: -0.5198469161987305, loss G: -0.09953783452510834\n",
      "Epoch [9/10] Batch [364/469] Loss D: -0.5422598123550415, loss G: -0.24170932173728943\n",
      "Epoch [9/10] Batch [365/469] Loss D: -0.5142993927001953, loss G: -0.2088761180639267\n",
      "Epoch [9/10] Batch [366/469] Loss D: -0.565258800983429, loss G: -0.13633200526237488\n",
      "Epoch [9/10] Batch [367/469] Loss D: -0.5601863265037537, loss G: -0.2478303462266922\n",
      "Epoch [9/10] Batch [368/469] Loss D: -0.47766023874282837, loss G: -0.12340967357158661\n",
      "Epoch [9/10] Batch [369/469] Loss D: -0.5751669406890869, loss G: -0.16875618696212769\n",
      "Epoch [9/10] Batch [370/469] Loss D: -0.5606839060783386, loss G: -0.23454725742340088\n",
      "Epoch [9/10] Batch [371/469] Loss D: -0.5794829726219177, loss G: -0.10062377154827118\n",
      "Epoch [9/10] Batch [372/469] Loss D: -0.5443925857543945, loss G: -0.2676335275173187\n",
      "Epoch [9/10] Batch [373/469] Loss D: -0.6301088333129883, loss G: -0.09958672523498535\n",
      "Epoch [9/10] Batch [374/469] Loss D: -0.5904901027679443, loss G: -0.2478918433189392\n",
      "Epoch [9/10] Batch [375/469] Loss D: -0.5510396957397461, loss G: -0.11275699734687805\n",
      "Epoch [9/10] Batch [376/469] Loss D: -0.5985313653945923, loss G: -0.16986985504627228\n",
      "Epoch [9/10] Batch [377/469] Loss D: -0.6119887828826904, loss G: -0.26845014095306396\n",
      "Epoch [9/10] Batch [378/469] Loss D: -0.5750994086265564, loss G: -0.08083929121494293\n",
      "Epoch [9/10] Batch [379/469] Loss D: -0.5987815260887146, loss G: -0.2869521379470825\n",
      "Epoch [9/10] Batch [380/469] Loss D: -0.5924714803695679, loss G: -0.12132102996110916\n",
      "Epoch [9/10] Batch [381/469] Loss D: -0.6111416816711426, loss G: -0.15990209579467773\n",
      "Epoch [9/10] Batch [382/469] Loss D: -0.5734630227088928, loss G: -0.1361389011144638\n",
      "Epoch [9/10] Batch [383/469] Loss D: -0.5970653891563416, loss G: -0.19510257244110107\n",
      "Epoch [9/10] Batch [384/469] Loss D: -0.6090022921562195, loss G: -0.16246147453784943\n",
      "Epoch [9/10] Batch [385/469] Loss D: -0.5785819292068481, loss G: -0.08146806061267853\n",
      "Epoch [9/10] Batch [386/469] Loss D: -0.5978502035140991, loss G: -0.31147852540016174\n",
      "Epoch [9/10] Batch [387/469] Loss D: -0.47891420125961304, loss G: -0.12635460495948792\n",
      "Epoch [9/10] Batch [388/469] Loss D: -0.555120587348938, loss G: -0.22750675678253174\n",
      "Epoch [9/10] Batch [389/469] Loss D: -0.5663563013076782, loss G: -0.14369022846221924\n",
      "Epoch [9/10] Batch [390/469] Loss D: -0.5422096252441406, loss G: -0.25194990634918213\n",
      "Epoch [9/10] Batch [391/469] Loss D: -0.49404817819595337, loss G: -0.09844523668289185\n",
      "Epoch [9/10] Batch [392/469] Loss D: -0.5061070322990417, loss G: -0.3729017972946167\n",
      "Epoch [9/10] Batch [393/469] Loss D: -0.4896836280822754, loss G: -0.10066530853509903\n",
      "Epoch [9/10] Batch [394/469] Loss D: -0.5221681594848633, loss G: -0.2687092423439026\n",
      "Epoch [9/10] Batch [395/469] Loss D: -0.5790369510650635, loss G: -0.1506233811378479\n",
      "Epoch [9/10] Batch [396/469] Loss D: -0.6006617546081543, loss G: -0.17813676595687866\n",
      "Epoch [9/10] Batch [397/469] Loss D: -0.6121482849121094, loss G: -0.09469392150640488\n",
      "Epoch [9/10] Batch [398/469] Loss D: -0.599014401435852, loss G: -0.3184148371219635\n",
      "Epoch [9/10] Batch [399/469] Loss D: -0.470072865486145, loss G: -0.05902619659900665\n",
      "Epoch [9/10] Batch [400/469] Loss D: -0.4790767729282379, loss G: -0.23429913818836212\n",
      "Epoch [9/10] Batch [401/469] Loss D: -0.6026721596717834, loss G: -0.05971354618668556\n",
      "Epoch [9/10] Batch [402/469] Loss D: -0.5540792942047119, loss G: -0.3807324469089508\n",
      "Epoch [9/10] Batch [403/469] Loss D: -0.3847903609275818, loss G: -0.1425141990184784\n",
      "Epoch [9/10] Batch [404/469] Loss D: -0.6254967451095581, loss G: -0.10590662062168121\n",
      "Epoch [9/10] Batch [405/469] Loss D: -0.5697376728057861, loss G: -0.42168983817100525\n",
      "Epoch [9/10] Batch [406/469] Loss D: -0.4598812460899353, loss G: -0.14961519837379456\n",
      "Epoch [9/10] Batch [407/469] Loss D: -0.6012152433395386, loss G: -0.10914620757102966\n",
      "Epoch [9/10] Batch [408/469] Loss D: -0.4467022716999054, loss G: -0.4095379710197449\n",
      "Epoch [9/10] Batch [409/469] Loss D: -0.48079636693000793, loss G: -0.05379602313041687\n",
      "Epoch [9/10] Batch [410/469] Loss D: -0.4711087942123413, loss G: -0.2816225290298462\n",
      "Epoch [9/10] Batch [411/469] Loss D: -0.6320010423660278, loss G: -0.10365819931030273\n",
      "Epoch [9/10] Batch [412/469] Loss D: -0.5292863845825195, loss G: -0.2695761024951935\n",
      "Epoch [9/10] Batch [413/469] Loss D: -0.6061052680015564, loss G: -0.09579730033874512\n",
      "Epoch [9/10] Batch [414/469] Loss D: -0.550787627696991, loss G: -0.30955344438552856\n",
      "Epoch [9/10] Batch [415/469] Loss D: -0.5636376738548279, loss G: -0.059333983808755875\n",
      "Epoch [9/10] Batch [416/469] Loss D: -0.33104947209358215, loss G: -0.22693726420402527\n",
      "Epoch [9/10] Batch [417/469] Loss D: -0.5385131239891052, loss G: -0.32694172859191895\n",
      "Epoch [9/10] Batch [418/469] Loss D: -0.4933845102787018, loss G: -0.0727216824889183\n",
      "Epoch [9/10] Batch [419/469] Loss D: -0.41137242317199707, loss G: -0.1490045189857483\n",
      "Epoch [9/10] Batch [420/469] Loss D: -0.5927203893661499, loss G: -0.3650543987751007\n",
      "Epoch [9/10] Batch [421/469] Loss D: -0.5752899646759033, loss G: -0.06065237522125244\n",
      "Epoch [9/10] Batch [422/469] Loss D: -0.557960569858551, loss G: -0.20910850167274475\n",
      "Epoch [9/10] Batch [423/469] Loss D: -0.4959387183189392, loss G: -0.18636420369148254\n",
      "Epoch [9/10] Batch [424/469] Loss D: -0.6011978387832642, loss G: -0.1451309621334076\n",
      "Epoch [9/10] Batch [425/469] Loss D: -0.5026518106460571, loss G: -0.3045443296432495\n",
      "Epoch [9/10] Batch [426/469] Loss D: -0.5071266889572144, loss G: -0.09192341566085815\n",
      "Epoch [9/10] Batch [427/469] Loss D: -0.47815901041030884, loss G: -0.282668799161911\n",
      "Epoch [9/10] Batch [428/469] Loss D: -0.5068836212158203, loss G: -0.11660440266132355\n",
      "Epoch [9/10] Batch [429/469] Loss D: -0.604621171951294, loss G: -0.2316361963748932\n",
      "Epoch [9/10] Batch [430/469] Loss D: -0.53038489818573, loss G: -0.15233606100082397\n",
      "Epoch [9/10] Batch [431/469] Loss D: -0.5370907783508301, loss G: -0.1972535252571106\n",
      "Epoch [9/10] Batch [432/469] Loss D: -0.6051076650619507, loss G: -0.13228225708007812\n",
      "Epoch [9/10] Batch [433/469] Loss D: -0.6083176136016846, loss G: -0.16346988081932068\n",
      "Epoch [9/10] Batch [434/469] Loss D: -0.6185822486877441, loss G: -0.12998582422733307\n",
      "Epoch [9/10] Batch [435/469] Loss D: -0.6424908638000488, loss G: -0.16568660736083984\n",
      "Epoch [9/10] Batch [436/469] Loss D: -0.620256245136261, loss G: -0.1125827431678772\n",
      "Epoch [9/10] Batch [437/469] Loss D: -0.5700610876083374, loss G: -0.10818655788898468\n",
      "Epoch [9/10] Batch [438/469] Loss D: -0.5772359371185303, loss G: -0.26881080865859985\n",
      "Epoch [9/10] Batch [439/469] Loss D: -0.6253839135169983, loss G: -0.11077079176902771\n",
      "Epoch [9/10] Batch [440/469] Loss D: -0.5669456124305725, loss G: -0.23820525407791138\n",
      "Epoch [9/10] Batch [441/469] Loss D: -0.47128719091415405, loss G: -0.16374588012695312\n",
      "Epoch [9/10] Batch [442/469] Loss D: -0.5104174017906189, loss G: -0.2677852511405945\n",
      "Epoch [9/10] Batch [443/469] Loss D: -0.4985917806625366, loss G: -0.12762333452701569\n",
      "Epoch [9/10] Batch [444/469] Loss D: -0.48102930188179016, loss G: -0.22446393966674805\n",
      "Epoch [9/10] Batch [445/469] Loss D: -0.4970338046550751, loss G: -0.12998420000076294\n",
      "Epoch [9/10] Batch [446/469] Loss D: -0.5356072187423706, loss G: -0.225172221660614\n",
      "Epoch [9/10] Batch [447/469] Loss D: -0.6124991178512573, loss G: -0.10310571640729904\n",
      "Epoch [9/10] Batch [448/469] Loss D: -0.6222954988479614, loss G: -0.2405143827199936\n",
      "Epoch [9/10] Batch [449/469] Loss D: -0.5097212195396423, loss G: -0.174002006649971\n",
      "Epoch [9/10] Batch [450/469] Loss D: -0.5967923402786255, loss G: -0.15041661262512207\n",
      "Epoch [9/10] Batch [451/469] Loss D: -0.5489787459373474, loss G: -0.23362773656845093\n",
      "Epoch [9/10] Batch [452/469] Loss D: -0.5750061869621277, loss G: -0.058216407895088196\n",
      "Epoch [9/10] Batch [453/469] Loss D: -0.4781605899333954, loss G: -0.30794671177864075\n",
      "Epoch [9/10] Batch [454/469] Loss D: -0.5727728009223938, loss G: -0.10132535547018051\n",
      "Epoch [9/10] Batch [455/469] Loss D: -0.6192519664764404, loss G: -0.1933809220790863\n",
      "Epoch [9/10] Batch [456/469] Loss D: -0.59783536195755, loss G: -0.11609496176242828\n",
      "Epoch [9/10] Batch [457/469] Loss D: -0.5185438394546509, loss G: -0.2670535445213318\n",
      "Epoch [9/10] Batch [458/469] Loss D: -0.5473068356513977, loss G: -0.16558419167995453\n",
      "Epoch [9/10] Batch [459/469] Loss D: -0.5648027658462524, loss G: -0.1354925036430359\n",
      "Epoch [9/10] Batch [460/469] Loss D: -0.6191954612731934, loss G: -0.19725099205970764\n",
      "Epoch [9/10] Batch [461/469] Loss D: -0.6036980152130127, loss G: -0.13717783987522125\n",
      "Epoch [9/10] Batch [462/469] Loss D: -0.5714970827102661, loss G: -0.2831703722476959\n",
      "Epoch [9/10] Batch [463/469] Loss D: -0.5548313856124878, loss G: -0.10688485205173492\n",
      "Epoch [9/10] Batch [464/469] Loss D: -0.5775673985481262, loss G: -0.13857701420783997\n",
      "Epoch [9/10] Batch [465/469] Loss D: -0.6000330448150635, loss G: -0.33863869309425354\n",
      "Epoch [9/10] Batch [466/469] Loss D: -0.593210756778717, loss G: -0.05243658274412155\n",
      "Epoch [9/10] Batch [467/469] Loss D: -0.4497131109237671, loss G: -0.25458797812461853\n",
      "Epoch [9/10] Batch [468/469] Loss D: -0.6014729738235474, loss G: -0.2121969610452652\n",
      "Epoch [9/10] Batch [469/469] Loss D: -0.439155638217926, loss G: -0.13468864560127258\n",
      "Epoch [10/10] Batch [1/469] Loss D: -0.5322878956794739, loss G: -0.15984511375427246\n",
      "Epoch [10/10] Batch [2/469] Loss D: -0.5170853137969971, loss G: -0.27931487560272217\n",
      "Epoch [10/10] Batch [3/469] Loss D: -0.4154987931251526, loss G: -0.20222526788711548\n",
      "Epoch [10/10] Batch [4/469] Loss D: -0.5597724914550781, loss G: -0.1545071005821228\n",
      "Epoch [10/10] Batch [5/469] Loss D: -0.5466235876083374, loss G: -0.1939937323331833\n",
      "Epoch [10/10] Batch [6/469] Loss D: -0.5940344333648682, loss G: -0.14054074883460999\n",
      "Epoch [10/10] Batch [7/469] Loss D: -0.6127998232841492, loss G: -0.11009421199560165\n",
      "Epoch [10/10] Batch [8/469] Loss D: -0.5856389403343201, loss G: -0.2860417366027832\n",
      "Epoch [10/10] Batch [9/469] Loss D: -0.632044792175293, loss G: -0.07406039535999298\n",
      "Epoch [10/10] Batch [10/469] Loss D: -0.5693236589431763, loss G: -0.19602249562740326\n",
      "Epoch [10/10] Batch [11/469] Loss D: -0.7059369087219238, loss G: -0.15877896547317505\n",
      "Epoch [10/10] Batch [12/469] Loss D: -0.5317102670669556, loss G: -0.10287103056907654\n",
      "Epoch [10/10] Batch [13/469] Loss D: -0.546047031879425, loss G: -0.2915210723876953\n",
      "Epoch [10/10] Batch [14/469] Loss D: -0.5257601737976074, loss G: -0.10810689628124237\n",
      "Epoch [10/10] Batch [15/469] Loss D: -0.547235369682312, loss G: -0.2755855619907379\n",
      "Epoch [10/10] Batch [16/469] Loss D: -0.484530508518219, loss G: -0.15707272291183472\n",
      "Epoch [10/10] Batch [17/469] Loss D: -0.508514940738678, loss G: -0.20000478625297546\n",
      "Epoch [10/10] Batch [18/469] Loss D: -0.4911348223686218, loss G: -0.30457884073257446\n",
      "Epoch [10/10] Batch [19/469] Loss D: -0.5598195195198059, loss G: -0.0648840069770813\n",
      "Epoch [10/10] Batch [20/469] Loss D: -0.5291587710380554, loss G: -0.26972392201423645\n",
      "Epoch [10/10] Batch [21/469] Loss D: -0.5053317546844482, loss G: -0.20252366364002228\n",
      "Epoch [10/10] Batch [22/469] Loss D: -0.6258066296577454, loss G: -0.06052657961845398\n",
      "Epoch [10/10] Batch [23/469] Loss D: -0.6000356078147888, loss G: -0.3223101496696472\n",
      "Epoch [10/10] Batch [24/469] Loss D: -0.5386280417442322, loss G: -0.06204850971698761\n",
      "Epoch [10/10] Batch [25/469] Loss D: -0.6075219511985779, loss G: -0.21419887244701385\n",
      "Epoch [10/10] Batch [26/469] Loss D: -0.48344290256500244, loss G: -0.3187864422798157\n",
      "Epoch [10/10] Batch [27/469] Loss D: -0.4607490301132202, loss G: -0.07205066084861755\n",
      "Epoch [10/10] Batch [28/469] Loss D: -0.4950920641422272, loss G: -0.26356929540634155\n",
      "Epoch [10/10] Batch [29/469] Loss D: -0.549983024597168, loss G: -0.2791785001754761\n",
      "Epoch [10/10] Batch [30/469] Loss D: -0.48789310455322266, loss G: -0.06240469217300415\n",
      "Epoch [10/10] Batch [31/469] Loss D: -0.4497242569923401, loss G: -0.25889119505882263\n",
      "Epoch [10/10] Batch [32/469] Loss D: -0.4626418352127075, loss G: -0.2896430492401123\n",
      "Epoch [10/10] Batch [33/469] Loss D: -0.570192813873291, loss G: -0.07555612921714783\n",
      "Epoch [10/10] Batch [34/469] Loss D: -0.5006152391433716, loss G: -0.30598971247673035\n",
      "Epoch [10/10] Batch [35/469] Loss D: -0.5671143531799316, loss G: -0.11994689702987671\n",
      "Epoch [10/10] Batch [36/469] Loss D: -0.6407912373542786, loss G: -0.14147555828094482\n",
      "Epoch [10/10] Batch [37/469] Loss D: -0.5938705205917358, loss G: -0.1791536808013916\n",
      "Epoch [10/10] Batch [38/469] Loss D: -0.624476432800293, loss G: -0.16144171357154846\n",
      "Epoch [10/10] Batch [39/469] Loss D: -0.6214405298233032, loss G: -0.11949799209833145\n",
      "Epoch [10/10] Batch [40/469] Loss D: -0.6132479310035706, loss G: -0.20726823806762695\n",
      "Epoch [10/10] Batch [41/469] Loss D: -0.4982410669326782, loss G: -0.15840382874011993\n",
      "Epoch [10/10] Batch [42/469] Loss D: -0.612074613571167, loss G: -0.10399717092514038\n",
      "Epoch [10/10] Batch [43/469] Loss D: -0.6163336634635925, loss G: -0.27747684717178345\n",
      "Epoch [10/10] Batch [44/469] Loss D: -0.5166348218917847, loss G: -0.1550350934267044\n",
      "Epoch [10/10] Batch [45/469] Loss D: -0.5739884376525879, loss G: -0.09961254894733429\n",
      "Epoch [10/10] Batch [46/469] Loss D: -0.5209861397743225, loss G: -0.28894472122192383\n",
      "Epoch [10/10] Batch [47/469] Loss D: -0.5382164716720581, loss G: -0.08557067811489105\n",
      "Epoch [10/10] Batch [48/469] Loss D: -0.5926536321640015, loss G: -0.2233845591545105\n",
      "Epoch [10/10] Batch [49/469] Loss D: -0.6104394197463989, loss G: -0.14367589354515076\n",
      "Epoch [10/10] Batch [50/469] Loss D: -0.5693143606185913, loss G: -0.15493197739124298\n",
      "Epoch [10/10] Batch [51/469] Loss D: -0.6171529293060303, loss G: -0.12995433807373047\n",
      "Epoch [10/10] Batch [52/469] Loss D: -0.5825890302658081, loss G: -0.21060189604759216\n",
      "Epoch [10/10] Batch [53/469] Loss D: -0.650254487991333, loss G: -0.17604491114616394\n",
      "Epoch [10/10] Batch [54/469] Loss D: -0.5448311567306519, loss G: -0.11194474995136261\n",
      "Epoch [10/10] Batch [55/469] Loss D: -0.593658447265625, loss G: -0.22191140055656433\n",
      "Epoch [10/10] Batch [56/469] Loss D: -0.5716997385025024, loss G: -0.14715921878814697\n",
      "Epoch [10/10] Batch [57/469] Loss D: -0.5582745671272278, loss G: -0.20972898602485657\n",
      "Epoch [10/10] Batch [58/469] Loss D: -0.6674181222915649, loss G: -0.10056952387094498\n",
      "Epoch [10/10] Batch [59/469] Loss D: -0.5352588295936584, loss G: -0.38799941539764404\n",
      "Epoch [10/10] Batch [60/469] Loss D: -0.3816273808479309, loss G: -0.1416226029396057\n",
      "Epoch [10/10] Batch [61/469] Loss D: -0.5533790588378906, loss G: -0.11929914355278015\n",
      "Epoch [10/10] Batch [62/469] Loss D: -0.5796398520469666, loss G: -0.22362208366394043\n",
      "Epoch [10/10] Batch [63/469] Loss D: -0.5774505734443665, loss G: -0.14527922868728638\n",
      "Epoch [10/10] Batch [64/469] Loss D: -0.5963971614837646, loss G: -0.21576911211013794\n",
      "Epoch [10/10] Batch [65/469] Loss D: -0.6264341473579407, loss G: -0.07218229025602341\n",
      "Epoch [10/10] Batch [66/469] Loss D: -0.5770223140716553, loss G: -0.23213046789169312\n",
      "Epoch [10/10] Batch [67/469] Loss D: -0.5801123380661011, loss G: -0.14701159298419952\n",
      "Epoch [10/10] Batch [68/469] Loss D: -0.594367265701294, loss G: -0.1399872899055481\n",
      "Epoch [10/10] Batch [69/469] Loss D: -0.6404556035995483, loss G: -0.14705289900302887\n",
      "Epoch [10/10] Batch [70/469] Loss D: -0.5764012336730957, loss G: -0.18027853965759277\n",
      "Epoch [10/10] Batch [71/469] Loss D: -0.6190626621246338, loss G: -0.08199761807918549\n",
      "Epoch [10/10] Batch [72/469] Loss D: -0.41725462675094604, loss G: -0.38562604784965515\n",
      "Epoch [10/10] Batch [73/469] Loss D: -0.5554718971252441, loss G: -0.06916084885597229\n",
      "Epoch [10/10] Batch [74/469] Loss D: -0.5576320886611938, loss G: -0.2630176544189453\n",
      "Epoch [10/10] Batch [75/469] Loss D: -0.4874840974807739, loss G: -0.13250303268432617\n",
      "Epoch [10/10] Batch [76/469] Loss D: -0.5155576467514038, loss G: -0.2839135527610779\n",
      "Epoch [10/10] Batch [77/469] Loss D: -0.6101121306419373, loss G: -0.05247538536787033\n",
      "Epoch [10/10] Batch [78/469] Loss D: -0.4737670421600342, loss G: -0.246101975440979\n",
      "Epoch [10/10] Batch [79/469] Loss D: -0.4854305386543274, loss G: -0.1993924379348755\n",
      "Epoch [10/10] Batch [80/469] Loss D: -0.6339513063430786, loss G: -0.07738611102104187\n",
      "Epoch [10/10] Batch [81/469] Loss D: -0.5299587845802307, loss G: -0.36498066782951355\n",
      "Epoch [10/10] Batch [82/469] Loss D: -0.5080552697181702, loss G: -0.05688067153096199\n",
      "Epoch [10/10] Batch [83/469] Loss D: -0.5867759585380554, loss G: -0.22803287208080292\n",
      "Epoch [10/10] Batch [84/469] Loss D: -0.5761653780937195, loss G: -0.20370030403137207\n",
      "Epoch [10/10] Batch [85/469] Loss D: -0.5961431264877319, loss G: -0.07376305758953094\n",
      "Epoch [10/10] Batch [86/469] Loss D: -0.6442025899887085, loss G: -0.26310598850250244\n",
      "Epoch [10/10] Batch [87/469] Loss D: -0.5516157150268555, loss G: -0.07186269760131836\n",
      "Epoch [10/10] Batch [88/469] Loss D: -0.48305606842041016, loss G: -0.3017599582672119\n",
      "Epoch [10/10] Batch [89/469] Loss D: -0.5925783514976501, loss G: -0.10462501645088196\n",
      "Epoch [10/10] Batch [90/469] Loss D: -0.500585675239563, loss G: -0.2115575224161148\n",
      "Epoch [10/10] Batch [91/469] Loss D: -0.5961840152740479, loss G: -0.19280096888542175\n",
      "Epoch [10/10] Batch [92/469] Loss D: -0.569780707359314, loss G: -0.08855344355106354\n",
      "Epoch [10/10] Batch [93/469] Loss D: -0.6121597290039062, loss G: -0.2470693737268448\n",
      "Epoch [10/10] Batch [94/469] Loss D: -0.5940477848052979, loss G: -0.12520605325698853\n",
      "Epoch [10/10] Batch [95/469] Loss D: -0.5874213576316833, loss G: -0.26970118284225464\n",
      "Epoch [10/10] Batch [96/469] Loss D: -0.44143763184547424, loss G: -0.1507032960653305\n",
      "Epoch [10/10] Batch [97/469] Loss D: -0.5188584923744202, loss G: -0.2530411183834076\n",
      "Epoch [10/10] Batch [98/469] Loss D: -0.5865171551704407, loss G: -0.19095657765865326\n",
      "Epoch [10/10] Batch [99/469] Loss D: -0.545910120010376, loss G: -0.20191267132759094\n",
      "Epoch [10/10] Batch [100/469] Loss D: -0.5397775173187256, loss G: -0.12998802959918976\n",
      "Epoch [10/10] Batch [101/469] Loss D: -0.5800745487213135, loss G: -0.1850968897342682\n",
      "Epoch [10/10] Batch [102/469] Loss D: -0.5839123725891113, loss G: -0.17840753495693207\n",
      "Epoch [10/10] Batch [103/469] Loss D: -0.6150268316268921, loss G: -0.131545752286911\n",
      "Epoch [10/10] Batch [104/469] Loss D: -0.5907862782478333, loss G: -0.2146516740322113\n",
      "Epoch [10/10] Batch [105/469] Loss D: -0.5969435572624207, loss G: -0.0949191153049469\n",
      "Epoch [10/10] Batch [106/469] Loss D: -0.5564061999320984, loss G: -0.3047482967376709\n",
      "Epoch [10/10] Batch [107/469] Loss D: -0.5594212412834167, loss G: -0.10704202204942703\n",
      "Epoch [10/10] Batch [108/469] Loss D: -0.6105866432189941, loss G: -0.16133703291416168\n",
      "Epoch [10/10] Batch [109/469] Loss D: -0.6137642860412598, loss G: -0.21650777757167816\n",
      "Epoch [10/10] Batch [110/469] Loss D: -0.5669183135032654, loss G: -0.08960150182247162\n",
      "Epoch [10/10] Batch [111/469] Loss D: -0.5692926049232483, loss G: -0.24122706055641174\n",
      "Epoch [10/10] Batch [112/469] Loss D: -0.631345272064209, loss G: -0.10548631846904755\n",
      "Epoch [10/10] Batch [113/469] Loss D: -0.546584963798523, loss G: -0.2741735279560089\n",
      "Epoch [10/10] Batch [114/469] Loss D: -0.6154850721359253, loss G: -0.07129700481891632\n",
      "Epoch [10/10] Batch [115/469] Loss D: -0.6566078662872314, loss G: -0.09681485593318939\n",
      "Epoch [10/10] Batch [116/469] Loss D: -0.5357653498649597, loss G: -0.4488500952720642\n",
      "Epoch [10/10] Batch [117/469] Loss D: -0.36658334732055664, loss G: -0.16357098519802094\n",
      "Epoch [10/10] Batch [118/469] Loss D: -0.5744063854217529, loss G: -0.1408175528049469\n",
      "Epoch [10/10] Batch [119/469] Loss D: -0.5705982446670532, loss G: -0.23913559317588806\n",
      "Epoch [10/10] Batch [120/469] Loss D: -0.5504001379013062, loss G: -0.2275281548500061\n",
      "Epoch [10/10] Batch [121/469] Loss D: -0.5254197120666504, loss G: -0.06089169159531593\n",
      "Epoch [10/10] Batch [122/469] Loss D: -0.48366329073905945, loss G: -0.2577337622642517\n",
      "Epoch [10/10] Batch [123/469] Loss D: -0.6060065031051636, loss G: -0.2565128803253174\n",
      "Epoch [10/10] Batch [124/469] Loss D: -0.487537145614624, loss G: -0.12410679459571838\n",
      "Epoch [10/10] Batch [125/469] Loss D: -0.5971515774726868, loss G: -0.23302075266838074\n",
      "Epoch [10/10] Batch [126/469] Loss D: -0.6028110980987549, loss G: -0.12034323811531067\n",
      "Epoch [10/10] Batch [127/469] Loss D: -0.6001689434051514, loss G: -0.20560139417648315\n",
      "Epoch [10/10] Batch [128/469] Loss D: -0.6060630083084106, loss G: -0.1289580762386322\n",
      "Epoch [10/10] Batch [129/469] Loss D: -0.6235090494155884, loss G: -0.18225817382335663\n",
      "Epoch [10/10] Batch [130/469] Loss D: -0.6099387407302856, loss G: -0.11663380265235901\n",
      "Epoch [10/10] Batch [131/469] Loss D: -0.4972543716430664, loss G: -0.3943091630935669\n",
      "Epoch [10/10] Batch [132/469] Loss D: -0.4946759343147278, loss G: -0.10931587219238281\n",
      "Epoch [10/10] Batch [133/469] Loss D: -0.5186829566955566, loss G: -0.20211458206176758\n",
      "Epoch [10/10] Batch [134/469] Loss D: -0.5732202529907227, loss G: -0.1136070042848587\n",
      "Epoch [10/10] Batch [135/469] Loss D: -0.5460333824157715, loss G: -0.19515849649906158\n",
      "Epoch [10/10] Batch [136/469] Loss D: -0.6378260254859924, loss G: -0.21671590209007263\n",
      "Epoch [10/10] Batch [137/469] Loss D: -0.5667012929916382, loss G: -0.09939267486333847\n",
      "Epoch [10/10] Batch [138/469] Loss D: -0.5880883932113647, loss G: -0.2641124129295349\n",
      "Epoch [10/10] Batch [139/469] Loss D: -0.512932538986206, loss G: -0.1516454815864563\n",
      "Epoch [10/10] Batch [140/469] Loss D: -0.5200585126876831, loss G: -0.18106207251548767\n",
      "Epoch [10/10] Batch [141/469] Loss D: -0.628940999507904, loss G: -0.18674024939537048\n",
      "Epoch [10/10] Batch [142/469] Loss D: -0.6153140068054199, loss G: -0.06787635385990143\n",
      "Epoch [10/10] Batch [143/469] Loss D: -0.6062615513801575, loss G: -0.29472270607948303\n",
      "Epoch [10/10] Batch [144/469] Loss D: -0.5671972036361694, loss G: -0.08851198852062225\n",
      "Epoch [10/10] Batch [145/469] Loss D: -0.6467291116714478, loss G: -0.14542582631111145\n",
      "Epoch [10/10] Batch [146/469] Loss D: -0.5429635643959045, loss G: -0.1988447606563568\n",
      "Epoch [10/10] Batch [147/469] Loss D: -0.5485326647758484, loss G: -0.2735171318054199\n",
      "Epoch [10/10] Batch [148/469] Loss D: -0.48400238156318665, loss G: -0.09262734651565552\n",
      "Epoch [10/10] Batch [149/469] Loss D: -0.5325606465339661, loss G: -0.28475692868232727\n",
      "Epoch [10/10] Batch [150/469] Loss D: -0.5796346068382263, loss G: -0.09046196937561035\n",
      "Epoch [10/10] Batch [151/469] Loss D: -0.6245102882385254, loss G: -0.21243572235107422\n",
      "Epoch [10/10] Batch [152/469] Loss D: -0.5704498291015625, loss G: -0.10441598296165466\n",
      "Epoch [10/10] Batch [153/469] Loss D: -0.5732992887496948, loss G: -0.24471977353096008\n",
      "Epoch [10/10] Batch [154/469] Loss D: -0.48076093196868896, loss G: -0.10989440232515335\n",
      "Epoch [10/10] Batch [155/469] Loss D: -0.5750939846038818, loss G: -0.28968948125839233\n",
      "Epoch [10/10] Batch [156/469] Loss D: -0.49865978956222534, loss G: -0.09604305028915405\n",
      "Epoch [10/10] Batch [157/469] Loss D: -0.5676041841506958, loss G: -0.2684658169746399\n",
      "Epoch [10/10] Batch [158/469] Loss D: -0.41991811990737915, loss G: -0.17972564697265625\n",
      "Epoch [10/10] Batch [159/469] Loss D: -0.5816588997840881, loss G: -0.18791332840919495\n",
      "Epoch [10/10] Batch [160/469] Loss D: -0.6058336496353149, loss G: -0.08980396389961243\n",
      "Epoch [10/10] Batch [161/469] Loss D: -0.5291339159011841, loss G: -0.34425005316734314\n",
      "Epoch [10/10] Batch [162/469] Loss D: -0.5268986225128174, loss G: -0.11788976937532425\n",
      "Epoch [10/10] Batch [163/469] Loss D: -0.6104534268379211, loss G: -0.15336918830871582\n",
      "Epoch [10/10] Batch [164/469] Loss D: -0.6833397150039673, loss G: -0.1539878249168396\n",
      "Epoch [10/10] Batch [165/469] Loss D: -0.5654892921447754, loss G: -0.17013657093048096\n",
      "Epoch [10/10] Batch [166/469] Loss D: -0.653122067451477, loss G: -0.07516241073608398\n",
      "Epoch [10/10] Batch [167/469] Loss D: -0.5800498127937317, loss G: -0.38881778717041016\n",
      "Epoch [10/10] Batch [168/469] Loss D: -0.5096501111984253, loss G: -0.12605427205562592\n",
      "Epoch [10/10] Batch [169/469] Loss D: -0.6063618659973145, loss G: -0.06599172949790955\n",
      "Epoch [10/10] Batch [170/469] Loss D: -0.48607969284057617, loss G: -0.40716636180877686\n",
      "Epoch [10/10] Batch [171/469] Loss D: -0.473020076751709, loss G: -0.0949934720993042\n",
      "Epoch [10/10] Batch [172/469] Loss D: -0.5411782264709473, loss G: -0.20540431141853333\n",
      "Epoch [10/10] Batch [173/469] Loss D: -0.5787665843963623, loss G: -0.15610221028327942\n",
      "Epoch [10/10] Batch [174/469] Loss D: -0.5159134268760681, loss G: -0.15123680233955383\n",
      "Epoch [10/10] Batch [175/469] Loss D: -0.580102801322937, loss G: -0.2359769344329834\n",
      "Epoch [10/10] Batch [176/469] Loss D: -0.5228487849235535, loss G: -0.2052893340587616\n",
      "Epoch [10/10] Batch [177/469] Loss D: -0.5419528484344482, loss G: -0.15032832324504852\n",
      "Epoch [10/10] Batch [178/469] Loss D: -0.5644482374191284, loss G: -0.17109671235084534\n",
      "Epoch [10/10] Batch [179/469] Loss D: -0.5809155702590942, loss G: -0.23484034836292267\n",
      "Epoch [10/10] Batch [180/469] Loss D: -0.5854772329330444, loss G: -0.10862194746732712\n",
      "Epoch [10/10] Batch [181/469] Loss D: -0.6517314910888672, loss G: -0.11433832347393036\n",
      "Epoch [10/10] Batch [182/469] Loss D: -0.6351044774055481, loss G: -0.18302461504936218\n",
      "Epoch [10/10] Batch [183/469] Loss D: -0.6323062777519226, loss G: -0.12323734164237976\n",
      "Epoch [10/10] Batch [184/469] Loss D: -0.5757031440734863, loss G: -0.18792349100112915\n",
      "Epoch [10/10] Batch [185/469] Loss D: -0.6241283416748047, loss G: -0.14157909154891968\n",
      "Epoch [10/10] Batch [186/469] Loss D: -0.6170667409896851, loss G: -0.14606225490570068\n",
      "Epoch [10/10] Batch [187/469] Loss D: -0.4998118281364441, loss G: -0.16133840382099152\n",
      "Epoch [10/10] Batch [188/469] Loss D: -0.6715927124023438, loss G: -0.10954646021127701\n",
      "Epoch [10/10] Batch [189/469] Loss D: -0.6365488767623901, loss G: -0.2194284051656723\n",
      "Epoch [10/10] Batch [190/469] Loss D: -0.5352391004562378, loss G: -0.083999864757061\n",
      "Epoch [10/10] Batch [191/469] Loss D: -0.6851270794868469, loss G: -0.18507283926010132\n",
      "Epoch [10/10] Batch [192/469] Loss D: -0.5925540924072266, loss G: -0.1632901430130005\n",
      "Epoch [10/10] Batch [193/469] Loss D: -0.5817207098007202, loss G: -0.08968115597963333\n",
      "Epoch [10/10] Batch [194/469] Loss D: -0.4573672115802765, loss G: -0.4024655520915985\n",
      "Epoch [10/10] Batch [195/469] Loss D: -0.43455976247787476, loss G: -0.1049710363149643\n",
      "Epoch [10/10] Batch [196/469] Loss D: -0.4922887682914734, loss G: -0.2508247494697571\n",
      "Epoch [10/10] Batch [197/469] Loss D: -0.6606716513633728, loss G: -0.07601988315582275\n",
      "Epoch [10/10] Batch [198/469] Loss D: -0.5643540024757385, loss G: -0.2181701362133026\n",
      "Epoch [10/10] Batch [199/469] Loss D: -0.5600355863571167, loss G: -0.09354431182146072\n",
      "Epoch [10/10] Batch [200/469] Loss D: -0.6096792221069336, loss G: -0.2206907570362091\n",
      "Epoch [10/10] Batch [201/469] Loss D: -0.6474905014038086, loss G: -0.08179720491170883\n",
      "Epoch [10/10] Batch [202/469] Loss D: -0.6274998188018799, loss G: -0.09666739404201508\n",
      "Epoch [10/10] Batch [203/469] Loss D: -0.6527947187423706, loss G: -0.2550397515296936\n",
      "Epoch [10/10] Batch [204/469] Loss D: -0.5432838797569275, loss G: -0.11356396228075027\n",
      "Epoch [10/10] Batch [205/469] Loss D: -0.5555871725082397, loss G: -0.18829572200775146\n",
      "Epoch [10/10] Batch [206/469] Loss D: -0.5915308594703674, loss G: -0.18493729829788208\n",
      "Epoch [10/10] Batch [207/469] Loss D: -0.5452012419700623, loss G: -0.09136077761650085\n",
      "Epoch [10/10] Batch [208/469] Loss D: -0.5418726205825806, loss G: -0.24801403284072876\n",
      "Epoch [10/10] Batch [209/469] Loss D: -0.6122145652770996, loss G: -0.13741743564605713\n",
      "Epoch [10/10] Batch [210/469] Loss D: -0.5371721982955933, loss G: -0.11120805889368057\n",
      "Epoch [10/10] Batch [211/469] Loss D: -0.5483983755111694, loss G: -0.33874934911727905\n",
      "Epoch [10/10] Batch [212/469] Loss D: -0.44607120752334595, loss G: -0.09520245343446732\n",
      "Epoch [10/10] Batch [213/469] Loss D: -0.4584443271160126, loss G: -0.24494703114032745\n",
      "Epoch [10/10] Batch [214/469] Loss D: -0.45630955696105957, loss G: -0.1600261777639389\n",
      "Epoch [10/10] Batch [215/469] Loss D: -0.4941673278808594, loss G: -0.3250913619995117\n",
      "Epoch [10/10] Batch [216/469] Loss D: -0.5432286858558655, loss G: -0.06920218467712402\n",
      "Epoch [10/10] Batch [217/469] Loss D: -0.5938822031021118, loss G: -0.22571083903312683\n",
      "Epoch [10/10] Batch [218/469] Loss D: -0.5524851083755493, loss G: -0.12688131630420685\n",
      "Epoch [10/10] Batch [219/469] Loss D: -0.6414821743965149, loss G: -0.14105433225631714\n",
      "Epoch [10/10] Batch [220/469] Loss D: -0.6233254671096802, loss G: -0.13757021725177765\n",
      "Epoch [10/10] Batch [221/469] Loss D: -0.5932268500328064, loss G: -0.2067371904850006\n",
      "Epoch [10/10] Batch [222/469] Loss D: -0.5361664891242981, loss G: -0.15676426887512207\n",
      "Epoch [10/10] Batch [223/469] Loss D: -0.620163083076477, loss G: -0.11879948526620865\n",
      "Epoch [10/10] Batch [224/469] Loss D: -0.6038306951522827, loss G: -0.16391277313232422\n",
      "Epoch [10/10] Batch [225/469] Loss D: -0.6432108879089355, loss G: -0.12766999006271362\n",
      "Epoch [10/10] Batch [226/469] Loss D: -0.5874500274658203, loss G: -0.1439627856016159\n",
      "Epoch [10/10] Batch [227/469] Loss D: -0.4877568185329437, loss G: -0.27163976430892944\n",
      "Epoch [10/10] Batch [228/469] Loss D: -0.5821709632873535, loss G: -0.0979352816939354\n",
      "Epoch [10/10] Batch [229/469] Loss D: -0.6124751567840576, loss G: -0.25580301880836487\n",
      "Epoch [10/10] Batch [230/469] Loss D: -0.6364718675613403, loss G: -0.08586597442626953\n",
      "Epoch [10/10] Batch [231/469] Loss D: -0.6316230893135071, loss G: -0.13147377967834473\n",
      "Epoch [10/10] Batch [232/469] Loss D: -0.57900071144104, loss G: -0.2022986114025116\n",
      "Epoch [10/10] Batch [233/469] Loss D: -0.591866672039032, loss G: -0.141166552901268\n",
      "Epoch [10/10] Batch [234/469] Loss D: -0.6096495389938354, loss G: -0.18522515892982483\n",
      "Epoch [10/10] Batch [235/469] Loss D: -0.5791603922843933, loss G: -0.11863047629594803\n",
      "Epoch [10/10] Batch [236/469] Loss D: -0.5585128664970398, loss G: -0.16409803926944733\n",
      "Epoch [10/10] Batch [237/469] Loss D: -0.5225059986114502, loss G: -0.3224497437477112\n",
      "Epoch [10/10] Batch [238/469] Loss D: -0.5186682939529419, loss G: -0.08684182167053223\n",
      "Epoch [10/10] Batch [239/469] Loss D: -0.5410681366920471, loss G: -0.27426499128341675\n",
      "Epoch [10/10] Batch [240/469] Loss D: -0.5319540500640869, loss G: -0.13930223882198334\n",
      "Epoch [10/10] Batch [241/469] Loss D: -0.5808226466178894, loss G: -0.18730676174163818\n",
      "Epoch [10/10] Batch [242/469] Loss D: -0.5958766341209412, loss G: -0.1907203495502472\n",
      "Epoch [10/10] Batch [243/469] Loss D: -0.587989091873169, loss G: -0.10040508210659027\n",
      "Epoch [10/10] Batch [244/469] Loss D: -0.544496476650238, loss G: -0.3395128548145294\n",
      "Epoch [10/10] Batch [245/469] Loss D: -0.5655869841575623, loss G: -0.0650312751531601\n",
      "Epoch [10/10] Batch [246/469] Loss D: -0.634453296661377, loss G: -0.14589734375476837\n",
      "Epoch [10/10] Batch [247/469] Loss D: -0.626314640045166, loss G: -0.18434783816337585\n",
      "Epoch [10/10] Batch [248/469] Loss D: -0.6414324641227722, loss G: -0.0822131335735321\n",
      "Epoch [10/10] Batch [249/469] Loss D: -0.6077162623405457, loss G: -0.349514901638031\n",
      "Epoch [10/10] Batch [250/469] Loss D: -0.5392038226127625, loss G: -0.08822042495012283\n",
      "Epoch [10/10] Batch [251/469] Loss D: -0.6052225828170776, loss G: -0.15601801872253418\n",
      "Epoch [10/10] Batch [252/469] Loss D: -0.5747536420822144, loss G: -0.15564779937267303\n",
      "Epoch [10/10] Batch [253/469] Loss D: -0.5338416695594788, loss G: -0.13867199420928955\n",
      "Epoch [10/10] Batch [254/469] Loss D: -0.6995120048522949, loss G: -0.2362716645002365\n",
      "Epoch [10/10] Batch [255/469] Loss D: -0.556423544883728, loss G: -0.07449094206094742\n",
      "Epoch [10/10] Batch [256/469] Loss D: -0.5420330166816711, loss G: -0.23198169469833374\n",
      "Epoch [10/10] Batch [257/469] Loss D: -0.6603025197982788, loss G: -0.06984826177358627\n",
      "Epoch [10/10] Batch [258/469] Loss D: -0.507489025592804, loss G: -0.32466673851013184\n",
      "Epoch [10/10] Batch [259/469] Loss D: -0.5517479181289673, loss G: -0.09510977566242218\n",
      "Epoch [10/10] Batch [260/469] Loss D: -0.5996167659759521, loss G: -0.2173897922039032\n",
      "Epoch [10/10] Batch [261/469] Loss D: -0.49552789330482483, loss G: -0.11265715956687927\n",
      "Epoch [10/10] Batch [262/469] Loss D: -0.5770837068557739, loss G: -0.15009352564811707\n",
      "Epoch [10/10] Batch [263/469] Loss D: -0.5393013954162598, loss G: -0.33094149827957153\n",
      "Epoch [10/10] Batch [264/469] Loss D: -0.5661725997924805, loss G: -0.09366932511329651\n",
      "Epoch [10/10] Batch [265/469] Loss D: -0.5540494322776794, loss G: -0.23538589477539062\n",
      "Epoch [10/10] Batch [266/469] Loss D: -0.6071802973747253, loss G: -0.07986673712730408\n",
      "Epoch [10/10] Batch [267/469] Loss D: -0.5209050178527832, loss G: -0.3448651432991028\n",
      "Epoch [10/10] Batch [268/469] Loss D: -0.4913454055786133, loss G: -0.12823699414730072\n",
      "Epoch [10/10] Batch [269/469] Loss D: -0.6023564338684082, loss G: -0.15790262818336487\n",
      "Epoch [10/10] Batch [270/469] Loss D: -0.5670167803764343, loss G: -0.17263716459274292\n",
      "Epoch [10/10] Batch [271/469] Loss D: -0.595018208026886, loss G: -0.12268465757369995\n",
      "Epoch [10/10] Batch [272/469] Loss D: -0.5754219889640808, loss G: -0.20247095823287964\n",
      "Epoch [10/10] Batch [273/469] Loss D: -0.5363271832466125, loss G: -0.12088952213525772\n",
      "Epoch [10/10] Batch [274/469] Loss D: -0.5530082583427429, loss G: -0.3366904854774475\n",
      "Epoch [10/10] Batch [275/469] Loss D: -0.5375930666923523, loss G: -0.04874112084507942\n",
      "Epoch [10/10] Batch [276/469] Loss D: -0.47440165281295776, loss G: -0.33604955673217773\n",
      "Epoch [10/10] Batch [277/469] Loss D: -0.5740025043487549, loss G: -0.13076652586460114\n",
      "Epoch [10/10] Batch [278/469] Loss D: -0.6191403865814209, loss G: -0.1033298671245575\n",
      "Epoch [10/10] Batch [279/469] Loss D: -0.5550017952919006, loss G: -0.23611292243003845\n",
      "Epoch [10/10] Batch [280/469] Loss D: -0.5457143783569336, loss G: -0.10839442908763885\n",
      "Epoch [10/10] Batch [281/469] Loss D: -0.5813939571380615, loss G: -0.2350011169910431\n",
      "Epoch [10/10] Batch [282/469] Loss D: -0.5772954225540161, loss G: -0.16949540376663208\n",
      "Epoch [10/10] Batch [283/469] Loss D: -0.5919700264930725, loss G: -0.14783722162246704\n",
      "Epoch [10/10] Batch [284/469] Loss D: -0.49527615308761597, loss G: -0.2911810874938965\n",
      "Epoch [10/10] Batch [285/469] Loss D: -0.6018998026847839, loss G: -0.126052126288414\n",
      "Epoch [10/10] Batch [286/469] Loss D: -0.6165266036987305, loss G: -0.1672113835811615\n",
      "Epoch [10/10] Batch [287/469] Loss D: -0.6595103740692139, loss G: -0.1294906735420227\n",
      "Epoch [10/10] Batch [288/469] Loss D: -0.6408441662788391, loss G: -0.09069813787937164\n",
      "Epoch [10/10] Batch [289/469] Loss D: -0.5464363694190979, loss G: -0.3443387746810913\n",
      "Epoch [10/10] Batch [290/469] Loss D: -0.4798431992530823, loss G: -0.15950623154640198\n",
      "Epoch [10/10] Batch [291/469] Loss D: -0.5500733852386475, loss G: -0.12533625960350037\n",
      "Epoch [10/10] Batch [292/469] Loss D: -0.5186794996261597, loss G: -0.3549010157585144\n",
      "Epoch [10/10] Batch [293/469] Loss D: -0.5353202819824219, loss G: -0.10898829996585846\n",
      "Epoch [10/10] Batch [294/469] Loss D: -0.5721303224563599, loss G: -0.22385713458061218\n",
      "Epoch [10/10] Batch [295/469] Loss D: -0.572766900062561, loss G: -0.07854018360376358\n",
      "Epoch [10/10] Batch [296/469] Loss D: -0.5830186009407043, loss G: -0.2809351980686188\n",
      "Epoch [10/10] Batch [297/469] Loss D: -0.5332701206207275, loss G: -0.10359670966863632\n",
      "Epoch [10/10] Batch [298/469] Loss D: -0.6127663254737854, loss G: -0.2575286030769348\n",
      "Epoch [10/10] Batch [299/469] Loss D: -0.5397002696990967, loss G: -0.1395636349916458\n",
      "Epoch [10/10] Batch [300/469] Loss D: -0.5918692350387573, loss G: -0.08294423669576645\n",
      "Epoch [10/10] Batch [301/469] Loss D: -0.5842363238334656, loss G: -0.3775806725025177\n",
      "Epoch [10/10] Batch [302/469] Loss D: -0.49530118703842163, loss G: -0.09519275277853012\n",
      "Epoch [10/10] Batch [303/469] Loss D: -0.5433950424194336, loss G: -0.230301171541214\n",
      "Epoch [10/10] Batch [304/469] Loss D: -0.613008439540863, loss G: -0.12287961691617966\n",
      "Epoch [10/10] Batch [305/469] Loss D: -0.501185417175293, loss G: -0.21063271164894104\n",
      "Epoch [10/10] Batch [306/469] Loss D: -0.4965062141418457, loss G: -0.17968763411045074\n",
      "Epoch [10/10] Batch [307/469] Loss D: -0.6454747915267944, loss G: -0.14860320091247559\n",
      "Epoch [10/10] Batch [308/469] Loss D: -0.5748648643493652, loss G: -0.1284518837928772\n",
      "Epoch [10/10] Batch [309/469] Loss D: -0.6133327484130859, loss G: -0.14005109667778015\n",
      "Epoch [10/10] Batch [310/469] Loss D: -0.6804328560829163, loss G: -0.10609889775514603\n",
      "Epoch [10/10] Batch [311/469] Loss D: -0.593308687210083, loss G: -0.26007142663002014\n",
      "Epoch [10/10] Batch [312/469] Loss D: -0.5247976779937744, loss G: -0.14314760267734528\n",
      "Epoch [10/10] Batch [313/469] Loss D: -0.5800695419311523, loss G: -0.22088374197483063\n",
      "Epoch [10/10] Batch [314/469] Loss D: -0.5866861343383789, loss G: -0.05987278372049332\n",
      "Epoch [10/10] Batch [315/469] Loss D: -0.43399977684020996, loss G: -0.27997761964797974\n",
      "Epoch [10/10] Batch [316/469] Loss D: -0.5339062809944153, loss G: -0.16821980476379395\n",
      "Epoch [10/10] Batch [317/469] Loss D: -0.5117826461791992, loss G: -0.22239190340042114\n",
      "Epoch [10/10] Batch [318/469] Loss D: -0.596837043762207, loss G: -0.08461371064186096\n",
      "Epoch [10/10] Batch [319/469] Loss D: -0.4528881311416626, loss G: -0.48082101345062256\n",
      "Epoch [10/10] Batch [320/469] Loss D: -0.4251469373703003, loss G: -0.10432509332895279\n",
      "Epoch [10/10] Batch [321/469] Loss D: -0.549983561038971, loss G: -0.181998610496521\n",
      "Epoch [10/10] Batch [322/469] Loss D: -0.6373934745788574, loss G: -0.27045053243637085\n",
      "Epoch [10/10] Batch [323/469] Loss D: -0.5264184474945068, loss G: -0.0700233206152916\n",
      "Epoch [10/10] Batch [324/469] Loss D: -0.46999749541282654, loss G: -0.28779542446136475\n",
      "Epoch [10/10] Batch [325/469] Loss D: -0.5879560708999634, loss G: -0.18556049466133118\n",
      "Epoch [10/10] Batch [326/469] Loss D: -0.6136199235916138, loss G: -0.04619788005948067\n",
      "Epoch [10/10] Batch [327/469] Loss D: -0.4607957601547241, loss G: -0.3143683969974518\n",
      "Epoch [10/10] Batch [328/469] Loss D: -0.539541482925415, loss G: -0.143751323223114\n",
      "Epoch [10/10] Batch [329/469] Loss D: -0.5205344557762146, loss G: -0.20619641244411469\n",
      "Epoch [10/10] Batch [330/469] Loss D: -0.5679105520248413, loss G: -0.16022522747516632\n",
      "Epoch [10/10] Batch [331/469] Loss D: -0.5383040904998779, loss G: -0.17791198194026947\n",
      "Epoch [10/10] Batch [332/469] Loss D: -0.5786752104759216, loss G: -0.14612190425395966\n",
      "Epoch [10/10] Batch [333/469] Loss D: -0.6016298532485962, loss G: -0.14226360619068146\n",
      "Epoch [10/10] Batch [334/469] Loss D: -0.6193187832832336, loss G: -0.2132582664489746\n",
      "Epoch [10/10] Batch [335/469] Loss D: -0.5836601257324219, loss G: -0.10880643129348755\n",
      "Epoch [10/10] Batch [336/469] Loss D: -0.5038602948188782, loss G: -0.2591537833213806\n",
      "Epoch [10/10] Batch [337/469] Loss D: -0.5397657752037048, loss G: -0.09108461439609528\n",
      "Epoch [10/10] Batch [338/469] Loss D: -0.5528087615966797, loss G: -0.2791759669780731\n",
      "Epoch [10/10] Batch [339/469] Loss D: -0.5939345955848694, loss G: -0.16377079486846924\n",
      "Epoch [10/10] Batch [340/469] Loss D: -0.5568115711212158, loss G: -0.1384512484073639\n",
      "Epoch [10/10] Batch [341/469] Loss D: -0.6009313464164734, loss G: -0.1556919813156128\n",
      "Epoch [10/10] Batch [342/469] Loss D: -0.5768693089485168, loss G: -0.23745641112327576\n",
      "Epoch [10/10] Batch [343/469] Loss D: -0.5433818101882935, loss G: -0.08296889066696167\n",
      "Epoch [10/10] Batch [344/469] Loss D: -0.5052651166915894, loss G: -0.38560745120048523\n",
      "Epoch [10/10] Batch [345/469] Loss D: -0.5023672580718994, loss G: -0.08184412121772766\n",
      "Epoch [10/10] Batch [346/469] Loss D: -0.598030686378479, loss G: -0.16137604415416718\n",
      "Epoch [10/10] Batch [347/469] Loss D: -0.5713680982589722, loss G: -0.2129477560520172\n",
      "Epoch [10/10] Batch [348/469] Loss D: -0.604828953742981, loss G: -0.15919458866119385\n",
      "Epoch [10/10] Batch [349/469] Loss D: -0.6523664593696594, loss G: -0.0683036744594574\n",
      "Epoch [10/10] Batch [350/469] Loss D: -0.46995067596435547, loss G: -0.4165552854537964\n",
      "Epoch [10/10] Batch [351/469] Loss D: -0.4384632706642151, loss G: -0.18966934084892273\n",
      "Epoch [10/10] Batch [352/469] Loss D: -0.5836825966835022, loss G: -0.10631666332483292\n",
      "Epoch [10/10] Batch [353/469] Loss D: -0.5360648036003113, loss G: -0.3685283660888672\n",
      "Epoch [10/10] Batch [354/469] Loss D: -0.5135720372200012, loss G: -0.0726563110947609\n",
      "Epoch [10/10] Batch [355/469] Loss D: -0.6064085960388184, loss G: -0.17394444346427917\n",
      "Epoch [10/10] Batch [356/469] Loss D: -0.602647066116333, loss G: -0.22988776862621307\n",
      "Epoch [10/10] Batch [357/469] Loss D: -0.47581690549850464, loss G: -0.23582136631011963\n",
      "Epoch [10/10] Batch [358/469] Loss D: -0.6965570449829102, loss G: -0.04801366478204727\n",
      "Epoch [10/10] Batch [359/469] Loss D: -0.5760588645935059, loss G: -0.2478172481060028\n",
      "Epoch [10/10] Batch [360/469] Loss D: -0.5641177892684937, loss G: -0.18289873003959656\n",
      "Epoch [10/10] Batch [361/469] Loss D: -0.5851824283599854, loss G: -0.1367284655570984\n",
      "Epoch [10/10] Batch [362/469] Loss D: -0.5869330167770386, loss G: -0.18533656001091003\n",
      "Epoch [10/10] Batch [363/469] Loss D: -0.6725714206695557, loss G: -0.10671775788068771\n",
      "Epoch [10/10] Batch [364/469] Loss D: -0.5408754944801331, loss G: -0.211504727602005\n",
      "Epoch [10/10] Batch [365/469] Loss D: -0.6228148341178894, loss G: -0.09894121438264847\n",
      "Epoch [10/10] Batch [366/469] Loss D: -0.5812174081802368, loss G: -0.2022731602191925\n",
      "Epoch [10/10] Batch [367/469] Loss D: -0.6093776822090149, loss G: -0.21363936364650726\n",
      "Epoch [10/10] Batch [368/469] Loss D: -0.598397970199585, loss G: -0.09609931707382202\n",
      "Epoch [10/10] Batch [369/469] Loss D: -0.6166214346885681, loss G: -0.20811517536640167\n",
      "Epoch [10/10] Batch [370/469] Loss D: -0.6390549540519714, loss G: -0.1335843801498413\n",
      "Epoch [10/10] Batch [371/469] Loss D: -0.5644065737724304, loss G: -0.16977323591709137\n",
      "Epoch [10/10] Batch [372/469] Loss D: -0.6432188153266907, loss G: -0.17211224138736725\n",
      "Epoch [10/10] Batch [373/469] Loss D: -0.6440811157226562, loss G: -0.12485440820455551\n",
      "Epoch [10/10] Batch [374/469] Loss D: -0.5695376992225647, loss G: -0.1297701597213745\n",
      "Epoch [10/10] Batch [375/469] Loss D: -0.5472398996353149, loss G: -0.17332349717617035\n",
      "Epoch [10/10] Batch [376/469] Loss D: -0.5919762253761292, loss G: -0.3128998279571533\n",
      "Epoch [10/10] Batch [377/469] Loss D: -0.6037962436676025, loss G: -0.04464663937687874\n",
      "Epoch [10/10] Batch [378/469] Loss D: -0.5667957067489624, loss G: -0.2712501287460327\n",
      "Epoch [10/10] Batch [379/469] Loss D: -0.5399019718170166, loss G: -0.08845896273851395\n",
      "Epoch [10/10] Batch [380/469] Loss D: -0.4693678021430969, loss G: -0.29919445514678955\n",
      "Epoch [10/10] Batch [381/469] Loss D: -0.5366270542144775, loss G: -0.08531850576400757\n",
      "Epoch [10/10] Batch [382/469] Loss D: -0.5134894847869873, loss G: -0.21149078011512756\n",
      "Epoch [10/10] Batch [383/469] Loss D: -0.5859581232070923, loss G: -0.163034588098526\n",
      "Epoch [10/10] Batch [384/469] Loss D: -0.5764904022216797, loss G: -0.1354210078716278\n",
      "Epoch [10/10] Batch [385/469] Loss D: -0.5562747120857239, loss G: -0.21431457996368408\n",
      "Epoch [10/10] Batch [386/469] Loss D: -0.6498697400093079, loss G: -0.14625437557697296\n",
      "Epoch [10/10] Batch [387/469] Loss D: -0.6490228176116943, loss G: -0.15857809782028198\n",
      "Epoch [10/10] Batch [388/469] Loss D: -0.6278604865074158, loss G: -0.10267458856105804\n",
      "Epoch [10/10] Batch [389/469] Loss D: -0.5592892169952393, loss G: -0.21422255039215088\n",
      "Epoch [10/10] Batch [390/469] Loss D: -0.5523107647895813, loss G: -0.28735971450805664\n",
      "Epoch [10/10] Batch [391/469] Loss D: -0.5891219973564148, loss G: -0.046374768018722534\n",
      "Epoch [10/10] Batch [392/469] Loss D: -0.5376056432723999, loss G: -0.2784266173839569\n",
      "Epoch [10/10] Batch [393/469] Loss D: -0.4969024658203125, loss G: -0.2524949908256531\n",
      "Epoch [10/10] Batch [394/469] Loss D: -0.6266035437583923, loss G: -0.06132156774401665\n",
      "Epoch [10/10] Batch [395/469] Loss D: -0.6237205862998962, loss G: -0.2221396267414093\n",
      "Epoch [10/10] Batch [396/469] Loss D: -0.5706601142883301, loss G: -0.18115215003490448\n",
      "Epoch [10/10] Batch [397/469] Loss D: -0.5293760895729065, loss G: -0.24818558990955353\n",
      "Epoch [10/10] Batch [398/469] Loss D: -0.5667428970336914, loss G: -0.07529181241989136\n",
      "Epoch [10/10] Batch [399/469] Loss D: -0.48967060446739197, loss G: -0.3338729441165924\n",
      "Epoch [10/10] Batch [400/469] Loss D: -0.5679078102111816, loss G: -0.1285112053155899\n",
      "Epoch [10/10] Batch [401/469] Loss D: -0.5304327011108398, loss G: -0.14987987279891968\n",
      "Epoch [10/10] Batch [402/469] Loss D: -0.589184045791626, loss G: -0.20524725317955017\n",
      "Epoch [10/10] Batch [403/469] Loss D: -0.5830001831054688, loss G: -0.12971067428588867\n",
      "Epoch [10/10] Batch [404/469] Loss D: -0.5203022956848145, loss G: -0.3025643825531006\n",
      "Epoch [10/10] Batch [405/469] Loss D: -0.518161952495575, loss G: -0.1682533621788025\n",
      "Epoch [10/10] Batch [406/469] Loss D: -0.5676013231277466, loss G: -0.17143234610557556\n",
      "Epoch [10/10] Batch [407/469] Loss D: -0.6584824323654175, loss G: -0.08898613601922989\n",
      "Epoch [10/10] Batch [408/469] Loss D: -0.5771160125732422, loss G: -0.2084207534790039\n",
      "Epoch [10/10] Batch [409/469] Loss D: -0.6616424322128296, loss G: -0.12080173939466476\n",
      "Epoch [10/10] Batch [410/469] Loss D: -0.6160062551498413, loss G: -0.26167431473731995\n",
      "Epoch [10/10] Batch [411/469] Loss D: -0.5174458622932434, loss G: -0.07471306622028351\n",
      "Epoch [10/10] Batch [412/469] Loss D: -0.6668240427970886, loss G: -0.1730833202600479\n",
      "Epoch [10/10] Batch [413/469] Loss D: -0.6691763401031494, loss G: -0.11406297236680984\n",
      "Epoch [10/10] Batch [414/469] Loss D: -0.5859595537185669, loss G: -0.17750966548919678\n",
      "Epoch [10/10] Batch [415/469] Loss D: -0.5904458165168762, loss G: -0.20658312737941742\n",
      "Epoch [10/10] Batch [416/469] Loss D: -0.4962698221206665, loss G: -0.06870675086975098\n",
      "Epoch [10/10] Batch [417/469] Loss D: -0.596687376499176, loss G: -0.29820239543914795\n",
      "Epoch [10/10] Batch [418/469] Loss D: -0.5684217214584351, loss G: -0.1123514398932457\n",
      "Epoch [10/10] Batch [419/469] Loss D: -0.616948127746582, loss G: -0.144071564078331\n",
      "Epoch [10/10] Batch [420/469] Loss D: -0.6204429864883423, loss G: -0.18107128143310547\n",
      "Epoch [10/10] Batch [421/469] Loss D: -0.5672221183776855, loss G: -0.0929383710026741\n",
      "Epoch [10/10] Batch [422/469] Loss D: -0.3700222373008728, loss G: -0.32820653915405273\n",
      "Epoch [10/10] Batch [423/469] Loss D: -0.6208325624465942, loss G: -0.1417311578989029\n",
      "Epoch [10/10] Batch [424/469] Loss D: -0.5707718133926392, loss G: -0.05069955810904503\n",
      "Epoch [10/10] Batch [425/469] Loss D: -0.425248920917511, loss G: -0.2950454354286194\n",
      "Epoch [10/10] Batch [426/469] Loss D: -0.6429101228713989, loss G: -0.09417590498924255\n",
      "Epoch [10/10] Batch [427/469] Loss D: -0.6046019792556763, loss G: -0.18776482343673706\n",
      "Epoch [10/10] Batch [428/469] Loss D: -0.5868622064590454, loss G: -0.1241031289100647\n",
      "Epoch [10/10] Batch [429/469] Loss D: -0.6433165669441223, loss G: -0.18943804502487183\n",
      "Epoch [10/10] Batch [430/469] Loss D: -0.546768307685852, loss G: -0.20404347777366638\n",
      "Epoch [10/10] Batch [431/469] Loss D: -0.5992448925971985, loss G: -0.056078750640153885\n",
      "Epoch [10/10] Batch [432/469] Loss D: -0.532752513885498, loss G: -0.28946638107299805\n",
      "Epoch [10/10] Batch [433/469] Loss D: -0.4900500178337097, loss G: -0.2262856662273407\n",
      "Epoch [10/10] Batch [434/469] Loss D: -0.6344757080078125, loss G: -0.04832722246646881\n",
      "Epoch [10/10] Batch [435/469] Loss D: -0.4918118715286255, loss G: -0.37650781869888306\n",
      "Epoch [10/10] Batch [436/469] Loss D: -0.5058679580688477, loss G: -0.15190540254116058\n",
      "Epoch [10/10] Batch [437/469] Loss D: -0.6385964155197144, loss G: -0.04843383654952049\n",
      "Epoch [10/10] Batch [438/469] Loss D: -0.5615974068641663, loss G: -0.3105093538761139\n",
      "Epoch [10/10] Batch [439/469] Loss D: -0.5127047300338745, loss G: -0.13758867979049683\n",
      "Epoch [10/10] Batch [440/469] Loss D: -0.6394455432891846, loss G: -0.11312750726938248\n",
      "Epoch [10/10] Batch [441/469] Loss D: -0.6444391012191772, loss G: -0.2038179337978363\n",
      "Epoch [10/10] Batch [442/469] Loss D: -0.6239593029022217, loss G: -0.07120153307914734\n",
      "Epoch [10/10] Batch [443/469] Loss D: -0.5360963344573975, loss G: -0.30691009759902954\n",
      "Epoch [10/10] Batch [444/469] Loss D: -0.5476256608963013, loss G: -0.0769263282418251\n",
      "Epoch [10/10] Batch [445/469] Loss D: -0.5922423005104065, loss G: -0.19077765941619873\n",
      "Epoch [10/10] Batch [446/469] Loss D: -0.4878506660461426, loss G: -0.31344345211982727\n",
      "Epoch [10/10] Batch [447/469] Loss D: -0.5467650890350342, loss G: -0.06843777000904083\n",
      "Epoch [10/10] Batch [448/469] Loss D: -0.6045060157775879, loss G: -0.21620795130729675\n",
      "Epoch [10/10] Batch [449/469] Loss D: -0.5258917808532715, loss G: -0.11965106427669525\n",
      "Epoch [10/10] Batch [450/469] Loss D: -0.6075486540794373, loss G: -0.21189802885055542\n",
      "Epoch [10/10] Batch [451/469] Loss D: -0.5474738478660583, loss G: -0.1882351040840149\n",
      "Epoch [10/10] Batch [452/469] Loss D: -0.5393116474151611, loss G: -0.1760607361793518\n",
      "Epoch [10/10] Batch [453/469] Loss D: -0.5739778280258179, loss G: -0.09425966441631317\n",
      "Epoch [10/10] Batch [454/469] Loss D: -0.6525436639785767, loss G: -0.25678497552871704\n",
      "Epoch [10/10] Batch [455/469] Loss D: -0.6611136794090271, loss G: -0.04400409758090973\n",
      "Epoch [10/10] Batch [456/469] Loss D: -0.6109911203384399, loss G: -0.24636289477348328\n",
      "Epoch [10/10] Batch [457/469] Loss D: -0.5005006194114685, loss G: -0.157586932182312\n",
      "Epoch [10/10] Batch [458/469] Loss D: -0.5790199637413025, loss G: -0.21564146876335144\n",
      "Epoch [10/10] Batch [459/469] Loss D: -0.6803687810897827, loss G: -0.0652155727148056\n",
      "Epoch [10/10] Batch [460/469] Loss D: -0.5658090114593506, loss G: -0.2828875184059143\n",
      "Epoch [10/10] Batch [461/469] Loss D: -0.5608818531036377, loss G: -0.096315398812294\n",
      "Epoch [10/10] Batch [462/469] Loss D: -0.5696266889572144, loss G: -0.23642531037330627\n",
      "Epoch [10/10] Batch [463/469] Loss D: -0.6057922840118408, loss G: -0.12598460912704468\n",
      "Epoch [10/10] Batch [464/469] Loss D: -0.6550377011299133, loss G: -0.12480182945728302\n",
      "Epoch [10/10] Batch [465/469] Loss D: -0.5384490489959717, loss G: -0.21190261840820312\n",
      "Epoch [10/10] Batch [466/469] Loss D: -0.6729918122291565, loss G: -0.13250434398651123\n",
      "Epoch [10/10] Batch [467/469] Loss D: -0.6514947414398193, loss G: -0.19251811504364014\n",
      "Epoch [10/10] Batch [468/469] Loss D: -0.6213890314102173, loss G: -0.0871044248342514\n",
      "Epoch [10/10] Batch [469/469] Loss D: -0.698071300983429, loss G: -0.09116441756486893\n"
     ]
    }
   ],
   "source": [
    "num_epochs=10\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (real_imgs, text_embeddings) in enumerate(dataloader):\n",
    "        real_imgs = real_imgs.to(device)\n",
    "        text_embeddings = torch.tensor(text_embeddings, dtype=torch.float32).to(device)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizerD1.zero_grad()\n",
    "\n",
    "        noise = torch.randn(len(real_imgs), noise_dim).to(device)\n",
    "        fake_imgs = netG1(noise, text_embeddings)\n",
    "\n",
    "        real_validity = netD1(real_imgs, text_embeddings)\n",
    "        fake_validity = netD1(fake_imgs.detach(), text_embeddings)\n",
    "\n",
    "        # gradient_penalty = compute_gradient_penalty(netD1, real_imgs.data, fake_imgs.data, text_embeddings)\n",
    "        d_loss = -torch.mean(real_validity) + torch.mean(fake_validity)\n",
    "        # d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + lambda_gp * gradient_penalty\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizerD1.step()\n",
    "\n",
    "        # ------------------\n",
    "        #  Train Generator\n",
    "        # ------------------\n",
    "\n",
    "        optimizerG1.zero_grad()\n",
    "\n",
    "        gen_validity = netD1(fake_imgs, text_embeddings)\n",
    "        g_loss = -torch.mean(gen_validity)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizerG1.step()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] Batch [{i+1}/{len(dataloader)}] Loss D: {d_loss.item()}, loss G: {g_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained Stage-I models\n",
    "torch.save(netG1.state_dict(), 'netG1.pth')\n",
    "torch.save(netD1.state_dict(), 'netD1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:11: SyntaxWarning: invalid escape sequence '\\g'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\g'\n",
      "C:\\Users\\hardi\\AppData\\Local\\Temp\\ipykernel_37668\\1827126145.py:11: SyntaxWarning: invalid escape sequence '\\g'\n",
      "  glove_file = 'goolove\\glove.6B.300d.txt'\n"
     ]
    }
   ],
   "source": [
    "def load_glove_embeddings(glove_file):\n",
    "    embeddings_index = {}\n",
    "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    return embeddings_index\n",
    "\n",
    "glove_file = 'goolove\\glove.6B.300d.txt'\n",
    "glove_model = load_glove_embeddings(glove_file)\n",
    "text_dim = 300  # GloVe embedding dimension\n",
    "projected_dim = 128\n",
    "noise_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hardi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the trained models\n",
    "netG1 = Generator_Stage1(noise_dim, text_dim, projected_dim)\n",
    "netG1.load_state_dict(torch.load('netG1.pth'))\n",
    "netG1.eval()\n",
    "\n",
    "# netG2 = Generator_Stage2(text_dim, projected_dim)\n",
    "# netG2.load_state_dict(torch.load('netG2.pth'))\n",
    "# netG2.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "netG1.to(device)\n",
    "# netG2.to(device)\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Function to get text embeddings using GloVe\n",
    "def get_text_embedding(text, glove_model):\n",
    "    words = word_tokenize(text.lower())\n",
    "    embeddings = [glove_model[word] for word in words if word in glove_model]\n",
    "    if embeddings:\n",
    "        text_embedding = np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        text_embedding = np.zeros(len(next(iter(glove_model.values()))))\n",
    "    text_embedding = torch.tensor(text_embedding, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
    "    return text_embedding.to(device)\n",
    "\n",
    "# Function to generate and save image from text\n",
    "def generate_image_from_text(text, noise_dim, glove_model):\n",
    "    text_embedding = get_text_embedding(text, glove_model)\n",
    "    \n",
    "    noise = torch.randn(1, noise_dim).to(device)\n",
    "    with torch.no_grad():\n",
    "        fake_img_stage1 = netG1(noise, text_embedding)\n",
    "        # fake_img_stage2 = netG2(fake_img_stage1, text_embedding)\n",
    "\n",
    "    # Convert the generated image to a PIL image and save\n",
    "    img = fake_img_stage1.squeeze().cpu().numpy()\n",
    "    img = np.transpose(img, (1, 2, 0))\n",
    "    img = (img + 1) / 2.0 * 255  # Rescale to [0, 255]\n",
    "    img = img.astype(np.uint8)\n",
    "    img = Image.fromarray(img)\n",
    "    \n",
    "    # img.save('generated_image.png')\n",
    "    return img\n",
    "\n",
    "# Example usage\n",
    "text_input = \"digit illustr kabuto rock'n'roll watertyp dodo pokmon character brown shell larg black eye cerise pupil promin yellow claw\"\n",
    "generated_image = generate_image_from_text(text_input, noise_dim, glove_model)\n",
    "generated_image.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
